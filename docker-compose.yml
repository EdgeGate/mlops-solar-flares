services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      retries: 5

  airflow-init:
    image: apache/airflow:2.9.2
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
      _AIRFLOW_WWW_USER_EMAIL: admin@example.com
      _AIRFLOW_WWW_USER_FIRSTNAME: Air
      _AIRFLOW_WWW_USER_LASTNAME: Flow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./:/opt/project
    entrypoint: ["bash","-lc"]
    command:
      - >
        airflow db migrate &&
        airflow users create
        --username "$_AIRFLOW_WWW_USER_USERNAME"
        --password "$_AIRFLOW_WWW_USER_PASSWORD"
        --firstname "$_AIRFLOW_WWW_USER_FIRSTNAME"
        --lastname "$_AIRFLOW_WWW_USER_LASTNAME"
        --role Admin
        --email "$_AIRFLOW_WWW_USER_EMAIL"


  airflow-webserver:
    image: apache/airflow:2.9.2
    depends_on:
      - airflow-init
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      PROJECT_ROOT: /opt/project
      MLFLOW_TRACKING_URI: http://mlflow:5000
      _PIP_ADDITIONAL_REQUIREMENTS: >
        pandas==2.1.4 packaging==24.2 requests
        xarray==2024.6.0 netCDF4 fastparquet
        pyarrow==15.0.2
        scikit-learn==1.5.1
        mlflow==2.14.1
        evidently==0.7.12
        matplotlib==3.9.1
        xgboost==2.1.1
        joblib==1.4.2
        papermill==2.6.0
        pydantic>=1.10.15,<2
        typing_extensions<4.12
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./:/opt/project
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./mlruns:/mlflow/mlruns
    command: ["webserver"]

  airflow-scheduler:
    image: apache/airflow:2.9.2
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      PROJECT_ROOT: /opt/project
      MLFLOW_TRACKING_URI: http://mlflow:5000
      _PIP_ADDITIONAL_REQUIREMENTS: >
        pandas==2.1.4 packaging==24.2 requests
        xarray==2024.6.0 netCDF4 fastparquet
        pyarrow==15.0.2
        scikit-learn==1.5.1
        mlflow==2.14.1
        evidently==0.7.12
        matplotlib==3.9.1
        xgboost==2.1.1
        joblib==1.4.2
        papermill==2.6.0
        pydantic>=1.10.15,<2
        typing_extensions<4.12
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./:/opt/project
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/project/data
      - ./mlruns:/mlflow/mlruns
    command: ["scheduler"]


  postgres-mlflow:
    image: postgres:15
    container_name: postgres-mlflow
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow
    volumes:
      - postgres-mlflow-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mlflow"]
      interval: 5s
      retries: 5

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    container_name: mlflow
    depends_on:
      postgres-mlflow:
        condition: service_healthy
    ports:
      - "5000:5000"
    environment:
      MLFLOW_BACKEND_STORE_URI: postgresql+psycopg2://mlflow:mlflow@postgres-mlflow/mlflow
      MLFLOW_ARTIFACTS_DESTINATION: file:///mlflow/mlruns
    volumes:
      - ./mlruns:/mlflow/mlruns

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      MODEL_NAME: solar-flares-classifier
      MODEL_ALIAS: Production
    ports:
      - "8000:8000"
    volumes:
      - ./api:/app
      - ./mlruns:/mlflow/mlruns
    command: ["uvicorn","app:app","--host","0.0.0.0","--port","8000","--reload"]

  prometheus:
    image: prom/prometheus:v2.54.1
    volumes:
      - ./api/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.retention.time=15d
    ports:
      - "9090:9090"
    depends_on:
      - api

  grafana:
    image: grafana/grafana:10.4.3
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    ports:
      - "3000:3000"
    volumes:
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus



volumes:
  postgres-data:
  postgres-mlflow-data:
