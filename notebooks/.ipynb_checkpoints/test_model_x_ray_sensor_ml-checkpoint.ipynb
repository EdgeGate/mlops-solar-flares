{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93a4696-d8c7-42fd-a0d6-48c583727413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d7f4cc-0cf8-463f-abd4-495ce6a5f4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Chargement du fichier xrs_clean.parquet...\n",
      "âœ… DonnÃ©es chargÃ©es : 147639 lignes, 11 colonnes\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“¥ Chargement du fichier xrs_clean.parquet...\")\n",
    "\n",
    "parquet_path = Path(r\"C:\\Users\\gate\\Documents\\Jedha\\Projet\\4\\mlops-solar-flares\\data\\xrs_clean.parquet\")\n",
    "df = parquet_path\n",
    "df = pd.read_parquet(parquet_path, engine=\"pyarrow\")\n",
    "print(f\"âœ… DonnÃ©es chargÃ©es : {df.shape[0]} lignes, {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341b35dd-0a37-4d8c-8aa5-980aa0003a12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# head: <bound method NDFrame.head of                             time  flux_long_wm2  flux_short_wm2 satellite  \\\n",
      "0      2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09      <NA>   \n",
      "1      2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09      <NA>   \n",
      "2      2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09      <NA>   \n",
      "3      2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09      <NA>   \n",
      "4      2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09      <NA>   \n",
      "...                          ...            ...             ...       ...   \n",
      "147634 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07   GOES-18   \n",
      "147635 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07   GOES-18   \n",
      "147636 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07   GOES-18   \n",
      "147637 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07   GOES-18   \n",
      "147638 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07   GOES-18   \n",
      "\n",
      "       energy_long energy_short      source        date  hour  minute_of_day  \\\n",
      "0       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              0   \n",
      "1       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              1   \n",
      "2       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              2   \n",
      "3       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              3   \n",
      "4       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              4   \n",
      "...            ...          ...         ...         ...   ...            ...   \n",
      "147634  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            754   \n",
      "147635  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            755   \n",
      "147636  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            756   \n",
      "147637  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            757   \n",
      "147638  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            758   \n",
      "\n",
      "        dow  \n",
      "0         3  \n",
      "1         3  \n",
      "2         3  \n",
      "3         3  \n",
      "4         3  \n",
      "...     ...  \n",
      "147634    0  \n",
      "147635    0  \n",
      "147636    0  \n",
      "147637    0  \n",
      "147638    0  \n",
      "\n",
      "[147639 rows x 11 columns]>\n",
      "\n",
      "# dtypes:\n",
      " time              datetime64[ns, UTC]\n",
      "flux_long_wm2                 float32\n",
      "flux_short_wm2                float32\n",
      "satellite              string[python]\n",
      "energy_long                    object\n",
      "energy_short                   object\n",
      "source                 string[python]\n",
      "date                   string[python]\n",
      "hour                            int16\n",
      "minute_of_day                   int16\n",
      "dow                              int8\n",
      "dtype: object\n",
      "\n",
      "# describe: <bound method NDFrame.describe of                             time  flux_long_wm2  flux_short_wm2 satellite  \\\n",
      "0      2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09      <NA>   \n",
      "1      2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09      <NA>   \n",
      "2      2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09      <NA>   \n",
      "3      2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09      <NA>   \n",
      "4      2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09      <NA>   \n",
      "...                          ...            ...             ...       ...   \n",
      "147634 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07   GOES-18   \n",
      "147635 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07   GOES-18   \n",
      "147636 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07   GOES-18   \n",
      "147637 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07   GOES-18   \n",
      "147638 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07   GOES-18   \n",
      "\n",
      "       energy_long energy_short      source        date  hour  minute_of_day  \\\n",
      "0       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              0   \n",
      "1       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              1   \n",
      "2       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              2   \n",
      "3       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              3   \n",
      "4       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              4   \n",
      "...            ...          ...         ...         ...   ...            ...   \n",
      "147634  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            754   \n",
      "147635  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            755   \n",
      "147636  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            756   \n",
      "147637  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            757   \n",
      "147638  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            758   \n",
      "\n",
      "        dow  \n",
      "0         3  \n",
      "1         3  \n",
      "2         3  \n",
      "3         3  \n",
      "4         3  \n",
      "...     ...  \n",
      "147634    0  \n",
      "147635    0  \n",
      "147636    0  \n",
      "147637    0  \n",
      "147638    0  \n",
      "\n",
      "[147639 rows x 11 columns]>\n",
      "\n",
      "# missing (%):\n",
      "satellite         91.68\n",
      "source             8.32\n",
      "flux_long_wm2      1.11\n",
      "flux_short_wm2     1.11\n",
      "time               0.00\n",
      "energy_long        0.00\n",
      "energy_short       0.00\n",
      "date               0.00\n",
      "hour               0.00\n",
      "minute_of_day      0.00\n",
      "\n",
      "# time range: 2025-05-01 00:00:00+00:00 -> 2025-08-11 12:38:00+00:00\n",
      "# time monotonic: True\n",
      "\n",
      "# last days (rows/day):\n",
      " time\n",
      "2025-08-02 00:00:00+00:00    1440\n",
      "2025-08-03 00:00:00+00:00    1440\n",
      "2025-08-04 00:00:00+00:00    1440\n",
      "2025-08-05 00:00:00+00:00    1440\n",
      "2025-08-06 00:00:00+00:00    1440\n",
      "2025-08-07 00:00:00+00:00    1440\n",
      "2025-08-08 00:00:00+00:00    1440\n",
      "2025-08-09 00:00:00+00:00    1440\n",
      "2025-08-10 00:00:00+00:00    1440\n",
      "2025-08-11 00:00:00+00:00     759\n"
     ]
    }
   ],
   "source": [
    "def quickpeek(df, topn=10):\n",
    "\n",
    "    print(\"# head:\", df.head)\n",
    "    print(\"\\n# dtypes:\\n\", df.dtypes)\n",
    "    print(\"\\n# describe:\", df.describe)\n",
    "\n",
    "    # missing %\n",
    "    print(\"\\n# missing (%):\")\n",
    "    miss = (df.isna().mean()*100).round(2).sort_values(ascending=False)\n",
    "    print(miss.head(topn).to_string())\n",
    "\n",
    "    if \"time\" in df:\n",
    "        # conversion robuste: tente direct, sinon passe par string\n",
    "        try:\n",
    "            t = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "        except Exception:\n",
    "            t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "        print(\"\\n# time range:\", t.min(), \"->\", t.max())\n",
    "\n",
    "        t_valid = t.dropna()\n",
    "        print(\"# time monotonic:\", t_valid.is_monotonic_increasing)\n",
    "\n",
    "        # comptage par jour sans dÃ©pendre du backend Arrow\n",
    "        try:\n",
    "            per_day = t.dt.floor(\"D\").value_counts().sort_index()\n",
    "        except Exception:\n",
    "            # fallback: utiliser la colonne 'date' si dispo\n",
    "            if \"date\" in df.columns:\n",
    "                per_day = pd.to_datetime(df[\"date\"], errors=\"coerce\").value_counts().sort_index()\n",
    "            else:\n",
    "                per_day = pd.Series(dtype=\"int64\")\n",
    "\n",
    "        if len(per_day):\n",
    "            print(\"\\n# last days (rows/day):\\n\", per_day.tail(10).to_string())\n",
    "\n",
    "\n",
    "quickpeek(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224673ab-a673-43ce-9c32-1dca75f6b9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ DerniÃ¨res lignes du fichier :\n",
      "                     time  flux_long_wm2  flux_short_wm2 satellite energy_long energy_short source       date  hour  minute_of_day  dow\n",
      "2025-08-11 12:29:00+00:00       0.000002    8.580523e-08   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            749    0\n",
      "2025-08-11 12:30:00+00:00       0.000002    1.043969e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            750    0\n",
      "2025-08-11 12:31:00+00:00       0.000003    2.087382e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            751    0\n",
      "2025-08-11 12:32:00+00:00       0.000004    3.514351e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            752    0\n",
      "2025-08-11 12:33:00+00:00       0.000004    4.549486e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            753    0\n",
      "2025-08-11 12:34:00+00:00       0.000005    5.942913e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            754    0\n",
      "2025-08-11 12:35:00+00:00       0.000006    7.550105e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            755    0\n",
      "2025-08-11 12:36:00+00:00       0.000007    8.529071e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            756    0\n",
      "2025-08-11 12:37:00+00:00       0.000007    8.953128e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            757    0\n",
      "2025-08-11 12:38:00+00:00       0.000007    8.543802e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            758    0\n",
      "\n",
      "ðŸ“„ PremiÃ¨res lignes du fichier triÃ© par 'time' :\n",
      "                       time  flux_long_wm2  flux_short_wm2 satellite energy_long energy_short      source        date  hour  minute_of_day  dow\n",
      "0 2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              0    3\n",
      "1 2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              1    3\n",
      "2 2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              2    3\n",
      "3 2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              3    3\n",
      "4 2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              4    3\n",
      "5 2025-05-01 00:05:00+00:00   6.989604e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              5    3\n",
      "6 2025-05-01 00:06:00+00:00   7.057731e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              6    3\n",
      "7 2025-05-01 00:07:00+00:00   7.109684e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              7    3\n",
      "8 2025-05-01 00:08:00+00:00   7.121013e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              8    3\n",
      "9 2025-05-01 00:09:00+00:00   7.152076e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              9    3\n"
     ]
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# DerniÃ¨res lignes triÃ©es par temps\n",
    "print(\"\\nðŸ“„ DerniÃ¨res lignes du fichier :\")\n",
    "print(df.sort_values(\"time\").tail(10).to_string(index=False))\n",
    "\n",
    "# PremiÃ¨res lignes triÃ©es par temps\n",
    "print(\"\\nðŸ“„ PremiÃ¨res lignes du fichier triÃ© par 'time' :\")\n",
    "print(df.sort_values(\"time\").head(10).reset_index(drop=True).to_string(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0990570e-256d-4811-8809-97b8b8de7b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›  CrÃ©ation de la variable cible 'flare_class'...\n",
      "âœ… Variable cible ajoutÃ©e.\n"
     ]
    }
   ],
   "source": [
    "TARGET_NAME  = \"flare_class\"\n",
    "ALL_CLASSES  = np.array([\"A\", \"B\", \"C\", \"M\", \"X\"], dtype=object)\n",
    "print(\"ðŸ›  CrÃ©ation de la variable cible 'flare_class'...\")\n",
    "\n",
    "def rule_predict(flux):\n",
    "    \"\"\"\n",
    "    Classe une Ã©ruption selon le pic de flux X (W/mÂ², 1-8 Ã…) \n",
    "    en utilisant les seuils NOAA officiels, avec A inclus.\n",
    "    \"\"\"\n",
    "    if pd.isna(flux):\n",
    "        return None\n",
    "    elif flux < 1e-7:       # A : < 10â»â· W/mÂ²\n",
    "        return \"A\"\n",
    "    elif flux < 1e-6:       # B : 10â»â· â‰¤ flux < 10â»â¶\n",
    "        return \"B\"\n",
    "    elif flux < 1e-5:       # C : 10â»â¶ â‰¤ flux < 10â»âµ\n",
    "        return \"C\"\n",
    "    elif flux < 1e-4:       # M : 10â»âµ â‰¤ flux < 10â»â´\n",
    "        return \"M\"\n",
    "    else:                   # X : â‰¥ 10â»â´\n",
    "        return \"X\"\n",
    "\n",
    "df[\"flare_class\"] = df[\"flux_long_wm2\"].apply(rule_predict)\n",
    "\n",
    "print(\"âœ… Variable cible ajoutÃ©e.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12457b0-bbf4-45c4-88a8-e77bb8c64054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“… Conversion et enrichissement des features temporelles...\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“… Conversion et enrichissement des features temporelles...\")\n",
    "# -- S'assurer d'avoir un datetime --\n",
    "if \"time\" in df.columns:\n",
    "    t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "elif isinstance(df.index, pd.DatetimeIndex):\n",
    "    t = pd.to_datetime(df.index, utc=True, errors=\"coerce\")\n",
    "elif \"date\" in df.columns:\n",
    "    t = pd.to_datetime(df[\"date\"].astype(str), utc=True, errors=\"coerce\")\n",
    "else:\n",
    "    raise KeyError(\"Impossible de trouver une colonne/indice temps ('time' ou 'date').\")\n",
    "\n",
    "# -- Colonnes temporelles dÃ©rivÃ©es --\n",
    "df[\"day_of_year\"] = t.dt.dayofyear.astype(\"int16\")     # 1..365/366\n",
    "df[\"hour\"] = t.dt.hour.astype(\"int16\") if \"hour\" not in df else df[\"hour\"]\n",
    "\n",
    "# Encodage cyclique du jour de l'annÃ©e\n",
    "rad_doy = 2 * np.pi * (df[\"day_of_year\"] - 1) / 365.25\n",
    "df[\"sin_doy\"] = np.sin(rad_doy)\n",
    "df[\"cos_doy\"] = np.cos(rad_doy)\n",
    "\n",
    "# Optionnel : indicateur jour/nuit (si utile)\n",
    "df[\"is_daytime\"] = ((df[\"hour\"] >= 6) & (df[\"hour\"] <= 18)).astype(\"int8\")\n",
    "\n",
    "df[\"flux_ratio_short_long\"] = df[\"flux_short_wm2\"] / df[\"flux_long_wm2\"]\n",
    "df[\"flux_diff_short_long\"] = df[\"flux_short_wm2\"] - df[\"flux_long_wm2\"]\n",
    "df[\"log_flux_long\"] = np.log10(df[\"flux_long_wm2\"].clip(lower=1e-9))\n",
    "df[\"log_flux_short\"] = np.log10(df[\"flux_short_wm2\"].clip(lower=1e-9))\n",
    "df[\"sin_doy\"] = np.sin(2 * np.pi * df[\"day_of_year\"] / 365.25)\n",
    "df[\"cos_doy\"] = np.cos(2 * np.pi * df[\"day_of_year\"] / 365.25)\n",
    "df[\"flux_long_rolling_mean_1h\"] = df[\"flux_long_wm2\"].rolling(window=12, min_periods=1).mean()\n",
    "df[\"flux_long_rolling_std_1h\"] = df[\"flux_long_wm2\"].rolling(window=12, min_periods=1).std()\n",
    "df[\"flux_long_delta\"] = df[\"flux_long_wm2\"].diff()\n",
    "hist = np.log10(df[\"flux_long_wm2\"].clip(lower=1e-9)).shift(1)  # t-1\n",
    "df[\"max_60\"]  = hist.rolling(60,  min_periods=3).max()\n",
    "df[\"mean_60\"] = hist.rolling(60,  min_periods=3).mean()\n",
    "df[\"max_180\"] = hist.rolling(180, min_periods=5).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75460774-e23c-48dc-8abe-e385a73ca394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Nettoyage des colonnes inutiles...\n",
      "âœ… Colonnes supprimÃ©es : ['satellite']\n",
      "âœ… Types harmonisÃ©s.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ§¹ Nettoyage des colonnes inutiles...\")\n",
    "colonnes_a_supprimer = [\"satellite\"] if \"satellite\" in df.columns else []\n",
    "df = df.drop(columns=colonnes_a_supprimer)\n",
    "print(f\"âœ… Colonnes supprimÃ©es : {colonnes_a_supprimer}\")\n",
    "\n",
    "# Harmonisation des types\n",
    "numeric_features = [\"flux_long_wm2\", \"flux_short_wm2\", \"hour\", \"minute_of_day\", \"dow\"]\n",
    "categorical_features = [\"source\", \"energy_long\", \"energy_short\"]\n",
    "\n",
    "for col in numeric_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "\n",
    "print(\"âœ… Types harmonisÃ©s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517ba1fb-bb83-418f-8fcd-984540f18440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Fichier sauvegardÃ© : C:\\Users\\gate\\Documents\\Jedha\\Projet\\4\\mlops-solar-flares\\data\\xrs_clean_ml.parquet\n"
     ]
    }
   ],
   "source": [
    "output_path = parquet_path.parent / \"xrs_clean_ml.parquet\"\n",
    "df.to_parquet(output_path, engine=\"pyarrow\", index=False)\n",
    "print(f\"ðŸ’¾ Fichier sauvegardÃ© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641183ee-39f5-40c6-941e-b3040f52e2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# head:                        time  flux_long_wm2  flux_short_wm2 energy_long  \\\n",
      "0 2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09  0.1-0.8 nm   \n",
      "1 2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09  0.1-0.8 nm   \n",
      "2 2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09  0.1-0.8 nm   \n",
      "3 2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09  0.1-0.8 nm   \n",
      "4 2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09  0.1-0.8 nm   \n",
      "\n",
      "  energy_short      source        date  hour  minute_of_day  dow  ...  \\\n",
      "0  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            0.0  3.0  ...   \n",
      "1  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            1.0  3.0  ...   \n",
      "2  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            2.0  3.0  ...   \n",
      "3  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            3.0  3.0  ...   \n",
      "4  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            4.0  3.0  ...   \n",
      "\n",
      "  flux_ratio_short_long  flux_diff_short_long  log_flux_long  log_flux_short  \\\n",
      "0              0.001424         -7.011782e-07      -6.153553            -9.0   \n",
      "1              0.001430         -6.984714e-07      -6.155230            -9.0   \n",
      "2              0.001418         -7.042154e-07      -6.151678            -9.0   \n",
      "3              0.001425         -7.005647e-07      -6.153932            -9.0   \n",
      "4              0.001436         -6.956016e-07      -6.157016            -9.0   \n",
      "\n",
      "   flux_long_rolling_mean_1h  flux_long_rolling_std_1h  flux_long_delta  \\\n",
      "0               7.021782e-07                       NaN              NaN   \n",
      "1               7.008248e-07              1.914016e-09    -2.706827e-09   \n",
      "2               7.022883e-07              2.873626e-09     5.744084e-09   \n",
      "3               7.021074e-07              2.374036e-09    -3.650712e-09   \n",
      "4               7.010063e-07              3.207776e-09    -4.963113e-09   \n",
      "\n",
      "     max_60   mean_60  max_180  \n",
      "0       NaN       NaN      NaN  \n",
      "1       NaN       NaN      NaN  \n",
      "2       NaN       NaN      NaN  \n",
      "3 -6.151678 -6.153487      NaN  \n",
      "4 -6.151678 -6.153598      NaN  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "# dtypes:\n",
      " time                         datetime64[ns, UTC]\n",
      "flux_long_wm2                            float64\n",
      "flux_short_wm2                           float64\n",
      "energy_long                       string[python]\n",
      "energy_short                      string[python]\n",
      "source                            string[python]\n",
      "date                              string[python]\n",
      "hour                                     float64\n",
      "minute_of_day                            float64\n",
      "dow                                      float64\n",
      "flare_class                               object\n",
      "day_of_year                                int16\n",
      "sin_doy                                  float64\n",
      "cos_doy                                  float64\n",
      "is_daytime                                  int8\n",
      "flux_ratio_short_long                    float32\n",
      "flux_diff_short_long                     float32\n",
      "log_flux_long                            float64\n",
      "log_flux_short                           float64\n",
      "flux_long_rolling_mean_1h                float64\n",
      "flux_long_rolling_std_1h                 float64\n",
      "flux_long_delta                          float32\n",
      "max_60                                   float64\n",
      "mean_60                                  float64\n",
      "max_180                                  float64\n",
      "dtype: object\n",
      "\n",
      "# describe:\n",
      "        flux_long_wm2  flux_short_wm2           hour  minute_of_day  \\\n",
      "count   1.459950e+05    1.459950e+05  147639.000000  147639.000000   \n",
      "mean    1.458551e-06    5.521534e-08      11.470872     717.749517   \n",
      "std     1.933292e-06    2.454070e-07       6.921239     415.635068   \n",
      "min     0.000000e+00    0.000000e+00       0.000000       0.000000   \n",
      "25%     7.571672e-07    1.000000e-09       5.000000     358.000000   \n",
      "50%     1.012731e-06    1.067018e-08      11.000000     716.000000   \n",
      "75%     1.448387e-06    3.325150e-08      17.000000    1078.000000   \n",
      "max     3.827447e-05    7.218636e-06      23.000000    1439.000000   \n",
      "\n",
      "                 dow    day_of_year        sin_doy        cos_doy  \\\n",
      "count  147639.000000  147639.000000  147639.000000  147639.000000   \n",
      "mean        3.043098     171.764757       0.162587      -0.860098   \n",
      "std         2.001092      29.597817       0.463188       0.138766   \n",
      "min         0.000000     121.000000      -0.640038      -0.999979   \n",
      "25%         1.000000     146.000000      -0.244772      -0.976509   \n",
      "50%         3.000000     172.000000       0.181760      -0.904405   \n",
      "75%         5.000000     197.000000       0.589176      -0.789905   \n",
      "max         6.000000     223.000000       0.872404      -0.488785   \n",
      "\n",
      "          is_daytime  flux_ratio_short_long  flux_diff_short_long  \\\n",
      "count  147639.000000          145826.000000          1.459950e+05   \n",
      "mean        0.541585               0.017432         -1.403336e-06   \n",
      "std         0.498269               0.021963          1.708289e-06   \n",
      "min         0.000000               0.000593         -3.177940e-05   \n",
      "25%         0.000000               0.001781         -1.418173e-06   \n",
      "50%         1.000000               0.010556         -1.000832e-06   \n",
      "75%         1.000000               0.024459         -7.508702e-07   \n",
      "max         1.000000               0.271675          0.000000e+00   \n",
      "\n",
      "       log_flux_long  log_flux_short  flux_long_rolling_mean_1h  \\\n",
      "count  145995.000000   145995.000000               1.460670e+05   \n",
      "mean       -5.951880       -8.051828               1.458326e-06   \n",
      "std         0.279030        0.793542               1.867544e-06   \n",
      "min        -9.000000       -9.000000               0.000000e+00   \n",
      "25%        -6.120808       -9.000000               7.612819e-07   \n",
      "50%        -5.994506       -7.971828               1.018668e-06   \n",
      "75%        -5.839115       -7.478189               1.455909e-06   \n",
      "max        -4.417091       -5.141545               3.793919e-05   \n",
      "\n",
      "       flux_long_rolling_std_1h  flux_long_delta         max_60  \\\n",
      "count              1.460580e+05     1.459800e+05  146204.000000   \n",
      "mean               1.255168e-07     2.717106e-11      -5.809509   \n",
      "std                5.044059e-07     2.306650e-07       0.336034   \n",
      "min                0.000000e+00    -6.468221e-06      -9.000000   \n",
      "25%                1.189654e-08    -1.140921e-08      -6.035817   \n",
      "50%                2.800016e-08    -2.431236e-09      -5.879467   \n",
      "75%                7.355538e-08     4.122896e-09      -5.662226   \n",
      "max                1.763178e-05     2.147228e-05      -4.417091   \n",
      "\n",
      "             mean_60        max_180  \n",
      "count  146204.000000  146366.000000  \n",
      "mean       -5.951833      -5.661165  \n",
      "std         0.256504       0.386181  \n",
      "min        -9.000000      -6.331707  \n",
      "25%        -6.114751      -5.938429  \n",
      "50%        -5.987386      -5.749202  \n",
      "75%        -5.840416      -5.468499  \n",
      "max        -4.600644      -4.417091  \n",
      "\n",
      "# missing (%):\n",
      "source                      8.32\n",
      "flux_ratio_short_long       1.23\n",
      "flux_long_delta             1.12\n",
      "flux_short_wm2              1.11\n",
      "log_flux_short              1.11\n",
      "flare_class                 1.11\n",
      "log_flux_long               1.11\n",
      "flux_long_wm2               1.11\n",
      "flux_diff_short_long        1.11\n",
      "flux_long_rolling_std_1h    1.07\n",
      "\n",
      "âœ… Aucune colonne entiÃ¨rement vide trouvÃ©e.\n",
      "\n",
      "# time range: 2025-05-01 00:00:00+00:00 -> 2025-08-11 12:38:00+00:00\n",
      "# time monotonic: True\n",
      "\n",
      "# last days (rows/day):\n",
      " time\n",
      "2025-08-02 00:00:00+00:00    1440\n",
      "2025-08-03 00:00:00+00:00    1440\n",
      "2025-08-04 00:00:00+00:00    1440\n",
      "2025-08-05 00:00:00+00:00    1440\n",
      "2025-08-06 00:00:00+00:00    1440\n",
      "2025-08-07 00:00:00+00:00    1440\n",
      "2025-08-08 00:00:00+00:00    1440\n",
      "2025-08-09 00:00:00+00:00    1440\n",
      "2025-08-10 00:00:00+00:00    1440\n",
      "2025-08-11 00:00:00+00:00     759\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flux_long_wm2</th>\n",
       "      <th>flux_short_wm2</th>\n",
       "      <th>energy_long</th>\n",
       "      <th>energy_short</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute_of_day</th>\n",
       "      <th>dow</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_ratio_short_long</th>\n",
       "      <th>flux_diff_short_long</th>\n",
       "      <th>log_flux_long</th>\n",
       "      <th>log_flux_short</th>\n",
       "      <th>flux_long_rolling_mean_1h</th>\n",
       "      <th>flux_long_rolling_std_1h</th>\n",
       "      <th>flux_long_delta</th>\n",
       "      <th>max_60</th>\n",
       "      <th>mean_60</th>\n",
       "      <th>max_180</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-01 00:00:00+00:00</td>\n",
       "      <td>7.021782e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>-7.011782e-07</td>\n",
       "      <td>-6.153553</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.021782e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-01 00:01:00+00:00</td>\n",
       "      <td>6.994713e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-6.984714e-07</td>\n",
       "      <td>-6.155230</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.008248e-07</td>\n",
       "      <td>1.914016e-09</td>\n",
       "      <td>-2.706827e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-01 00:02:00+00:00</td>\n",
       "      <td>7.052154e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>-7.042154e-07</td>\n",
       "      <td>-6.151678</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.022883e-07</td>\n",
       "      <td>2.873626e-09</td>\n",
       "      <td>5.744084e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-01 00:03:00+00:00</td>\n",
       "      <td>7.015647e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-7.005647e-07</td>\n",
       "      <td>-6.153932</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.021074e-07</td>\n",
       "      <td>2.374036e-09</td>\n",
       "      <td>-3.650712e-09</td>\n",
       "      <td>-6.151678</td>\n",
       "      <td>-6.153487</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-01 00:04:00+00:00</td>\n",
       "      <td>6.966016e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>-6.956016e-07</td>\n",
       "      <td>-6.157016</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.010063e-07</td>\n",
       "      <td>3.207776e-09</td>\n",
       "      <td>-4.963113e-09</td>\n",
       "      <td>-6.151678</td>\n",
       "      <td>-6.153598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147634</th>\n",
       "      <td>2025-08-11 12:34:00+00:00</td>\n",
       "      <td>5.304605e-06</td>\n",
       "      <td>5.942913e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>-4.710314e-06</td>\n",
       "      <td>-5.275347</td>\n",
       "      <td>-6.226001</td>\n",
       "      <td>2.810613e-06</td>\n",
       "      <td>1.091601e-06</td>\n",
       "      <td>8.360598e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.630177</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147635</th>\n",
       "      <td>2025-08-11 12:35:00+00:00</td>\n",
       "      <td>5.992305e-06</td>\n",
       "      <td>7.550105e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125997</td>\n",
       "      <td>-5.237294e-06</td>\n",
       "      <td>-5.222406</td>\n",
       "      <td>-6.122047</td>\n",
       "      <td>3.142742e-06</td>\n",
       "      <td>1.390251e-06</td>\n",
       "      <td>6.877003e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.624355</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147636</th>\n",
       "      <td>2025-08-11 12:36:00+00:00</td>\n",
       "      <td>6.500120e-06</td>\n",
       "      <td>8.529071e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131214</td>\n",
       "      <td>-5.647213e-06</td>\n",
       "      <td>-5.187079</td>\n",
       "      <td>-6.069098</td>\n",
       "      <td>3.517855e-06</td>\n",
       "      <td>1.638613e-06</td>\n",
       "      <td>5.078155e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.617594</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147637</th>\n",
       "      <td>2025-08-11 12:37:00+00:00</td>\n",
       "      <td>6.883591e-06</td>\n",
       "      <td>8.953128e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130065</td>\n",
       "      <td>-5.988278e-06</td>\n",
       "      <td>-5.162185</td>\n",
       "      <td>-6.048025</td>\n",
       "      <td>3.920874e-06</td>\n",
       "      <td>1.827872e-06</td>\n",
       "      <td>3.834707e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.610246</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147638</th>\n",
       "      <td>2025-08-11 12:38:00+00:00</td>\n",
       "      <td>7.047310e-06</td>\n",
       "      <td>8.543802e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121235</td>\n",
       "      <td>-6.192930e-06</td>\n",
       "      <td>-5.151977</td>\n",
       "      <td>-6.068349</td>\n",
       "      <td>4.328784e-06</td>\n",
       "      <td>1.940073e-06</td>\n",
       "      <td>1.637186e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.602539</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147639 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time  flux_long_wm2  flux_short_wm2 energy_long  \\\n",
       "0      2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09  0.1-0.8 nm   \n",
       "1      2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09  0.1-0.8 nm   \n",
       "2      2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09  0.1-0.8 nm   \n",
       "3      2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09  0.1-0.8 nm   \n",
       "4      2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09  0.1-0.8 nm   \n",
       "...                          ...            ...             ...         ...   \n",
       "147634 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07  0.1-0.8 nm   \n",
       "147635 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07  0.1-0.8 nm   \n",
       "147636 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07  0.1-0.8 nm   \n",
       "147637 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07  0.1-0.8 nm   \n",
       "147638 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07  0.1-0.8 nm   \n",
       "\n",
       "       energy_short      source        date  hour  minute_of_day  dow  ...  \\\n",
       "0       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            0.0  3.0  ...   \n",
       "1       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            1.0  3.0  ...   \n",
       "2       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            2.0  3.0  ...   \n",
       "3       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            3.0  3.0  ...   \n",
       "4       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            4.0  3.0  ...   \n",
       "...             ...         ...         ...   ...            ...  ...  ...   \n",
       "147634  0.05-0.4 nm        <NA>  2025-08-11  12.0          754.0  0.0  ...   \n",
       "147635  0.05-0.4 nm        <NA>  2025-08-11  12.0          755.0  0.0  ...   \n",
       "147636  0.05-0.4 nm        <NA>  2025-08-11  12.0          756.0  0.0  ...   \n",
       "147637  0.05-0.4 nm        <NA>  2025-08-11  12.0          757.0  0.0  ...   \n",
       "147638  0.05-0.4 nm        <NA>  2025-08-11  12.0          758.0  0.0  ...   \n",
       "\n",
       "       flux_ratio_short_long  flux_diff_short_long  log_flux_long  \\\n",
       "0                   0.001424         -7.011782e-07      -6.153553   \n",
       "1                   0.001430         -6.984714e-07      -6.155230   \n",
       "2                   0.001418         -7.042154e-07      -6.151678   \n",
       "3                   0.001425         -7.005647e-07      -6.153932   \n",
       "4                   0.001436         -6.956016e-07      -6.157016   \n",
       "...                      ...                   ...            ...   \n",
       "147634              0.112033         -4.710314e-06      -5.275347   \n",
       "147635              0.125997         -5.237294e-06      -5.222406   \n",
       "147636              0.131214         -5.647213e-06      -5.187079   \n",
       "147637              0.130065         -5.988278e-06      -5.162185   \n",
       "147638              0.121235         -6.192930e-06      -5.151977   \n",
       "\n",
       "        log_flux_short  flux_long_rolling_mean_1h  flux_long_rolling_std_1h  \\\n",
       "0            -9.000000               7.021782e-07                       NaN   \n",
       "1            -9.000000               7.008248e-07              1.914016e-09   \n",
       "2            -9.000000               7.022883e-07              2.873626e-09   \n",
       "3            -9.000000               7.021074e-07              2.374036e-09   \n",
       "4            -9.000000               7.010063e-07              3.207776e-09   \n",
       "...                ...                        ...                       ...   \n",
       "147634       -6.226001               2.810613e-06              1.091601e-06   \n",
       "147635       -6.122047               3.142742e-06              1.390251e-06   \n",
       "147636       -6.069098               3.517855e-06              1.638613e-06   \n",
       "147637       -6.048025               3.920874e-06              1.827872e-06   \n",
       "147638       -6.068349               4.328784e-06              1.940073e-06   \n",
       "\n",
       "        flux_long_delta    max_60   mean_60   max_180  \n",
       "0                   NaN       NaN       NaN       NaN  \n",
       "1         -2.706827e-09       NaN       NaN       NaN  \n",
       "2          5.744084e-09       NaN       NaN       NaN  \n",
       "3         -3.650712e-09 -6.151678 -6.153487       NaN  \n",
       "4         -4.963113e-09 -6.151678 -6.153598       NaN  \n",
       "...                 ...       ...       ...       ...  \n",
       "147634     8.360598e-07 -5.097139 -5.630177 -5.097139  \n",
       "147635     6.877003e-07 -5.097139 -5.624355 -5.097139  \n",
       "147636     5.078155e-07 -5.097139 -5.617594 -5.097139  \n",
       "147637     3.834707e-07 -5.097139 -5.610246 -5.097139  \n",
       "147638     1.637186e-07 -5.097139 -5.602539 -5.097139  \n",
       "\n",
       "[147639 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quickpeek(df, topn=10):\n",
    "\n",
    "    print(\"# head:\", df.head())\n",
    "    print(\"\\n# dtypes:\\n\", df.dtypes)\n",
    "    print(\"\\n# describe:\\n\", df.describe())\n",
    "\n",
    "    # missing %\n",
    "    print(\"\\n# missing (%):\")\n",
    "    miss = (df.isna().mean() * 100).round(2).sort_values(ascending=False)\n",
    "    print(miss.head(topn).to_string())\n",
    "\n",
    "    # ðŸ”¹ Suppression des colonnes entiÃ¨rement vides\n",
    "    colonnes_vides = df.columns[df.isna().all()].tolist()\n",
    "    if colonnes_vides:\n",
    "        print(f\"\\nðŸ—‘ Suppression de {len(colonnes_vides)} colonne(s) vide(s) : {colonnes_vides}\")\n",
    "        df.drop(columns=colonnes_vides, inplace=True)\n",
    "    else:\n",
    "        print(\"\\nâœ… Aucune colonne entiÃ¨rement vide trouvÃ©e.\")\n",
    "\n",
    "    if \"time\" in df:\n",
    "        # conversion robuste: tente direct, sinon passe par string\n",
    "        try:\n",
    "            t = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "        except Exception:\n",
    "            t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "        print(\"\\n# time range:\", t.min(), \"->\", t.max())\n",
    "        t_valid = t.dropna()\n",
    "        print(\"# time monotonic:\", t_valid.is_monotonic_increasing)\n",
    "\n",
    "        # comptage par jour\n",
    "        try:\n",
    "            per_day = t.dt.floor(\"D\").value_counts().sort_index()\n",
    "        except Exception:\n",
    "            if \"date\" in df.columns:\n",
    "                per_day = pd.to_datetime(df[\"date\"], errors=\"coerce\").value_counts().sort_index()\n",
    "            else:\n",
    "                per_day = pd.Series(dtype=\"int64\")\n",
    "\n",
    "        if len(per_day):\n",
    "            print(\"\\n# last days (rows/day):\\n\", per_day.tail(10).to_string())\n",
    "\n",
    "    return df  # On retourne le DataFrame propre\n",
    "quickpeek(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec80e1ff-3a26-4c12-8846-6c70a9e373c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Chargement du fichier xrs_clean_ml.parquet...\n",
      "âœ… DonnÃ©es chargÃ©es : 147639 lignes, 25 colonnes\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“¥ Chargement du fichier xrs_clean_ml.parquet...\")\n",
    "parquet_path = Path(r\"C:\\Users\\gate\\Documents\\Jedha\\Projet\\4\\mlops-solar-flares\\data\\xrs_clean_ml.parquet\")\n",
    "df = pd.read_parquet(parquet_path, engine=\"pyarrow\")\n",
    "print(f\"âœ… DonnÃ©es chargÃ©es : {df.shape[0]} lignes, {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb16736-ba0c-4a8f-ab2c-e9209cf66e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cible prÃªte.\n",
      "âœ‚ï¸ Split train/test (80/20, ordre temporel conservÃ©)...\n",
      "  - Train : 118111\n",
      "  - Test  : 29528\n",
      "âœ… Features sÃ©lectionnÃ©es (sans fuite) :\n",
      "  Num : ['flux_short_wm2', 'hour', 'minute_of_day', 'dow']\n",
      "  Cat : ['source', 'energy_long', 'energy_short']\n",
      "ðŸ§¹ Nettoyage des valeurs manquantes...\n",
      "  flux_short_wm2: mÃ©diane=0.000000\n",
      "  hour: mÃ©diane=11.000000\n",
      "  minute_of_day: mÃ©diane=719.000000\n",
      "  dow: mÃ©diane=3.000000\n",
      "  source: mode='NCEI-SunPy'\n",
      "  energy_long: mode='0.1-0.8 nm'\n",
      "  energy_short: mode='0.05-0.4 nm'\n",
      "âœ… DonnÃ©es nettoyÃ©es\n",
      "âš™ï¸ CrÃ©ation du preprocessor simplifiÃ©...\n",
      "ðŸ”„ Transformation des donnÃ©es...\n",
      "âœ… Transformation terminÃ©e. Shapes : (118111, 7) (29528, 7)\n",
      "ðŸŽ¯ PrÃ©paration des cibles...\n",
      "âœ… Encodage labels OK. Classes : ['A', 'B', 'C', 'M', 'X']\n",
      "   RÃ©partition train : {'B': 64972, 'C': 50460, 'M': 1054}\n",
      "   RÃ©partition test  : {'C': 22730, 'B': 6313, 'M': 297, 'A': 169}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cible \n",
    "# ============================\n",
    "def classify_flare(flux):\n",
    "    if pd.isna(flux): return None\n",
    "    elif flux < 1e-7: return \"A\"\n",
    "    elif flux < 1e-6: return \"B\"\n",
    "    elif flux < 1e-5: return \"C\"\n",
    "    elif flux < 1e-4: return \"M\"\n",
    "    else: return \"X\"\n",
    "\n",
    "if TARGET_NAME not in df.columns:\n",
    "    if \"flux_long_wm2\" not in df.columns:\n",
    "        raise KeyError(\"Colonne 'flux_long_wm2' manquante : impossible de construire la cible.\")\n",
    "    print(\"ðŸ›  CrÃ©ation de la variable cible 'flare_class' Ã  partir de flux_long_wm2...\")\n",
    "    df[TARGET_NAME] = df[\"flux_long_wm2\"].apply(classify_flare)\n",
    "print(\"âœ… Cible prÃªte.\")\n",
    "\n",
    "# ============================\n",
    "# Split temporel\n",
    "# ============================\n",
    "print(\"âœ‚ï¸ Split train/test (80/20, ordre temporel conservÃ©)...\")\n",
    "Y = df[TARGET_NAME].astype(\"string\")\n",
    "X = df.drop(columns=[TARGET_NAME])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=0, shuffle=False\n",
    ")\n",
    "print(f\"  - Train : {len(X_train)}\")\n",
    "print(f\"  - Test  : {len(X_test)}\")\n",
    "\n",
    "# ============================\n",
    "# DÃ©finition des features (âš ï¸ sans flux_long_wm2 pour Ã©viter la fuite)\n",
    "# ============================\n",
    "# Candidats habituels :\n",
    "numeric_features_all      = [\"flux_short_wm2\", \"hour\", \"minute_of_day\", \"dow\"]\n",
    "categorical_features_all  = [\"source\", \"energy_long\", \"energy_short\"]\n",
    "\n",
    "# Garder seulement celles qui existent rÃ©ellement\n",
    "numeric_features     = [c for c in numeric_features_all if c in X_train.columns]\n",
    "categorical_features = [c for c in categorical_features_all if c in X_train.columns]\n",
    "\n",
    "print(\"âœ… Features sÃ©lectionnÃ©es (sans fuite) :\")\n",
    "print(\"  Num :\", numeric_features)\n",
    "print(\"  Cat :\", categorical_features)\n",
    "\n",
    "# ============================\n",
    "# Nettoyage manuel des valeurs manquantes AVANT preprocessing\n",
    "# ============================\n",
    "print(\"ðŸ§¹ Nettoyage des valeurs manquantes...\")\n",
    "\n",
    "def clean_missing_values(X_train, X_test, numeric_cols, categorical_cols):\n",
    "    \"\"\"Nettoie manuellement les valeurs manquantes pour Ã©viter les bugs SimpleImputer\"\"\"\n",
    "    X_train_clean = X_train.copy()\n",
    "    X_test_clean = X_test.copy()\n",
    "    \n",
    "    # Pour les features numÃ©riques : remplacer par la mÃ©diane du train\n",
    "    for col in numeric_cols:\n",
    "        if col in X_train_clean.columns:\n",
    "            # Conversion en float64 propre\n",
    "            X_train_clean[col] = pd.to_numeric(X_train_clean[col], errors=\"coerce\")\n",
    "            X_test_clean[col] = pd.to_numeric(X_test_clean[col], errors=\"coerce\")\n",
    "            \n",
    "            # Calculer la mÃ©diane sur le train\n",
    "            median_val = X_train_clean[col].median()\n",
    "            if pd.isna(median_val):\n",
    "                median_val = 0.0  # fallback si tout est NaN\n",
    "            \n",
    "            # Remplacer les NaN\n",
    "            X_train_clean[col] = X_train_clean[col].fillna(median_val)\n",
    "            X_test_clean[col] = X_test_clean[col].fillna(median_val)\n",
    "            \n",
    "            print(f\"  {col}: mÃ©diane={median_val:.6f}\")\n",
    "    \n",
    "    # Pour les features catÃ©gorielles : remplacer par le mode du train\n",
    "    for col in categorical_cols:\n",
    "        if col in X_train_clean.columns:\n",
    "            # Conversion en object propre\n",
    "            X_train_clean[col] = X_train_clean[col].astype(str)\n",
    "            X_test_clean[col] = X_test_clean[col].astype(str)\n",
    "            \n",
    "            # Calculer le mode sur le train (ignorer les 'nan' string)\n",
    "            mode_candidates = X_train_clean[col][X_train_clean[col] != 'nan'].mode()\n",
    "            if len(mode_candidates) > 0:\n",
    "                mode_val = mode_candidates.iloc[0]\n",
    "            else:\n",
    "                mode_val = \"unknown\"  # fallback\n",
    "            \n",
    "            # Remplacer les NaN (maintenant string 'nan')\n",
    "            X_train_clean[col] = X_train_clean[col].replace('nan', mode_val)\n",
    "            X_test_clean[col] = X_test_clean[col].replace('nan', mode_val)\n",
    "            \n",
    "            print(f\"  {col}: mode='{mode_val}'\")\n",
    "    \n",
    "    return X_train_clean, X_test_clean\n",
    "\n",
    "# Appliquer le nettoyage\n",
    "X_train_clean, X_test_clean = clean_missing_values(\n",
    "    X_train, X_test, numeric_features, categorical_features\n",
    ")\n",
    "\n",
    "# Restreindre aux colonnes utiles (ordre fixe)\n",
    "X_train_final = X_train_clean[numeric_features + categorical_features].copy()\n",
    "X_test_final = X_test_clean[numeric_features + categorical_features].copy()\n",
    "\n",
    "print(\"âœ… DonnÃ©es nettoyÃ©es\")\n",
    "\n",
    "# ============================\n",
    "# PrÃ©processeur simplifiÃ© (sans SimpleImputer)\n",
    "# ============================\n",
    "print(\"âš™ï¸ CrÃ©ation du preprocessor simplifiÃ©...\")\n",
    "\n",
    "numeric_transformer = StandardScaler()  # Plus de SimpleImputer\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# Transformation\n",
    "# ============================\n",
    "print(\"ðŸ”„ Transformation des donnÃ©es...\")\n",
    "try:\n",
    "    X_train_t = preprocessor.fit_transform(X_train_final)\n",
    "    X_test_t  = preprocessor.transform(X_test_final)\n",
    "    print(\"âœ… Transformation terminÃ©e. Shapes :\", X_train_t.shape, X_test_t.shape)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur transformation: {e}\")\n",
    "    print(\"Debug - VÃ©rification des donnÃ©es:\")\n",
    "    print(\"X_train dtypes:\", X_train_final.dtypes.to_dict())\n",
    "    print(\"X_test dtypes:\", X_test_final.dtypes.to_dict())\n",
    "    \n",
    "    # VÃ©rifier s'il y a encore des NaN\n",
    "    for col in X_train_final.columns:\n",
    "        nan_count_train = X_train_final[col].isna().sum()\n",
    "        nan_count_test = X_test_final[col].isna().sum()\n",
    "        if nan_count_train > 0 or nan_count_test > 0:\n",
    "            print(f\"  {col}: {nan_count_train} NaN train, {nan_count_test} NaN test\")\n",
    "    raise\n",
    "\n",
    "# ============================\n",
    "# PrÃ©paration cibles & encodage labels\n",
    "# ============================\n",
    "print(\"ðŸŽ¯ PrÃ©paration des cibles...\")\n",
    "mask_train = Y_train.notna()\n",
    "mask_test  = Y_test.notna()\n",
    "\n",
    "Xtr = X_train_t[mask_train.values]\n",
    "Xte = X_test_t[mask_test.values]\n",
    "ytr = Y_train[mask_train].astype(str).values\n",
    "yte = Y_test[mask_test].astype(str).values\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(ALL_CLASSES)                 # mapping figÃ© A,B,C,M,X -> 0..4\n",
    "ytr_enc = le.transform(ytr)\n",
    "yte_enc = le.transform(yte)\n",
    "\n",
    "print(\"âœ… Encodage labels OK. Classes :\", list(le.classes_))\n",
    "print(\"   RÃ©partition train :\", pd.Series(ytr).value_counts().to_dict())\n",
    "print(\"   RÃ©partition test  :\", pd.Series(yte).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddbca5-84a0-470c-a68c-12cb3166ad12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f883845-e52d-478a-8e1f-f96e27eee6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066830b0-94a4-400c-b308-b114f8d3c4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207625e1-9101-486b-a5e0-61880a9afb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f4f65bf-e401-4135-a6b1-e2554322cbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === RECHARGER VOS DONNÃ‰ES / SPLITS ICI ===\n",
    "# Xtr, Xte, ytr_enc, yte_enc, ALL_CLASSES = ...\n",
    "\n",
    "# === Helpers (perdus au restart) ===\n",
    "def compact_labels(y):\n",
    "    present = np.unique(y)\n",
    "    to_compact  = {c:i for i,c in enumerate(present)}\n",
    "    to_original = {i:c for c,i in to_compact.items()}\n",
    "    y_comp = np.vectorize(to_compact.get)(y)\n",
    "    return y_comp, present, to_compact, to_original\n",
    "\n",
    "def remap_back(y_hat_comp, to_original):\n",
    "    return np.vectorize(to_original.get)(y_hat_comp)\n",
    "\n",
    "def evaluate_and_print(name, clf, Xtr, ytr_enc, Xte, yte_enc, present, to_original, ALL_CLASSES):\n",
    "    ytr_hat = remap_back(clf.predict(Xtr), to_original)\n",
    "    yte_hat = remap_back(clf.predict(Xte), to_original)\n",
    "\n",
    "    acc_tr  = accuracy_score(ytr_enc, ytr_hat)\n",
    "    bacc_tr = balanced_accuracy_score(ytr_enc, ytr_hat)\n",
    "    f1m_tr  = f1_score(ytr_enc, ytr_hat, average=\"macro\")\n",
    "    f1w_tr  = f1_score(ytr_enc, ytr_hat, average=\"weighted\")\n",
    "\n",
    "    acc_te  = accuracy_score(yte_enc, yte_hat)\n",
    "    bacc_te = balanced_accuracy_score(yte_enc, yte_hat)\n",
    "    f1m_te  = f1_score(yte_enc, yte_hat, average=\"macro\")\n",
    "    f1w_te  = f1_score(yte_enc, yte_hat, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n========== {name} ==========\")\n",
    "    print(\"ðŸ“Š Train :\", f\"acc={acc_tr:.4f} | bacc={bacc_tr:.4f} | f1m={f1m_tr:.4f} | f1w={f1w_tr:.4f}\")\n",
    "    print(\"ðŸ“Š Test  :\", f\"acc={acc_te:.4f} | bacc={bacc_te:.4f} | f1m={f1m_te:.4f} | f1w={f1w_te:.4f}\")\n",
    "\n",
    "    print(\"\\nðŸ§¾ Classification report (test)\")\n",
    "    print(classification_report(yte_enc, yte_hat,\n",
    "                                labels=np.arange(len(ALL_CLASSES)),\n",
    "                                target_names=ALL_CLASSES,\n",
    "                                zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(yte_enc, yte_hat, labels=np.arange(len(ALL_CLASSES)))\n",
    "    print(\"\\nðŸ§© Confusion matrix (counts)\\n\",\n",
    "          pd.DataFrame(cm, index=[f\"true_{c}\" for c in ALL_CLASSES],\n",
    "                          columns=[f\"pred_{c}\" for c in ALL_CLASSES]).to_string())\n",
    "\n",
    "    row_sums = cm.sum(axis=1, keepdims=True)\n",
    "    cmn = np.divide(cm, row_sums, out=np.zeros_like(cm, dtype=float), where=row_sums!=0)\n",
    "    print(\"\\nðŸ§© Confusion matrix (per-class)\\n\",\n",
    "          pd.DataFrame(cmn, index=[f\"true_{c}\" for c in ALL_CLASSES],\n",
    "                            columns=[f\"pred_{c}\" for c in ALL_CLASSES]).round(3).to_string())\n",
    "\n",
    "    return {\"acc_train\":acc_tr,\"bacc_train\":bacc_tr,\"f1m_train\":f1m_tr,\"f1w_train\":f1w_tr,\n",
    "            \"acc_test\":acc_te,\"bacc_test\":bacc_te,\"f1m_test\":f1m_te,\"f1w_test\":f1w_te}, yte_hat\n",
    "\n",
    "# === Objets communs recrÃ©Ã©s Ã  chaque fois ===\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_enc)\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# === Conteneurs de rÃ©sultats ===\n",
    "results_list = []    # tableaux de scores\n",
    "fitted_pool  = {}    # modÃ¨les entraÃ®nÃ©s + mapping\n",
    "\n",
    "def add_model_result(name, clf, present, to_original, res_dict, yhat):\n",
    "    results_list.append({\"model\": name, **res_dict})\n",
    "    fitted_pool[name] = (clf, to_original, present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09799604-92b2-43b7-9fa3-a2bf89b35d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 0) PrÃ©paration conteneurs pour tous les modÃ¨les\n",
    "# ==========================================================\n",
    "results_list = []       # stocke les dicts avec les scores\n",
    "fitted_pool = {}        # stocke les modÃ¨les entraÃ®nÃ©s + mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f3e1fa-69a1-412d-8fbd-3dfd86cb912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 1) Fonction d'ajout d'un modÃ¨le dans les pools\n",
    "# ==========================================================\n",
    "def add_model_result(name, clf, present, to_original, res_dict, yte_hat):\n",
    "    results_list.append(res_dict)\n",
    "    fitted_pool[name] = (clf, to_original, present)  # on garde aussi \"present\" pour prÃ©dictions futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83567fd-76bd-4d3b-bd85-b8e41b96bbb2",
   "metadata": {},
   "source": [
    "_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5af2ab-6f24-47cc-be10-93d806f1aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== LogisticRegression ==========\n",
      "ðŸ“Š Train : acc=0.8285 | bacc=0.8756 | f1m=0.7997 | f1w=0.8271\n",
      "ðŸ“Š Test  : acc=0.6399 | bacc=0.6214 | f1m=0.4321 | f1w=0.6664\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.38      0.92      0.54      6313\n",
      "           C       0.96      0.56      0.71     22730\n",
      "           M       0.32      1.00      0.48       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64     29509\n",
      "   macro avg       0.33      0.50      0.35     29509\n",
      "weighted avg       0.83      0.64      0.67     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5839     474       0       0\n",
      "true_C       0    9340   12747     643       0\n",
      "true_M       0       0       0     297       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.925   0.075   0.000     0.0\n",
      "true_C     0.0   0.411   0.561   0.028     0.0\n",
      "true_M     0.0   0.000   0.000   1.000     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 2) Logistic Regression\n",
    "# ==========================================================\n",
    "ytr_comp, present_lr, to_compact_lr, to_original_lr = compact_labels(ytr_enc)\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"lbfgs\")\n",
    "logreg.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_lr, yhat_lr = evaluate_and_print(\"LogisticRegression\", logreg, Xtr, ytr_enc, Xte, yte_enc,\n",
    "                                     present_lr, to_original_lr, ALL_CLASSES)\n",
    "add_model_result(\"LogisticRegression\", logreg, present_lr, to_original_lr, res_lr, yhat_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "709d4a30-2275-4646-848f-8b9d1a19dbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR best params: {'C': 2.0, 'class_weight': None} best CV f1_macro: 0.7996\n",
      "\n",
      "========== LogisticRegression (tuned) ==========\n",
      "ðŸ“Š Train : acc=0.8286 | bacc=0.8757 | f1m=0.7999 | f1w=0.8272\n",
      "ðŸ“Š Test  : acc=0.6407 | bacc=0.6216 | f1m=0.4322 | f1w=0.6672\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.38      0.92      0.54      6313\n",
      "           C       0.96      0.56      0.71     22730\n",
      "           M       0.31      1.00      0.48       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64     29509\n",
      "   macro avg       0.33      0.50      0.35     29509\n",
      "weighted avg       0.83      0.64      0.67     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5835     478       0       0\n",
      "true_C       0    9310   12774     646       0\n",
      "true_M       0       0       0     297       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.924   0.076   0.000     0.0\n",
      "true_C     0.0   0.410   0.562   0.028     0.0\n",
      "true_M     0.0   0.000   0.000   1.000     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 2) Logistic Regression (tuned)\n",
    "# ==========================================================\n",
    "# 1) Compactage des labels (gÃ¨re classes absentes)\n",
    "ytr_comp, present_lr, to_compact_lr, to_original_lr = compact_labels(ytr_enc)\n",
    "\n",
    "# 2) PondÃ©ration des classes sur labels compactÃ©s\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_comp)\n",
    "\n",
    "# 3) ModÃ¨le de base (multinomial)\n",
    "lr_base = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    multi_class=\"auto\",\n",
    "    n_jobs=None,           # (lbfgs n'accepte pas n_jobs)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4) CV 3-fold\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 5) Petite grille directionnelle (sobre)\n",
    "grid_lr = {\n",
    "    \"C\": [0.5, 1.0, 2.0],           # force/relÃ¢che la rÃ©gularisation L2\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "# 6) GridSearchCV\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=lr_base,\n",
    "    param_grid=grid_lr,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 7) Fit avec sample_weight\n",
    "gs_lr.fit(Xtr, ytr_comp, sample_weight=sample_weight_tr)\n",
    "\n",
    "# 8) RÃ©sultats de la recherche\n",
    "print(\"LR best params:\", gs_lr.best_params_,\n",
    "      \"best CV f1_macro:\", round(gs_lr.best_score_, 4))\n",
    "\n",
    "# 9) Refit final + Ã©valuation\n",
    "lr_best = gs_lr.best_estimator_\n",
    "res_lr, yhat_lr = evaluate_and_print(\n",
    "    \"LogisticRegression (tuned)\",\n",
    "    lr_best,\n",
    "    Xtr, ytr_enc,\n",
    "    Xte, yte_enc,\n",
    "    present_lr, to_original_lr, ALL_CLASSES\n",
    ")\n",
    "\n",
    "# 10) Stockage pour comparatif global\n",
    "add_model_result(\"LogisticRegression (tuned)\",\n",
    "                 lr_best, present_lr, to_original_lr,\n",
    "                 res_lr, yhat_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "497adac9-adc8-4999-956f-5b2118d612b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== DecisionTree ==========\n",
      "ðŸ“Š Train : acc=0.9843 | bacc=0.9880 | f1m=0.9892 | f1w=0.9842\n",
      "ðŸ“Š Test  : acc=0.6941 | bacc=0.5513 | f1m=0.5123 | f1w=0.7181\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.40      0.81      0.54      6313\n",
      "           C       0.92      0.67      0.77     22730\n",
      "           M       0.75      0.73      0.74       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.69     29509\n",
      "   macro avg       0.42      0.44      0.41     29509\n",
      "weighted avg       0.80      0.69      0.72     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5126    1187       0       0\n",
      "true_C       0    7519   15140      71       0\n",
      "true_M       0       0      81     216       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.812   0.188   0.000     0.0\n",
      "true_C     0.0   0.331   0.666   0.003     0.0\n",
      "true_M     0.0   0.000   0.273   0.727     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 3) Decision Tree\n",
    "# ==========================================================\n",
    "ytr_comp, present_dt, to_compact_dt, to_original_dt = compact_labels(ytr_enc)\n",
    "dt = DecisionTreeClassifier(class_weight=\"balanced\", random_state=0)\n",
    "dt.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_dt, yhat_dt = evaluate_and_print(\"DecisionTree\", dt, Xtr, ytr_enc, Xte, yte_enc,\n",
    "                                     present_dt, to_original_dt, ALL_CLASSES)\n",
    "add_model_result(\"DecisionTree\", dt, present_dt, to_original_dt, res_dt, yhat_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb66605f-5f0b-48fc-a8a9-db12707c893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT best params: {'ccp_alpha': 0.0, 'max_depth': None, 'min_samples_leaf': 1} best CV f1_macro: 0.8673\n",
      "\n",
      "========== DecisionTree (tuned) ==========\n",
      "ðŸ“Š Train : acc=0.9842 | bacc=0.9879 | f1m=0.9892 | f1w=0.9842\n",
      "ðŸ“Š Test  : acc=0.6933 | bacc=0.5535 | f1m=0.5142 | f1w=0.7174\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.40      0.82      0.54      6313\n",
      "           C       0.92      0.66      0.77     22730\n",
      "           M       0.76      0.73      0.75       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.69     29509\n",
      "   macro avg       0.42      0.44      0.41     29509\n",
      "weighted avg       0.80      0.69      0.72     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5152    1161       0       0\n",
      "true_C       0    7573   15089      68       0\n",
      "true_M       0       0      79     218       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.816   0.184   0.000     0.0\n",
      "true_C     0.0   0.333   0.664   0.003     0.0\n",
      "true_M     0.0   0.000   0.266   0.734     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 3) Decision Tree (tuned)\n",
    "# ==========================================================\n",
    "# PondÃ©ration des Ã©chantillons (Ã©quilibrage des classes)\n",
    "# 1) DÃ©finir le modÃ¨le + grille AVANT de crÃ©er gs_dt\n",
    "dt = DecisionTreeClassifier(class_weight=\"balanced\", random_state=0)\n",
    "grid_dt = {\n",
    "    \"max_depth\": [None, 12, 8, 5],\n",
    "    \"min_samples_leaf\": [1, 5, 20],\n",
    "    \"ccp_alpha\": [0.0, 1e-4, 5e-4]\n",
    "}\n",
    "\n",
    "# 2) CrÃ©er gs_dt\n",
    "gs_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=grid_dt,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 3) Fit (maintenant gs_dt existe bien)\n",
    "gs_dt.fit(Xtr, ytr_enc, sample_weight=sample_weight_tr)\n",
    "print(\"DT best params:\", gs_dt.best_params_, \"best CV f1_macro:\", round(gs_dt.best_score_,4))\n",
    "\n",
    "# 4) Refit final + report\n",
    "dt_best = gs_dt.best_estimator_\n",
    "res_dt, yhat_dt = evaluate_and_print(\n",
    "    \"DecisionTree (tuned)\", dt_best,\n",
    "    Xtr, ytr_enc, Xte, yte_enc,\n",
    "    present=np.unique(ytr_enc),\n",
    "    to_original={i:i for i in range(len(ALL_CLASSES))},\n",
    "    ALL_CLASSES=ALL_CLASSES\n",
    ")\n",
    "add_model_result(\"DecisionTree (tuned)\", dt_best, np.unique(ytr_enc),\n",
    "                 {i:i for i in range(len(ALL_CLASSES))}, res_dt, yhat_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f334c8dc-82f0-46e1-938a-d328837d6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== RandomForest ==========\n",
      "ðŸ“Š Train : acc=0.9843 | bacc=0.9880 | f1m=0.9892 | f1w=0.9842\n",
      "ðŸ“Š Test  : acc=0.6993 | bacc=0.4442 | f1m=0.4285 | f1w=0.7212\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.41      0.83      0.55      6313\n",
      "           C       0.92      0.67      0.78     22730\n",
      "           M       0.68      0.27      0.39       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.70     29509\n",
      "   macro avg       0.40      0.36      0.34     29509\n",
      "weighted avg       0.81      0.70      0.72     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5270    1043       0       0\n",
      "true_C       0    7405   15287      38       0\n",
      "true_M       0       0     217      80       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.835   0.165   0.000     0.0\n",
      "true_C     0.0   0.326   0.673   0.002     0.0\n",
      "true_M     0.0   0.000   0.731   0.269     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 4) Random Forest \n",
    "# ==========================================================\n",
    "ytr_comp, present_rf, to_compact_rf, to_original_rf = compact_labels(ytr_enc)\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", n_jobs=-1, random_state=0)\n",
    "rf.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_rf, yhat_rf = evaluate_and_print(\"RandomForest\", rf, Xtr, ytr_enc, Xte, yte_enc,\n",
    "                                     present_rf, to_original_rf, ALL_CLASSES)\n",
    "add_model_result(\"RandomForest\", rf, present_rf, to_original_rf, res_rf, yhat_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ef8ce86-eb69-4443-80e3-2e6ba7467459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF best params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 200} best CV f1_macro: 0.9032\n",
      "\n",
      "========== RandomForest (tuned) ==========\n",
      "ðŸ“Š Train : acc=0.9620 | bacc=0.9735 | f1m=0.9664 | f1w=0.9619\n",
      "ðŸ“Š Test  : acc=0.7097 | bacc=0.4790 | f1m=0.4615 | f1w=0.7310\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.42      0.82      0.56      6313\n",
      "           C       0.92      0.69      0.79     22730\n",
      "           M       0.66      0.40      0.50       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.71     29509\n",
      "   macro avg       0.40      0.38      0.37     29509\n",
      "weighted avg       0.81      0.71      0.73     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5208    1105       0       0\n",
      "true_C       0    7053   15616      61       0\n",
      "true_M       0       0     177     120       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.825   0.175   0.000     0.0\n",
      "true_C     0.0   0.310   0.687   0.003     0.0\n",
      "true_M     0.0   0.000   0.596   0.404     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 4) Random Forest (tuned)\n",
    "# ==========================================================\n",
    "# PondÃ©ration des Ã©chantillons (Ã©quilibrage des classes)\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_enc)\n",
    "\n",
    "# ModÃ¨le de base\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation 3-fold stratifiÃ©e\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Petite grille \"directionnelle\" (Ã©largis si besoin)\n",
    "grid_rf = {\n",
    "    \"n_estimators\": [200,],\n",
    "    \"max_depth\": [None, 5,],\n",
    "    \"min_samples_leaf\": [1,2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]  # ou None si tu veux tester\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=grid_rf,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit avec pondÃ©ration des classes\n",
    "gs_rf.fit(Xtr, ytr_enc, sample_weight=sample_weight_tr)\n",
    "\n",
    "# RÃ©sultats de la recherche\n",
    "print(\"RF best params:\", gs_rf.best_params_,\n",
    "      \"best CV f1_macro:\", round(gs_rf.best_score_, 4))\n",
    "\n",
    "# Refit final + Ã©valuation\n",
    "rf_best = gs_rf.best_estimator_\n",
    "res_rf, yhat_rf = evaluate_and_print(\n",
    "    \"RandomForest (tuned)\",\n",
    "    rf_best,\n",
    "    Xtr, ytr_enc,\n",
    "    Xte, yte_enc,\n",
    "    present=np.unique(ytr_enc),\n",
    "    to_original={i: i for i in range(len(ALL_CLASSES))},\n",
    "    ALL_CLASSES=ALL_CLASSES\n",
    ")\n",
    "\n",
    "# Stockage pour comparaison ultÃ©rieure (si tu utilises ce helper)\n",
    "add_model_result(\n",
    "    \"RandomForest (tuned)\",\n",
    "    rf_best,\n",
    "    np.unique(ytr_enc),\n",
    "    {i: i for i in range(len(ALL_CLASSES))},\n",
    "    res_rf,\n",
    "    yhat_rf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98e43fee-b225-418a-bc1d-65f1a7edd581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== GradientBoosting ==========\n",
      "ðŸ“Š Train : acc=0.8611 | bacc=0.8759 | f1m=0.8812 | f1w=0.8609\n",
      "ðŸ“Š Test  : acc=0.7382 | bacc=0.6036 | f1m=0.5546 | f1w=0.7583\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.45      0.89      0.60      6313\n",
      "           C       0.96      0.70      0.81     22730\n",
      "           M       0.81      0.82      0.81       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.74     29509\n",
      "   macro avg       0.44      0.48      0.44     29509\n",
      "weighted avg       0.84      0.74      0.76     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5641     672       0       0\n",
      "true_C       0    6772   15899      59       0\n",
      "true_M       0       0      53     244       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.894   0.106   0.000     0.0\n",
      "true_C     0.0   0.298   0.699   0.003     0.0\n",
      "true_M     0.0   0.000   0.178   0.822     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 5) Gradient Boosting \n",
    "# ==========================================================\n",
    "ytr_comp, present_gb, to_compact_gb, to_original_gb = compact_labels(ytr_enc)\n",
    "gb = GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "gb.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_gb, yhat_gb = evaluate_and_print(\"GradientBoosting\", gb, Xtr, ytr_enc, Xte, yte_enc,\n",
    "                                     present_gb, to_original_gb, ALL_CLASSES)\n",
    "add_model_result(\"GradientBoosting\", gb, present_gb, to_original_gb, res_gb, yhat_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dd3ddc3-9d69-4a1f-a727-64b9e6df406d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB best params: {'learning_rate': 0.2, 'max_depth': 8, 'n_estimators': 100} best CV f1_macro: 0.8883\n",
      "\n",
      "========== GradientBoosting (tuned) ==========\n",
      "ðŸ“Š Train : acc=0.9236 | bacc=0.9476 | f1m=0.9478 | f1w=0.9236\n",
      "ðŸ“Š Test  : acc=0.7244 | bacc=0.5745 | f1m=0.5265 | f1w=0.7450\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.43      0.84      0.57      6313\n",
      "           C       0.93      0.70      0.80     22730\n",
      "           M       0.71      0.76      0.74       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72     29509\n",
      "   macro avg       0.42      0.46      0.42     29509\n",
      "weighted avg       0.82      0.72      0.75     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5274    1039       0       0\n",
      "true_C       0    6764   15874      92       0\n",
      "true_M       0       0      70     227       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.835   0.165   0.000     0.0\n",
      "true_C     0.0   0.298   0.698   0.004     0.0\n",
      "true_M     0.0   0.000   0.236   0.764     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 5) Gradient Boosting (tuned)\n",
    "# ==========================================================\n",
    "# PondÃ©ration des Ã©chantillons (Ã©quilibrage des classes)\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_enc)\n",
    "\n",
    "# ModÃ¨le de base (proche de ce qui marchait le mieux chez toi)\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation 3-fold stratifiÃ©e\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Petite grille \"directionnelle\" (Ã©largis si besoin)\n",
    "grid_gb = {\n",
    "    \"n_estimators\":  [50, 100],\n",
    "    \"learning_rate\": [0.2,0.4],\n",
    "    \"max_depth\":     [4,6,8],\n",
    "    # optionnel :\n",
    "    # \"subsample\":     [1.0, 0.8],\n",
    "    # \"max_features\":  [\"sqrt\", None],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "gs_gb = GridSearchCV(\n",
    "    estimator=gb,\n",
    "    param_grid=grid_gb,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit avec pondÃ©ration des classes\n",
    "gs_gb.fit(Xtr, ytr_enc, sample_weight=sample_weight_tr)\n",
    "\n",
    "# RÃ©sultats de la recherche\n",
    "print(\"GB best params:\", gs_gb.best_params_,\n",
    "      \"best CV f1_macro:\", round(gs_gb.best_score_, 4))\n",
    "\n",
    "# Refit final + Ã©valuation (mapping identitÃ© car on est dÃ©jÃ  sur 0..4)\n",
    "gb_best = gs_gb.best_estimator_\n",
    "res_gb, yhat_gb = evaluate_and_print(\n",
    "    \"GradientBoosting (tuned)\",\n",
    "    gb_best,\n",
    "    Xtr, ytr_enc,\n",
    "    Xte, yte_enc,\n",
    "    present=np.unique(ytr_enc),\n",
    "    to_original={i: i for i in range(len(ALL_CLASSES))},\n",
    "    ALL_CLASSES=ALL_CLASSES\n",
    ")\n",
    "\n",
    "# Stockage pour comparaison ultÃ©rieure\n",
    "add_model_result(\"GradientBoosting (tuned)\", gb_best,\n",
    "                 np.unique(ytr_enc),\n",
    "                 {i: i for i in range(len(ALL_CLASSES))},\n",
    "                 res_gb, yhat_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58e504d3-75ba-4444-9755-7259b527198f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== XGBoost ==========\n",
      "ðŸ“Š Train : acc=0.8799 | bacc=0.9068 | f1m=0.9063 | f1w=0.8795\n",
      "ðŸ“Š Test  : acc=0.7191 | bacc=0.5690 | f1m=0.5354 | f1w=0.7412\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.43      0.88      0.58      6313\n",
      "           C       0.95      0.68      0.79     22730\n",
      "           M       0.84      0.71      0.77       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72     29509\n",
      "   macro avg       0.44      0.46      0.43     29509\n",
      "weighted avg       0.83      0.72      0.74     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5577     736       0       0\n",
      "true_C       0    7258   15432      40       0\n",
      "true_M       0       0      85     212       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.883   0.117   0.000     0.0\n",
      "true_C     0.0   0.319   0.679   0.002     0.0\n",
      "true_M     0.0   0.000   0.286   0.714     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 6) XGBoost \n",
    "# ==========================================================\n",
    "ytr_comp, present_xgb, to_compact_xgb, to_original_xgb = compact_labels(ytr_enc)\n",
    "k = len(present_xgb)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    num_class=k,\n",
    "    n_jobs=-1,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "xgb.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_xgb, yhat_xgb = evaluate_and_print(\n",
    "    \"XGBoost\", xgb, Xtr, ytr_enc, Xte, yte_enc,\n",
    "    present_xgb, to_original_xgb, ALL_CLASSES\n",
    ")\n",
    "\n",
    "add_model_result(\"XGBoost\", xgb, present_xgb, to_original_xgb, res_xgb, yhat_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "976fabd0-7d95-45e9-9644-41995d992df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB best params: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8} best CV f1_macro: 0.8927\n",
      "\n",
      "========== XGBoost (tuned) ==========\n",
      "ðŸ“Š Train : acc=0.8805 | bacc=0.9187 | f1m=0.9059 | f1w=0.8805\n",
      "ðŸ“Š Test  : acc=0.7379 | bacc=0.6045 | f1m=0.5442 | f1w=0.7574\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.45      0.85      0.59      6313\n",
      "           C       0.94      0.71      0.81     22730\n",
      "           M       0.72      0.86      0.78       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.74     29509\n",
      "   macro avg       0.42      0.48      0.44     29509\n",
      "weighted avg       0.83      0.74      0.76     29509\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5382     931       0       0\n",
      "true_C       0    6490   16140     100       0\n",
      "true_M       0       0      43     254       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.853   0.147   0.000     0.0\n",
      "true_C     0.0   0.286   0.710   0.004     0.0\n",
      "true_M     0.0   0.000   0.145   0.855     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 6) XGBoost (si dispo)\n",
    "# ==========================================================\n",
    "# 1) Compactage des labels (gÃ¨re classes absentes)\n",
    "ytr_comp, present_xgb, to_compact_xgb, to_original_xgb = compact_labels(ytr_enc)\n",
    "k = len(present_xgb)\n",
    "\n",
    "# 2) PondÃ©ration des classes sur les labels compactÃ©s\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_comp)\n",
    "\n",
    "# 3) ModÃ¨le de base\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    num_class=k,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4) CV 3-fold\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 5) Petite grille directionnelle (rapide)\n",
    "grid_xgb = {\n",
    "    \"n_estimators\":      [150, 200],\n",
    "    \"max_depth\":         [4, 6],\n",
    "    \"learning_rate\":     [0.05, 0.1],\n",
    "    \"subsample\":         [0.8, 1.0],\n",
    "    \"colsample_bytree\":  [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# 6) GridSearchCV\n",
    "gs_xgb = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=grid_xgb,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 7) Fit avec sample_weight\n",
    "gs_xgb.fit(Xtr, ytr_comp, sample_weight=sample_weight_tr)\n",
    "\n",
    "# 8) RÃ©sultats de la recherche\n",
    "print(\"XGB best params:\", gs_xgb.best_params_,\n",
    "      \"best CV f1_macro:\", round(gs_xgb.best_score_, 4))\n",
    "\n",
    "# 9) Refit final + Ã©valuation\n",
    "xgb_best = gs_xgb.best_estimator_\n",
    "res_xgb, yhat_xgb = evaluate_and_print(\n",
    "    \"XGBoost (tuned)\",\n",
    "    xgb_best,\n",
    "    Xtr, ytr_enc,\n",
    "    Xte, yte_enc,\n",
    "    present_xgb,\n",
    "    to_original_xgb,\n",
    "    ALL_CLASSES\n",
    ")\n",
    "\n",
    "# 10) Stockage pour comparatif global\n",
    "add_model_result(\"XGBoost (tuned)\",\n",
    "                 xgb_best,\n",
    "                 present_xgb,\n",
    "                 to_original_xgb,\n",
    "                 res_xgb,\n",
    "                 yhat_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "066500bb-6209-439a-8293-0b59189bbc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ Tableau comparatif (tri par F1-macro test) :\n",
      "                     model  acc_train  bacc_train  f1m_train  f1w_train  acc_test  bacc_test  f1m_test  f1w_test\n",
      "          GradientBoosting   0.861142    0.875911   0.881204   0.860869  0.738215   0.603643  0.554605  0.758304\n",
      "           XGBoost (tuned)   0.880475    0.918658   0.905948   0.880514  0.737944   0.604455  0.544241  0.757364\n",
      "                   XGBoost   0.879917    0.906753   0.906282   0.879519  0.719137   0.569037  0.535365  0.741151\n",
      "  GradientBoosting (tuned)   0.923596    0.947636   0.947752   0.923580  0.724355   0.574525  0.526499  0.745048\n",
      "      DecisionTree (tuned)   0.984196    0.987945   0.989154   0.984162  0.693314   0.553484  0.514238  0.717430\n",
      "              DecisionTree   0.984281    0.987967   0.989211   0.984247  0.694093   0.551332  0.512349  0.718053\n",
      "      RandomForest (tuned)   0.961961    0.973518   0.966360   0.961929  0.709750   0.479007  0.461487  0.731018\n",
      "LogisticRegression (tuned)   0.828597    0.875722   0.799886   0.827209  0.640686   0.621568  0.432164  0.667172\n",
      "        LogisticRegression   0.828529    0.875581   0.799701   0.827093  0.639906   0.621429  0.432113  0.666396\n",
      "              RandomForest   0.984281    0.987950   0.989211   0.984247  0.699346   0.444173  0.428538  0.721181\n",
      "\n",
      "â­ Meilleur modÃ¨le du run : GradientBoosting\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Tableau comparatif final\n",
    "# ==========================\n",
    "def build_leaderboard():\n",
    "    # 1) Source prioritaire: results_table (contient dÃ©jÃ  \"model\")\n",
    "    if \"results_table\" in globals() and isinstance(results_table, list) and len(results_table) > 0:\n",
    "        df = pd.DataFrame(results_table)\n",
    "    # 2) Sinon, on tente de reconstruire avec fitted_pool + results_list\n",
    "    elif (\"results_list\" in globals() and isinstance(results_list, list) and len(results_list) > 0\n",
    "          and \"fitted_pool\" in globals() and isinstance(fitted_pool, dict) and len(fitted_pool) > 0):\n",
    "        model_names = list(fitted_pool.keys())\n",
    "        m = min(len(model_names), len(results_list))\n",
    "        df = pd.DataFrame([{\"model\": model_names[i], **results_list[i]} for i in range(m)])\n",
    "    else:\n",
    "        print(\"âš ï¸ Aucun rÃ©sultat Ã  afficher (results_table/results_list vides).\")\n",
    "        return\n",
    "\n",
    "    df = df.sort_values([\"f1m_test\", \"bacc_test\", \"acc_test\"], ascending=False).reset_index(drop=True)\n",
    "    print(\"\\nðŸ Tableau comparatif (tri par F1-macro test) :\")\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    if \"model\" in df.columns:\n",
    "        best_name = df.iloc[0][\"model\"]\n",
    "        print(f\"\\nâ­ Meilleur modÃ¨le du run : {best_name}\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Colonne 'model' absente : pense Ã  utiliser add_model_result(...) dans chaque bloc.\")\n",
    "\n",
    "build_leaderboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d916773-28ca-42ff-95d4-63e2b6ceb865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ LogisticRegression â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 01:11:00+00:00     M       31\n",
      "2025-08-11 01:12:00+00:00 2025-08-11 01:16:00+00:00     C        5\n",
      "2025-08-11 01:17:00+00:00 2025-08-11 01:27:00+00:00     M       11\n",
      "2025-08-11 01:28:00+00:00 2025-08-11 03:03:00+00:00     C       96\n",
      "2025-08-11 03:04:00+00:00 2025-08-11 03:09:00+00:00     M        6\n",
      "2025-08-11 03:10:00+00:00 2025-08-11 03:46:00+00:00     C       37\n",
      "2025-08-11 03:47:00+00:00 2025-08-11 04:03:00+00:00     M       17\n",
      "2025-08-11 04:04:00+00:00 2025-08-11 04:55:00+00:00     C       52\n",
      "2025-08-11 04:56:00+00:00 2025-08-11 05:01:00+00:00     M        6\n",
      "2025-08-11 05:02:00+00:00 2025-08-11 05:30:00+00:00     C       29\n",
      "2025-08-11 05:31:00+00:00 2025-08-11 05:42:00+00:00     M       12\n",
      "2025-08-11 05:43:00+00:00 2025-08-11 06:02:00+00:00     C       20\n",
      "2025-08-11 06:03:00+00:00 2025-08-11 06:14:00+00:00     M       12\n",
      "2025-08-11 06:15:00+00:00 2025-08-11 08:37:00+00:00     C      143\n",
      "2025-08-11 08:38:00+00:00 2025-08-11 08:54:00+00:00     M       17\n",
      "2025-08-11 08:55:00+00:00 2025-08-11 10:33:00+00:00     C       99\n",
      "2025-08-11 10:34:00+00:00 2025-08-11 10:39:00+00:00     M        6\n",
      "2025-08-11 10:40:00+00:00 2025-08-11 10:52:00+00:00     C       13\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:55:00+00:00     M        3\n",
      "2025-08-11 10:56:00+00:00 2025-08-11 11:43:00+00:00     C       48\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:33:00+00:00     C       48\n",
      "2025-08-11 12:34:00+00:00 2025-08-11 12:38:00+00:00     M        5\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    590\n",
      "M    128\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.013\n",
      "C    0.766\n",
      "M    0.220\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 82.17%\n",
      " - M: 17.83%\n",
      " - X: 0.00%\n",
      "\n",
      "================ LogisticRegression (tuned) â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 01:11:00+00:00     M       31\n",
      "2025-08-11 01:12:00+00:00 2025-08-11 01:16:00+00:00     C        5\n",
      "2025-08-11 01:17:00+00:00 2025-08-11 01:27:00+00:00     M       11\n",
      "2025-08-11 01:28:00+00:00 2025-08-11 03:03:00+00:00     C       96\n",
      "2025-08-11 03:04:00+00:00 2025-08-11 03:09:00+00:00     M        6\n",
      "2025-08-11 03:10:00+00:00 2025-08-11 03:46:00+00:00     C       37\n",
      "2025-08-11 03:47:00+00:00 2025-08-11 04:03:00+00:00     M       17\n",
      "2025-08-11 04:04:00+00:00 2025-08-11 04:55:00+00:00     C       52\n",
      "2025-08-11 04:56:00+00:00 2025-08-11 05:01:00+00:00     M        6\n",
      "2025-08-11 05:02:00+00:00 2025-08-11 05:30:00+00:00     C       29\n",
      "2025-08-11 05:31:00+00:00 2025-08-11 05:42:00+00:00     M       12\n",
      "2025-08-11 05:43:00+00:00 2025-08-11 06:02:00+00:00     C       20\n",
      "2025-08-11 06:03:00+00:00 2025-08-11 06:14:00+00:00     M       12\n",
      "2025-08-11 06:15:00+00:00 2025-08-11 08:37:00+00:00     C      143\n",
      "2025-08-11 08:38:00+00:00 2025-08-11 08:54:00+00:00     M       17\n",
      "2025-08-11 08:55:00+00:00 2025-08-11 10:33:00+00:00     C       99\n",
      "2025-08-11 10:34:00+00:00 2025-08-11 10:39:00+00:00     M        6\n",
      "2025-08-11 10:40:00+00:00 2025-08-11 10:52:00+00:00     C       13\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:55:00+00:00     M        3\n",
      "2025-08-11 10:56:00+00:00 2025-08-11 11:43:00+00:00     C       48\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:33:00+00:00     C       48\n",
      "2025-08-11 12:34:00+00:00 2025-08-11 12:38:00+00:00     M        5\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    590\n",
      "M    128\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.013\n",
      "C    0.766\n",
      "M    0.221\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 82.17%\n",
      " - M: 17.83%\n",
      " - X: 0.00%\n",
      "\n",
      "================ DecisionTree â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:48:00+00:00     C      188\n",
      "2025-08-11 03:49:00+00:00 2025-08-11 03:54:00+00:00     M        6\n",
      "2025-08-11 03:55:00+00:00 2025-08-11 06:06:00+00:00     C      132\n",
      "2025-08-11 06:07:00+00:00 2025-08-11 06:07:00+00:00     M        1\n",
      "2025-08-11 06:08:00+00:00 2025-08-11 07:25:00+00:00     C       78\n",
      "2025-08-11 07:26:00+00:00 2025-08-11 07:29:00+00:00     B        4\n",
      "2025-08-11 07:30:00+00:00 2025-08-11 08:39:00+00:00     C       70\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 08:46:00+00:00     C        2\n",
      "2025-08-11 08:47:00+00:00 2025-08-11 08:47:00+00:00     M        1\n",
      "2025-08-11 08:48:00+00:00 2025-08-11 10:53:00+00:00     C      126\n",
      "2025-08-11 10:54:00+00:00 2025-08-11 10:54:00+00:00     M        1\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:38:00+00:00     C       53\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    698\n",
      "M     16\n",
      "B      4\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.006\n",
      "C    0.972\n",
      "M    0.022\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.56%\n",
      " - C: 97.21%\n",
      " - M: 2.23%\n",
      " - X: 0.00%\n",
      "\n",
      "================ DecisionTree (tuned) â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:05:00+00:00     C      145\n",
      "2025-08-11 03:06:00+00:00 2025-08-11 03:06:00+00:00     M        1\n",
      "2025-08-11 03:07:00+00:00 2025-08-11 03:48:00+00:00     C       42\n",
      "2025-08-11 03:49:00+00:00 2025-08-11 03:54:00+00:00     M        6\n",
      "2025-08-11 03:55:00+00:00 2025-08-11 03:56:00+00:00     C        2\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 03:57:00+00:00     M        1\n",
      "2025-08-11 03:58:00+00:00 2025-08-11 08:01:00+00:00     C      244\n",
      "2025-08-11 08:02:00+00:00 2025-08-11 08:02:00+00:00     B        1\n",
      "2025-08-11 08:03:00+00:00 2025-08-11 08:03:00+00:00     C        1\n",
      "2025-08-11 08:04:00+00:00 2025-08-11 08:04:00+00:00     B        1\n",
      "2025-08-11 08:05:00+00:00 2025-08-11 08:39:00+00:00     C       35\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 10:52:00+00:00     C      128\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:35:00+00:00     C       50\n",
      "2025-08-11 12:36:00+00:00 2025-08-11 12:38:00+00:00     M        3\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    696\n",
      "M     20\n",
      "B      2\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.003\n",
      "C    0.969\n",
      "M    0.028\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.28%\n",
      " - C: 96.94%\n",
      " - M: 2.79%\n",
      " - X: 0.00%\n",
      "\n",
      "================ RandomForest â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:48:00+00:00     C      188\n",
      "2025-08-11 03:49:00+00:00 2025-08-11 03:53:00+00:00     M        5\n",
      "2025-08-11 03:54:00+00:00 2025-08-11 08:39:00+00:00     C      286\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 10:52:00+00:00     C      128\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:36:00+00:00     C       51\n",
      "2025-08-11 12:37:00+00:00 2025-08-11 12:37:00+00:00     M        1\n",
      "2025-08-11 12:38:00+00:00 2025-08-11 12:38:00+00:00     C        1\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    703\n",
      "M     15\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.004\n",
      "C    0.973\n",
      "M    0.022\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 97.91%\n",
      " - M: 2.09%\n",
      " - X: 0.00%\n",
      "\n",
      "================ RandomForest (tuned) â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:47:00+00:00     C      187\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:57:00+00:00     M       10\n",
      "2025-08-11 03:58:00+00:00 2025-08-11 08:38:00+00:00     C      281\n",
      "2025-08-11 08:39:00+00:00 2025-08-11 08:46:00+00:00     M        8\n",
      "2025-08-11 08:47:00+00:00 2025-08-11 10:52:00+00:00     C      126\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:35:00+00:00     C       50\n",
      "2025-08-11 12:36:00+00:00 2025-08-11 12:38:00+00:00     M        3\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    693\n",
      "M     25\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.005\n",
      "C    0.962\n",
      "M    0.033\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 96.52%\n",
      " - M: 3.48%\n",
      " - X: 0.00%\n",
      "\n",
      "================ GradientBoosting â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:04:00+00:00     C      144\n",
      "2025-08-11 03:05:00+00:00 2025-08-11 03:06:00+00:00     M        2\n",
      "2025-08-11 03:07:00+00:00 2025-08-11 03:47:00+00:00     C       41\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:56:00+00:00     M        9\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 08:39:00+00:00     C      283\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 11:43:00+00:00     C      179\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:38:00+00:00     C       53\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    700\n",
      "M     18\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.007\n",
      "C    0.962\n",
      "M    0.030\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 97.49%\n",
      " - M: 2.51%\n",
      " - X: 0.00%\n",
      "\n",
      "================ GradientBoosting (tuned) â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:04:00+00:00     C      144\n",
      "2025-08-11 03:05:00+00:00 2025-08-11 03:05:00+00:00     M        1\n",
      "2025-08-11 03:06:00+00:00 2025-08-11 03:47:00+00:00     C       42\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:52:00+00:00     M        5\n",
      "2025-08-11 03:53:00+00:00 2025-08-11 03:56:00+00:00     C        4\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 03:57:00+00:00     M        1\n",
      "2025-08-11 03:58:00+00:00 2025-08-11 08:39:00+00:00     C      282\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:46:00+00:00     M        7\n",
      "2025-08-11 08:47:00+00:00 2025-08-11 10:52:00+00:00     C      126\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:36:00+00:00     C       51\n",
      "2025-08-11 12:37:00+00:00 2025-08-11 12:38:00+00:00     M        2\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    698\n",
      "M     20\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.002\n",
      "C    0.970\n",
      "M    0.028\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 97.21%\n",
      " - M: 2.79%\n",
      " - X: 0.00%\n",
      "\n",
      "================ XGBoost â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:48:00+00:00     C      188\n",
      "2025-08-11 03:49:00+00:00 2025-08-11 03:54:00+00:00     M        6\n",
      "2025-08-11 03:55:00+00:00 2025-08-11 08:39:00+00:00     C      285\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 10:52:00+00:00     C      128\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:38:00+00:00     C       53\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    703\n",
      "M     15\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.002\n",
      "C    0.977\n",
      "M    0.021\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 97.91%\n",
      " - M: 2.09%\n",
      " - X: 0.00%\n",
      "\n",
      "================ XGBoost (tuned) â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:04:00+00:00     C      144\n",
      "2025-08-11 03:05:00+00:00 2025-08-11 03:05:00+00:00     M        1\n",
      "2025-08-11 03:06:00+00:00 2025-08-11 03:47:00+00:00     C       42\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:56:00+00:00     M        9\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 08:38:00+00:00     C      282\n",
      "2025-08-11 08:39:00+00:00 2025-08-11 08:47:00+00:00     M        9\n",
      "2025-08-11 08:48:00+00:00 2025-08-11 10:52:00+00:00     C      125\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:35:00+00:00     C       50\n",
      "2025-08-11 12:36:00+00:00 2025-08-11 12:38:00+00:00     M        3\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    692\n",
      "M     26\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.001\n",
      "C    0.961\n",
      "M    0.038\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 96.38%\n",
      " - M: 3.62%\n",
      " - X: 0.00%\n",
      "\n",
      "ðŸ Part des classes prÃ©dites sur 718 min (par modÃ¨le) :\n",
      "                            p_A   p_B    p_C    p_M  p_X\n",
      "model                                                   \n",
      "DecisionTree                0.0  0.56  97.21   2.23  0.0\n",
      "DecisionTree (tuned)        0.0  0.28  96.94   2.79  0.0\n",
      "GradientBoosting            0.0  0.00  97.49   2.51  0.0\n",
      "GradientBoosting (tuned)    0.0  0.00  97.21   2.79  0.0\n",
      "LogisticRegression          0.0  0.00  82.17  17.83  0.0\n",
      "LogisticRegression (tuned)  0.0  0.00  82.17  17.83  0.0\n",
      "RandomForest                0.0  0.00  97.91   2.09  0.0\n",
      "RandomForest (tuned)        0.0  0.00  96.52   3.48  0.0\n",
      "XGBoost                     0.0  0.00  97.91   2.09  0.0\n",
      "XGBoost (tuned)             0.0  0.00  96.38   3.62  0.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) helpers gÃ©nÃ©riques\n",
    "# =========================\n",
    "H_NEXT = 718  # 12h \"observables\" dans ton dataset (peut Ãªtre 720 si complet)\n",
    "\n",
    "def safe_to_datetime(s):\n",
    "    return pd.to_datetime(s.astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "def get_last_minutes_block(X_test, mask_test, Xte, minutes=H_NEXT):\n",
    "    \"\"\"Retourne X12_t (features transformÃ©es) et t12 (timestamps) pour les 'minutes' derniÃ¨res minutes rÃ©elles du test.\"\"\"\n",
    "    # timeline cÃ´tÃ© X_test\n",
    "    if \"time\" in X_test.columns:\n",
    "        t_all = safe_to_datetime(X_test[\"time\"])\n",
    "    elif isinstance(X_test.index, pd.DatetimeIndex):\n",
    "        t_all = pd.to_datetime(X_test.index, utc=True, errors=\"coerce\").to_series()\n",
    "    elif \"date\" in X_test.columns:\n",
    "        t_all = safe_to_datetime(X_test[\"date\"])\n",
    "    else:\n",
    "        raise KeyError(\"Pas de colonne temps ('time' ou 'date') dans X_test.\")\n",
    "\n",
    "    # indices du test (aprÃ¨s filtre y non-NaN) et tri par temps\n",
    "    idx_test = X_test.index[mask_test]\n",
    "    t_test_sorted = (\n",
    "        pd.DataFrame({\"time\": t_all.loc[idx_test].values}, index=idx_test)\n",
    "        .dropna()\n",
    "        .sort_values(\"time\")\n",
    "    )\n",
    "    # prendre les 'minutes' derniÃ¨res\n",
    "    last_idx = t_test_sorted.tail(minutes).index\n",
    "    # positions dans Xte (qui est X_test_t[mask_test])\n",
    "    pos_map = pd.Series(range(len(idx_test)), index=idx_test)\n",
    "    sel_pos = pos_map.loc[last_idx].sort_values()\n",
    "    X_last = Xte[sel_pos.values]\n",
    "    t_last = t_test_sorted.loc[last_idx, \"time\"].sort_values().reset_index(drop=True)\n",
    "    return X_last, t_last\n",
    "\n",
    "def softmax_from_decision(scores):\n",
    "    scores = np.array(scores)\n",
    "    if scores.ndim == 1:\n",
    "        scores = np.column_stack([-scores, scores])\n",
    "    m = scores.max(axis=1, keepdims=True)\n",
    "    exp = np.exp(scores - m)\n",
    "    return exp / exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "def safe_predict_proba(estimator, X):\n",
    "    \"\"\"Renvoie (proba, classes_idx) oÃ¹ classes_idx = estimator.classes_ (indices compacts).\"\"\"\n",
    "    if hasattr(estimator, \"predict_proba\"):\n",
    "        p = estimator.predict_proba(X)\n",
    "        return p, estimator.classes_\n",
    "    elif hasattr(estimator, \"decision_function\"):\n",
    "        p = softmax_from_decision(estimator.decision_function(X))\n",
    "        # si le modÃ¨le ne donne pas la mÃªme shape que len(classes_), on harmonise\n",
    "        classes_ = getattr(estimator, \"classes_\", np.arange(p.shape[1]))\n",
    "        return p, classes_\n",
    "    else:\n",
    "        # fallback uniform (Ã  Ã©viter en prod, mais utile pour garder le flux)\n",
    "        k = len(getattr(estimator, \"classes_\", [0,1]))\n",
    "        n = X.shape[0]\n",
    "        return np.full((n, k), 1.0/k), getattr(estimator, \"classes_\", np.arange(k))\n",
    "\n",
    "def build_718_table_for_model(name, fitted_entry, X_last, t_last, ALL_CLASSES):\n",
    "    \"\"\"\n",
    "    Construit le DataFrame minute->probas/classes pour 'name' depuis fitted_pool[name].\n",
    "    fitted_entry = (clf, to_original, present)\n",
    "    \"\"\"\n",
    "    clf, to_original, present = fitted_entry\n",
    "\n",
    "    # proba sur classes COMPACTES prÃ©sentes pendant l'entraÃ®nement (ex: [0,1,2] => B,C,M)\n",
    "    proba_compact, compact_classes = safe_predict_proba(clf, X_last)  # shape: (N, k_present)\n",
    "\n",
    "    # mapping compact -> global index (0..len(ALL_CLASSES)-1)\n",
    "    compact_to_global = np.vectorize(to_original.get)(compact_classes)  # ex: [1,2,3] (B,C,M)\n",
    "\n",
    "    # construire un tableau proba sur TOUTES les classes globales A..X (mÃªme si absentes)\n",
    "    dfp = pd.DataFrame(0.0, index=np.arange(len(t_last)), columns=ALL_CLASSES)\n",
    "    # nom des colonnes pour les classes prÃ©sentes\n",
    "    present_names = ALL_CLASSES[compact_to_global]\n",
    "    # injecter les proba au bon endroit\n",
    "    for j, cname in enumerate(present_names):\n",
    "        dfp[cname] = proba_compact[:, j]\n",
    "\n",
    "    # ajouter time + classes dÃ©rivÃ©es\n",
    "    dfp.insert(0, \"time\", t_last.values)\n",
    "    dfp[\"pred_class\"]  = ALL_CLASSES[dfp[ALL_CLASSES].values.argmax(axis=1)]\n",
    "    dfp[\"pred_strong\"] = dfp[\"pred_class\"].isin([\"M\",\"X\"]).astype(int)\n",
    "\n",
    "    # tri par temps (sÃ©curitÃ©)\n",
    "    dfp = dfp.dropna(subset=[\"time\"]).copy()\n",
    "    dfp[\"time\"] = pd.to_datetime(dfp[\"time\"], utc=True, errors=\"coerce\")\n",
    "    dfp = dfp.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    # plages continues\n",
    "    change = dfp[\"pred_class\"].ne(dfp[\"pred_class\"].shift(1))\n",
    "    dfp[\"_grp\"] = change.cumsum()\n",
    "    spans = (\n",
    "        dfp.groupby(\"_grp\", as_index=False)\n",
    "           .agg(start=(\"time\", \"first\"),\n",
    "                end=(\"time\", \"last\"),\n",
    "                **{\"class\": (\"pred_class\", \"first\")},\n",
    "                minutes=(\"time\", \"size\"))\n",
    "           .drop(columns=[\"_grp\"])\n",
    "    )\n",
    "    return dfp, spans\n",
    "\n",
    "def describe_718(dfp, spans, name, ALL_CLASSES):\n",
    "    print(f\"\\n================ {name} â€” 718 minutes ================\")\n",
    "    print(\"\\nâ±ï¸ Plages continues :\")\n",
    "    print(spans.to_string(index=False))\n",
    "\n",
    "    print(\"\\nðŸ“Š Comptes classes prÃ©dites (718 min) :\")\n",
    "    print(dfp[\"pred_class\"].value_counts().to_string())\n",
    "\n",
    "    print(\"\\nðŸ“ˆ Probas moyennes (718 min) :\")\n",
    "    print(dfp[ALL_CLASSES].mean().round(3).to_string())\n",
    "\n",
    "    print(\"\\nðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\")\n",
    "    for c in ALL_CLASSES:\n",
    "        others = [x for x in ALL_CLASSES if x != c]\n",
    "        share = (dfp[c] >= dfp[others].max(axis=1)).mean() * 100\n",
    "        print(f\" - {c}: {share:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# 1) extraire X_last & t_last une seule fois\n",
    "# =========================\n",
    "X12_t, t12 = get_last_minutes_block(X_test, mask_test, Xte, minutes=H_NEXT)\n",
    "\n",
    "# =========================\n",
    "# 2) gÃ©nÃ©rer pour chaque modÃ¨le du pool\n",
    "# =========================\n",
    "pred_tables_718 = {}\n",
    "spans_718 = {}\n",
    "\n",
    "for name, fitted_entry in fitted_pool.items():\n",
    "    df_12h, spans = build_718_table_for_model(name, fitted_entry, X12_t, t12, ALL_CLASSES)\n",
    "    pred_tables_718[name] = df_12h\n",
    "    spans_718[name] = spans\n",
    "    # impression dÃ©taillÃ©e (tu peux commenter si trop verbeux)\n",
    "    describe_718(df_12h, spans, name, ALL_CLASSES)\n",
    "\n",
    "# =========================\n",
    "# 3) tableau comparatif des parts de classes (718 min)\n",
    "# =========================\n",
    "summary = []\n",
    "for name, dfp in pred_tables_718.items():\n",
    "    vc = dfp[\"pred_class\"].value_counts(normalize=True).reindex(ALL_CLASSES, fill_value=0.0)\n",
    "    summary.append({\"model\": name, **{f\"p_{c}\": vc.get(c, 0.0) for c in ALL_CLASSES}})\n",
    "\n",
    "summary_df = pd.DataFrame(summary).sort_values(\"model\")\n",
    "print(\"\\nðŸ Part des classes prÃ©dites sur 718 min (par modÃ¨le) :\")\n",
    "print((summary_df.set_index(\"model\") * 100).round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689f425-396b-4b74-bf3b-f9e455c9f819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4819c6-9cb7-41a1-b74f-13be01051253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed32f7b-7927-496d-811e-200dfeb5903e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c49f3-3c42-4d15-a53e-323d9070a73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28838c-db19-4b41-92c5-e6e9b4583b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1087c3e-90ce-4b0d-b165-8ca7f5d6a778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448775d5-ab73-41c3-bc70-10e2cae699bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae771a-3e5f-42e1-a80d-9327e4cca098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504ba66-b457-44f4-b296-f1ab3d9d9e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e5477-4c8e-42b1-b391-3225baa66aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
