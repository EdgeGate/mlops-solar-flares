{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93a4696-d8c7-42fd-a0d6-48c583727413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d7f4cc-0cf8-463f-abd4-495ce6a5f4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Chargement du fichier xrs_clean.parquet...\n",
      "✅ Données chargées : 147639 lignes, 11 colonnes\n"
     ]
    }
   ],
   "source": [
    "print(\"📥 Chargement du fichier xrs_clean.parquet...\")\n",
    "\n",
    "parquet_path = Path(r\"C:\\Users\\gate\\Documents\\Jedha\\Projet\\4\\mlops-solar-flares\\data\\xrs_clean.parquet\")\n",
    "df = parquet_path\n",
    "df = pd.read_parquet(parquet_path, engine=\"pyarrow\")\n",
    "print(f\"✅ Données chargées : {df.shape[0]} lignes, {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341b35dd-0a37-4d8c-8aa5-980aa0003a12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# head: <bound method NDFrame.head of                             time  flux_long_wm2  flux_short_wm2 satellite  \\\n",
      "0      2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09      <NA>   \n",
      "1      2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09      <NA>   \n",
      "2      2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09      <NA>   \n",
      "3      2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09      <NA>   \n",
      "4      2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09      <NA>   \n",
      "...                          ...            ...             ...       ...   \n",
      "147634 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07   GOES-18   \n",
      "147635 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07   GOES-18   \n",
      "147636 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07   GOES-18   \n",
      "147637 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07   GOES-18   \n",
      "147638 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07   GOES-18   \n",
      "\n",
      "       energy_long energy_short      source        date  hour  minute_of_day  \\\n",
      "0       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              0   \n",
      "1       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              1   \n",
      "2       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              2   \n",
      "3       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              3   \n",
      "4       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              4   \n",
      "...            ...          ...         ...         ...   ...            ...   \n",
      "147634  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            754   \n",
      "147635  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            755   \n",
      "147636  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            756   \n",
      "147637  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            757   \n",
      "147638  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            758   \n",
      "\n",
      "        dow  \n",
      "0         3  \n",
      "1         3  \n",
      "2         3  \n",
      "3         3  \n",
      "4         3  \n",
      "...     ...  \n",
      "147634    0  \n",
      "147635    0  \n",
      "147636    0  \n",
      "147637    0  \n",
      "147638    0  \n",
      "\n",
      "[147639 rows x 11 columns]>\n",
      "\n",
      "# dtypes:\n",
      " time              datetime64[ns, UTC]\n",
      "flux_long_wm2                 float32\n",
      "flux_short_wm2                float32\n",
      "satellite              string[python]\n",
      "energy_long                    object\n",
      "energy_short                   object\n",
      "source                 string[python]\n",
      "date                   string[python]\n",
      "hour                            int16\n",
      "minute_of_day                   int16\n",
      "dow                              int8\n",
      "dtype: object\n",
      "\n",
      "# describe: <bound method NDFrame.describe of                             time  flux_long_wm2  flux_short_wm2 satellite  \\\n",
      "0      2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09      <NA>   \n",
      "1      2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09      <NA>   \n",
      "2      2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09      <NA>   \n",
      "3      2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09      <NA>   \n",
      "4      2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09      <NA>   \n",
      "...                          ...            ...             ...       ...   \n",
      "147634 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07   GOES-18   \n",
      "147635 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07   GOES-18   \n",
      "147636 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07   GOES-18   \n",
      "147637 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07   GOES-18   \n",
      "147638 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07   GOES-18   \n",
      "\n",
      "       energy_long energy_short      source        date  hour  minute_of_day  \\\n",
      "0       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              0   \n",
      "1       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              1   \n",
      "2       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              2   \n",
      "3       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              3   \n",
      "4       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              4   \n",
      "...            ...          ...         ...         ...   ...            ...   \n",
      "147634  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            754   \n",
      "147635  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            755   \n",
      "147636  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            756   \n",
      "147637  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            757   \n",
      "147638  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            758   \n",
      "\n",
      "        dow  \n",
      "0         3  \n",
      "1         3  \n",
      "2         3  \n",
      "3         3  \n",
      "4         3  \n",
      "...     ...  \n",
      "147634    0  \n",
      "147635    0  \n",
      "147636    0  \n",
      "147637    0  \n",
      "147638    0  \n",
      "\n",
      "[147639 rows x 11 columns]>\n",
      "\n",
      "# missing (%):\n",
      "satellite         91.68\n",
      "source             8.32\n",
      "flux_long_wm2      1.11\n",
      "flux_short_wm2     1.11\n",
      "time               0.00\n",
      "energy_long        0.00\n",
      "energy_short       0.00\n",
      "date               0.00\n",
      "hour               0.00\n",
      "minute_of_day      0.00\n",
      "\n",
      "# time range: 2025-05-01 00:00:00+00:00 -> 2025-08-11 12:38:00+00:00\n",
      "# time monotonic: True\n",
      "\n",
      "# last days (rows/day):\n",
      " time\n",
      "2025-08-02 00:00:00+00:00    1440\n",
      "2025-08-03 00:00:00+00:00    1440\n",
      "2025-08-04 00:00:00+00:00    1440\n",
      "2025-08-05 00:00:00+00:00    1440\n",
      "2025-08-06 00:00:00+00:00    1440\n",
      "2025-08-07 00:00:00+00:00    1440\n",
      "2025-08-08 00:00:00+00:00    1440\n",
      "2025-08-09 00:00:00+00:00    1440\n",
      "2025-08-10 00:00:00+00:00    1440\n",
      "2025-08-11 00:00:00+00:00     759\n"
     ]
    }
   ],
   "source": [
    "def quickpeek(df, topn=10):\n",
    "\n",
    "    print(\"# head:\", df.head)\n",
    "    print(\"\\n# dtypes:\\n\", df.dtypes)\n",
    "    print(\"\\n# describe:\", df.describe)\n",
    "\n",
    "    # missing %\n",
    "    print(\"\\n# missing (%):\")\n",
    "    miss = (df.isna().mean()*100).round(2).sort_values(ascending=False)\n",
    "    print(miss.head(topn).to_string())\n",
    "\n",
    "    if \"time\" in df:\n",
    "        # conversion robuste: tente direct, sinon passe par string\n",
    "        try:\n",
    "            t = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "        except Exception:\n",
    "            t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "        print(\"\\n# time range:\", t.min(), \"->\", t.max())\n",
    "\n",
    "        t_valid = t.dropna()\n",
    "        print(\"# time monotonic:\", t_valid.is_monotonic_increasing)\n",
    "\n",
    "        # comptage par jour sans dépendre du backend Arrow\n",
    "        try:\n",
    "            per_day = t.dt.floor(\"D\").value_counts().sort_index()\n",
    "        except Exception:\n",
    "            # fallback: utiliser la colonne 'date' si dispo\n",
    "            if \"date\" in df.columns:\n",
    "                per_day = pd.to_datetime(df[\"date\"], errors=\"coerce\").value_counts().sort_index()\n",
    "            else:\n",
    "                per_day = pd.Series(dtype=\"int64\")\n",
    "\n",
    "        if len(per_day):\n",
    "            print(\"\\n# last days (rows/day):\\n\", per_day.tail(10).to_string())\n",
    "\n",
    "\n",
    "quickpeek(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224673ab-a673-43ce-9c32-1dca75f6b9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Dernières lignes du fichier :\n",
      "                     time  flux_long_wm2  flux_short_wm2 satellite energy_long energy_short source       date  hour  minute_of_day  dow\n",
      "2025-08-11 12:29:00+00:00       0.000002    8.580523e-08   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            749    0\n",
      "2025-08-11 12:30:00+00:00       0.000002    1.043969e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            750    0\n",
      "2025-08-11 12:31:00+00:00       0.000003    2.087382e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            751    0\n",
      "2025-08-11 12:32:00+00:00       0.000004    3.514351e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            752    0\n",
      "2025-08-11 12:33:00+00:00       0.000004    4.549486e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            753    0\n",
      "2025-08-11 12:34:00+00:00       0.000005    5.942913e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            754    0\n",
      "2025-08-11 12:35:00+00:00       0.000006    7.550105e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            755    0\n",
      "2025-08-11 12:36:00+00:00       0.000007    8.529071e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            756    0\n",
      "2025-08-11 12:37:00+00:00       0.000007    8.953128e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            757    0\n",
      "2025-08-11 12:38:00+00:00       0.000007    8.543802e-07   GOES-18  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11    12            758    0\n",
      "\n",
      "📄 Premières lignes du fichier trié par 'time' :\n",
      "                       time  flux_long_wm2  flux_short_wm2 satellite energy_long energy_short      source        date  hour  minute_of_day  dow\n",
      "0 2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              0    3\n",
      "1 2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              1    3\n",
      "2 2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              2    3\n",
      "3 2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              3    3\n",
      "4 2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              4    3\n",
      "5 2025-05-01 00:05:00+00:00   6.989604e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              5    3\n",
      "6 2025-05-01 00:06:00+00:00   7.057731e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              6    3\n",
      "7 2025-05-01 00:07:00+00:00   7.109684e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              7    3\n",
      "8 2025-05-01 00:08:00+00:00   7.121013e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              8    3\n",
      "9 2025-05-01 00:09:00+00:00   7.152076e-07    1.000000e-09      <NA>  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              9    3\n"
     ]
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# Dernières lignes triées par temps\n",
    "print(\"\\n📄 Dernières lignes du fichier :\")\n",
    "print(df.sort_values(\"time\").tail(10).to_string(index=False))\n",
    "\n",
    "# Premières lignes triées par temps\n",
    "print(\"\\n📄 Premières lignes du fichier trié par 'time' :\")\n",
    "print(df.sort_values(\"time\").head(10).reset_index(drop=True).to_string(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0990570e-256d-4811-8809-97b8b8de7b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠 Création de la variable cible 'flare_class'...\n",
      "✅ Variable cible ajoutée.\n"
     ]
    }
   ],
   "source": [
    "TARGET_NAME  = \"flare_class\"\n",
    "ALL_CLASSES  = np.array([\"A\", \"B\", \"C\", \"M\", \"X\"], dtype=object)\n",
    "print(\"🛠 Création de la variable cible 'flare_class'...\")\n",
    "\n",
    "def rule_predict(flux):\n",
    "    \"\"\"\n",
    "    Classe une éruption selon le pic de flux X (W/m², 1-8 Å) \n",
    "    en utilisant les seuils NOAA officiels, avec A inclus.\n",
    "    \"\"\"\n",
    "    if pd.isna(flux):\n",
    "        return None\n",
    "    elif flux < 1e-7:       # A : < 10⁻⁷ W/m²\n",
    "        return \"A\"\n",
    "    elif flux < 1e-6:       # B : 10⁻⁷ ≤ flux < 10⁻⁶\n",
    "        return \"B\"\n",
    "    elif flux < 1e-5:       # C : 10⁻⁶ ≤ flux < 10⁻⁵\n",
    "        return \"C\"\n",
    "    elif flux < 1e-4:       # M : 10⁻⁵ ≤ flux < 10⁻⁴\n",
    "        return \"M\"\n",
    "    else:                   # X : ≥ 10⁻⁴\n",
    "        return \"X\"\n",
    "\n",
    "df[\"flare_class\"] = df[\"flux_long_wm2\"].apply(rule_predict)\n",
    "\n",
    "print(\"✅ Variable cible ajoutée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12457b0-bbf4-45c4-88a8-e77bb8c64054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Conversion et enrichissement des features temporelles...\n"
     ]
    }
   ],
   "source": [
    "print(\"📅 Conversion et enrichissement des features temporelles...\")\n",
    "# -- S'assurer d'avoir un datetime --\n",
    "if \"time\" in df.columns:\n",
    "    t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "elif isinstance(df.index, pd.DatetimeIndex):\n",
    "    t = pd.to_datetime(df.index, utc=True, errors=\"coerce\")\n",
    "elif \"date\" in df.columns:\n",
    "    t = pd.to_datetime(df[\"date\"].astype(str), utc=True, errors=\"coerce\")\n",
    "else:\n",
    "    raise KeyError(\"Impossible de trouver une colonne/indice temps ('time' ou 'date').\")\n",
    "\n",
    "# -- Colonnes temporelles dérivées --\n",
    "df[\"day_of_year\"] = t.dt.dayofyear.astype(\"int16\")     # 1..365/366\n",
    "df[\"hour\"] = t.dt.hour.astype(\"int16\") if \"hour\" not in df else df[\"hour\"]\n",
    "\n",
    "# Encodage cyclique du jour de l'année\n",
    "rad_doy = 2 * np.pi * (df[\"day_of_year\"] - 1) / 365.25\n",
    "df[\"sin_doy\"] = np.sin(rad_doy)\n",
    "df[\"cos_doy\"] = np.cos(rad_doy)\n",
    "\n",
    "# Optionnel : indicateur jour/nuit (si utile)\n",
    "df[\"is_daytime\"] = ((df[\"hour\"] >= 6) & (df[\"hour\"] <= 18)).astype(\"int8\")\n",
    "\n",
    "df[\"flux_ratio_short_long\"] = df[\"flux_short_wm2\"] / df[\"flux_long_wm2\"]\n",
    "df[\"flux_diff_short_long\"] = df[\"flux_short_wm2\"] - df[\"flux_long_wm2\"]\n",
    "df[\"log_flux_long\"] = np.log10(df[\"flux_long_wm2\"].clip(lower=1e-9))\n",
    "df[\"log_flux_short\"] = np.log10(df[\"flux_short_wm2\"].clip(lower=1e-9))\n",
    "df[\"sin_doy\"] = np.sin(2 * np.pi * df[\"day_of_year\"] / 365.25)\n",
    "df[\"cos_doy\"] = np.cos(2 * np.pi * df[\"day_of_year\"] / 365.25)\n",
    "df[\"flux_long_rolling_mean_1h\"] = df[\"flux_long_wm2\"].rolling(window=12, min_periods=1).mean()\n",
    "df[\"flux_long_rolling_std_1h\"] = df[\"flux_long_wm2\"].rolling(window=12, min_periods=1).std()\n",
    "df[\"flux_long_delta\"] = df[\"flux_long_wm2\"].diff()\n",
    "hist = np.log10(df[\"flux_long_wm2\"].clip(lower=1e-9)).shift(1)  # t-1\n",
    "df[\"max_60\"]  = hist.rolling(60,  min_periods=3).max()\n",
    "df[\"mean_60\"] = hist.rolling(60,  min_periods=3).mean()\n",
    "df[\"max_180\"] = hist.rolling(180, min_periods=5).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75460774-e23c-48dc-8abe-e385a73ca394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Nettoyage des colonnes inutiles...\n",
      "✅ Colonnes supprimées : ['satellite']\n",
      "✅ Types harmonisés.\n"
     ]
    }
   ],
   "source": [
    "print(\"🧹 Nettoyage des colonnes inutiles...\")\n",
    "colonnes_a_supprimer = [\"satellite\"] if \"satellite\" in df.columns else []\n",
    "df = df.drop(columns=colonnes_a_supprimer)\n",
    "print(f\"✅ Colonnes supprimées : {colonnes_a_supprimer}\")\n",
    "\n",
    "# Harmonisation des types\n",
    "numeric_features = [\"flux_long_wm2\", \"flux_short_wm2\", \"hour\", \"minute_of_day\", \"dow\"]\n",
    "categorical_features = [\"source\", \"energy_long\", \"energy_short\"]\n",
    "\n",
    "for col in numeric_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "\n",
    "print(\"✅ Types harmonisés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517ba1fb-bb83-418f-8fcd-984540f18440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Fichier sauvegardé : C:\\Users\\gate\\Documents\\Jedha\\Projet\\4\\mlops-solar-flares\\data\\xrs_clean_ml.parquet\n"
     ]
    }
   ],
   "source": [
    "output_path = parquet_path.parent / \"xrs_clean_ml.parquet\"\n",
    "df.to_parquet(output_path, engine=\"pyarrow\", index=False)\n",
    "print(f\"💾 Fichier sauvegardé : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641183ee-39f5-40c6-941e-b3040f52e2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# head:                        time  flux_long_wm2  flux_short_wm2 energy_long  \\\n",
      "0 2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09  0.1-0.8 nm   \n",
      "1 2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09  0.1-0.8 nm   \n",
      "2 2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09  0.1-0.8 nm   \n",
      "3 2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09  0.1-0.8 nm   \n",
      "4 2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09  0.1-0.8 nm   \n",
      "\n",
      "  energy_short      source        date  hour  minute_of_day  dow  ...  \\\n",
      "0  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            0.0  3.0  ...   \n",
      "1  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            1.0  3.0  ...   \n",
      "2  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            2.0  3.0  ...   \n",
      "3  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            3.0  3.0  ...   \n",
      "4  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            4.0  3.0  ...   \n",
      "\n",
      "  flux_ratio_short_long  flux_diff_short_long  log_flux_long  log_flux_short  \\\n",
      "0              0.001424         -7.011782e-07      -6.153553            -9.0   \n",
      "1              0.001430         -6.984714e-07      -6.155230            -9.0   \n",
      "2              0.001418         -7.042154e-07      -6.151678            -9.0   \n",
      "3              0.001425         -7.005647e-07      -6.153932            -9.0   \n",
      "4              0.001436         -6.956016e-07      -6.157016            -9.0   \n",
      "\n",
      "   flux_long_rolling_mean_1h  flux_long_rolling_std_1h  flux_long_delta  \\\n",
      "0               7.021782e-07                       NaN              NaN   \n",
      "1               7.008248e-07              1.914016e-09    -2.706827e-09   \n",
      "2               7.022883e-07              2.873626e-09     5.744084e-09   \n",
      "3               7.021074e-07              2.374036e-09    -3.650712e-09   \n",
      "4               7.010063e-07              3.207776e-09    -4.963113e-09   \n",
      "\n",
      "     max_60   mean_60  max_180  \n",
      "0       NaN       NaN      NaN  \n",
      "1       NaN       NaN      NaN  \n",
      "2       NaN       NaN      NaN  \n",
      "3 -6.151678 -6.153487      NaN  \n",
      "4 -6.151678 -6.153598      NaN  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "# dtypes:\n",
      " time                         datetime64[ns, UTC]\n",
      "flux_long_wm2                            float64\n",
      "flux_short_wm2                           float64\n",
      "energy_long                       string[python]\n",
      "energy_short                      string[python]\n",
      "source                            string[python]\n",
      "date                              string[python]\n",
      "hour                                     float64\n",
      "minute_of_day                            float64\n",
      "dow                                      float64\n",
      "flare_class                               object\n",
      "day_of_year                                int16\n",
      "sin_doy                                  float64\n",
      "cos_doy                                  float64\n",
      "is_daytime                                  int8\n",
      "flux_ratio_short_long                    float32\n",
      "flux_diff_short_long                     float32\n",
      "log_flux_long                            float64\n",
      "log_flux_short                           float64\n",
      "flux_long_rolling_mean_1h                float64\n",
      "flux_long_rolling_std_1h                 float64\n",
      "flux_long_delta                          float32\n",
      "max_60                                   float64\n",
      "mean_60                                  float64\n",
      "max_180                                  float64\n",
      "dtype: object\n",
      "\n",
      "# describe:\n",
      "        flux_long_wm2  flux_short_wm2           hour  minute_of_day  \\\n",
      "count   1.459950e+05    1.459950e+05  147639.000000  147639.000000   \n",
      "mean    1.458551e-06    5.521534e-08      11.470872     717.749517   \n",
      "std     1.933292e-06    2.454070e-07       6.921239     415.635068   \n",
      "min     0.000000e+00    0.000000e+00       0.000000       0.000000   \n",
      "25%     7.571672e-07    1.000000e-09       5.000000     358.000000   \n",
      "50%     1.012731e-06    1.067018e-08      11.000000     716.000000   \n",
      "75%     1.448387e-06    3.325150e-08      17.000000    1078.000000   \n",
      "max     3.827447e-05    7.218636e-06      23.000000    1439.000000   \n",
      "\n",
      "                 dow    day_of_year        sin_doy        cos_doy  \\\n",
      "count  147639.000000  147639.000000  147639.000000  147639.000000   \n",
      "mean        3.043098     171.764757       0.162587      -0.860098   \n",
      "std         2.001092      29.597817       0.463188       0.138766   \n",
      "min         0.000000     121.000000      -0.640038      -0.999979   \n",
      "25%         1.000000     146.000000      -0.244772      -0.976509   \n",
      "50%         3.000000     172.000000       0.181760      -0.904405   \n",
      "75%         5.000000     197.000000       0.589176      -0.789905   \n",
      "max         6.000000     223.000000       0.872404      -0.488785   \n",
      "\n",
      "          is_daytime  flux_ratio_short_long  flux_diff_short_long  \\\n",
      "count  147639.000000          145826.000000          1.459950e+05   \n",
      "mean        0.541585               0.017432         -1.403336e-06   \n",
      "std         0.498269               0.021963          1.708289e-06   \n",
      "min         0.000000               0.000593         -3.177940e-05   \n",
      "25%         0.000000               0.001781         -1.418173e-06   \n",
      "50%         1.000000               0.010556         -1.000832e-06   \n",
      "75%         1.000000               0.024459         -7.508702e-07   \n",
      "max         1.000000               0.271675          0.000000e+00   \n",
      "\n",
      "       log_flux_long  log_flux_short  flux_long_rolling_mean_1h  \\\n",
      "count  145995.000000   145995.000000               1.460670e+05   \n",
      "mean       -5.951880       -8.051828               1.458326e-06   \n",
      "std         0.279030        0.793542               1.867544e-06   \n",
      "min        -9.000000       -9.000000               0.000000e+00   \n",
      "25%        -6.120808       -9.000000               7.612819e-07   \n",
      "50%        -5.994506       -7.971828               1.018668e-06   \n",
      "75%        -5.839115       -7.478189               1.455909e-06   \n",
      "max        -4.417091       -5.141545               3.793919e-05   \n",
      "\n",
      "       flux_long_rolling_std_1h  flux_long_delta         max_60  \\\n",
      "count              1.460580e+05     1.459800e+05  146204.000000   \n",
      "mean               1.255168e-07     2.717106e-11      -5.809509   \n",
      "std                5.044059e-07     2.306650e-07       0.336034   \n",
      "min                0.000000e+00    -6.468221e-06      -9.000000   \n",
      "25%                1.189654e-08    -1.140921e-08      -6.035817   \n",
      "50%                2.800016e-08    -2.431236e-09      -5.879467   \n",
      "75%                7.355538e-08     4.122896e-09      -5.662226   \n",
      "max                1.763178e-05     2.147228e-05      -4.417091   \n",
      "\n",
      "             mean_60        max_180  \n",
      "count  146204.000000  146366.000000  \n",
      "mean       -5.951833      -5.661165  \n",
      "std         0.256504       0.386181  \n",
      "min        -9.000000      -6.331707  \n",
      "25%        -6.114751      -5.938429  \n",
      "50%        -5.987386      -5.749202  \n",
      "75%        -5.840416      -5.468499  \n",
      "max        -4.600644      -4.417091  \n",
      "\n",
      "# missing (%):\n",
      "source                      8.32\n",
      "flux_ratio_short_long       1.23\n",
      "flux_long_delta             1.12\n",
      "flux_short_wm2              1.11\n",
      "log_flux_short              1.11\n",
      "flare_class                 1.11\n",
      "log_flux_long               1.11\n",
      "flux_long_wm2               1.11\n",
      "flux_diff_short_long        1.11\n",
      "flux_long_rolling_std_1h    1.07\n",
      "\n",
      "✅ Aucune colonne entièrement vide trouvée.\n",
      "\n",
      "# time range: 2025-05-01 00:00:00+00:00 -> 2025-08-11 12:38:00+00:00\n",
      "# time monotonic: True\n",
      "\n",
      "# last days (rows/day):\n",
      " time\n",
      "2025-08-02 00:00:00+00:00    1440\n",
      "2025-08-03 00:00:00+00:00    1440\n",
      "2025-08-04 00:00:00+00:00    1440\n",
      "2025-08-05 00:00:00+00:00    1440\n",
      "2025-08-06 00:00:00+00:00    1440\n",
      "2025-08-07 00:00:00+00:00    1440\n",
      "2025-08-08 00:00:00+00:00    1440\n",
      "2025-08-09 00:00:00+00:00    1440\n",
      "2025-08-10 00:00:00+00:00    1440\n",
      "2025-08-11 00:00:00+00:00     759\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flux_long_wm2</th>\n",
       "      <th>flux_short_wm2</th>\n",
       "      <th>energy_long</th>\n",
       "      <th>energy_short</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute_of_day</th>\n",
       "      <th>dow</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_ratio_short_long</th>\n",
       "      <th>flux_diff_short_long</th>\n",
       "      <th>log_flux_long</th>\n",
       "      <th>log_flux_short</th>\n",
       "      <th>flux_long_rolling_mean_1h</th>\n",
       "      <th>flux_long_rolling_std_1h</th>\n",
       "      <th>flux_long_delta</th>\n",
       "      <th>max_60</th>\n",
       "      <th>mean_60</th>\n",
       "      <th>max_180</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-01 00:00:00+00:00</td>\n",
       "      <td>7.021782e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>-7.011782e-07</td>\n",
       "      <td>-6.153553</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.021782e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-01 00:01:00+00:00</td>\n",
       "      <td>6.994713e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-6.984714e-07</td>\n",
       "      <td>-6.155230</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.008248e-07</td>\n",
       "      <td>1.914016e-09</td>\n",
       "      <td>-2.706827e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-01 00:02:00+00:00</td>\n",
       "      <td>7.052154e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>-7.042154e-07</td>\n",
       "      <td>-6.151678</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.022883e-07</td>\n",
       "      <td>2.873626e-09</td>\n",
       "      <td>5.744084e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-01 00:03:00+00:00</td>\n",
       "      <td>7.015647e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-7.005647e-07</td>\n",
       "      <td>-6.153932</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.021074e-07</td>\n",
       "      <td>2.374036e-09</td>\n",
       "      <td>-3.650712e-09</td>\n",
       "      <td>-6.151678</td>\n",
       "      <td>-6.153487</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-01 00:04:00+00:00</td>\n",
       "      <td>6.966016e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>-6.956016e-07</td>\n",
       "      <td>-6.157016</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>7.010063e-07</td>\n",
       "      <td>3.207776e-09</td>\n",
       "      <td>-4.963113e-09</td>\n",
       "      <td>-6.151678</td>\n",
       "      <td>-6.153598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147634</th>\n",
       "      <td>2025-08-11 12:34:00+00:00</td>\n",
       "      <td>5.304605e-06</td>\n",
       "      <td>5.942913e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>-4.710314e-06</td>\n",
       "      <td>-5.275347</td>\n",
       "      <td>-6.226001</td>\n",
       "      <td>2.810613e-06</td>\n",
       "      <td>1.091601e-06</td>\n",
       "      <td>8.360598e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.630177</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147635</th>\n",
       "      <td>2025-08-11 12:35:00+00:00</td>\n",
       "      <td>5.992305e-06</td>\n",
       "      <td>7.550105e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125997</td>\n",
       "      <td>-5.237294e-06</td>\n",
       "      <td>-5.222406</td>\n",
       "      <td>-6.122047</td>\n",
       "      <td>3.142742e-06</td>\n",
       "      <td>1.390251e-06</td>\n",
       "      <td>6.877003e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.624355</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147636</th>\n",
       "      <td>2025-08-11 12:36:00+00:00</td>\n",
       "      <td>6.500120e-06</td>\n",
       "      <td>8.529071e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131214</td>\n",
       "      <td>-5.647213e-06</td>\n",
       "      <td>-5.187079</td>\n",
       "      <td>-6.069098</td>\n",
       "      <td>3.517855e-06</td>\n",
       "      <td>1.638613e-06</td>\n",
       "      <td>5.078155e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.617594</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147637</th>\n",
       "      <td>2025-08-11 12:37:00+00:00</td>\n",
       "      <td>6.883591e-06</td>\n",
       "      <td>8.953128e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130065</td>\n",
       "      <td>-5.988278e-06</td>\n",
       "      <td>-5.162185</td>\n",
       "      <td>-6.048025</td>\n",
       "      <td>3.920874e-06</td>\n",
       "      <td>1.827872e-06</td>\n",
       "      <td>3.834707e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.610246</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147638</th>\n",
       "      <td>2025-08-11 12:38:00+00:00</td>\n",
       "      <td>7.047310e-06</td>\n",
       "      <td>8.543802e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121235</td>\n",
       "      <td>-6.192930e-06</td>\n",
       "      <td>-5.151977</td>\n",
       "      <td>-6.068349</td>\n",
       "      <td>4.328784e-06</td>\n",
       "      <td>1.940073e-06</td>\n",
       "      <td>1.637186e-07</td>\n",
       "      <td>-5.097139</td>\n",
       "      <td>-5.602539</td>\n",
       "      <td>-5.097139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147639 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time  flux_long_wm2  flux_short_wm2 energy_long  \\\n",
       "0      2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09  0.1-0.8 nm   \n",
       "1      2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09  0.1-0.8 nm   \n",
       "2      2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09  0.1-0.8 nm   \n",
       "3      2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09  0.1-0.8 nm   \n",
       "4      2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09  0.1-0.8 nm   \n",
       "...                          ...            ...             ...         ...   \n",
       "147634 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07  0.1-0.8 nm   \n",
       "147635 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07  0.1-0.8 nm   \n",
       "147636 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07  0.1-0.8 nm   \n",
       "147637 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07  0.1-0.8 nm   \n",
       "147638 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07  0.1-0.8 nm   \n",
       "\n",
       "       energy_short      source        date  hour  minute_of_day  dow  ...  \\\n",
       "0       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            0.0  3.0  ...   \n",
       "1       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            1.0  3.0  ...   \n",
       "2       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            2.0  3.0  ...   \n",
       "3       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            3.0  3.0  ...   \n",
       "4       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0            4.0  3.0  ...   \n",
       "...             ...         ...         ...   ...            ...  ...  ...   \n",
       "147634  0.05-0.4 nm        <NA>  2025-08-11  12.0          754.0  0.0  ...   \n",
       "147635  0.05-0.4 nm        <NA>  2025-08-11  12.0          755.0  0.0  ...   \n",
       "147636  0.05-0.4 nm        <NA>  2025-08-11  12.0          756.0  0.0  ...   \n",
       "147637  0.05-0.4 nm        <NA>  2025-08-11  12.0          757.0  0.0  ...   \n",
       "147638  0.05-0.4 nm        <NA>  2025-08-11  12.0          758.0  0.0  ...   \n",
       "\n",
       "       flux_ratio_short_long  flux_diff_short_long  log_flux_long  \\\n",
       "0                   0.001424         -7.011782e-07      -6.153553   \n",
       "1                   0.001430         -6.984714e-07      -6.155230   \n",
       "2                   0.001418         -7.042154e-07      -6.151678   \n",
       "3                   0.001425         -7.005647e-07      -6.153932   \n",
       "4                   0.001436         -6.956016e-07      -6.157016   \n",
       "...                      ...                   ...            ...   \n",
       "147634              0.112033         -4.710314e-06      -5.275347   \n",
       "147635              0.125997         -5.237294e-06      -5.222406   \n",
       "147636              0.131214         -5.647213e-06      -5.187079   \n",
       "147637              0.130065         -5.988278e-06      -5.162185   \n",
       "147638              0.121235         -6.192930e-06      -5.151977   \n",
       "\n",
       "        log_flux_short  flux_long_rolling_mean_1h  flux_long_rolling_std_1h  \\\n",
       "0            -9.000000               7.021782e-07                       NaN   \n",
       "1            -9.000000               7.008248e-07              1.914016e-09   \n",
       "2            -9.000000               7.022883e-07              2.873626e-09   \n",
       "3            -9.000000               7.021074e-07              2.374036e-09   \n",
       "4            -9.000000               7.010063e-07              3.207776e-09   \n",
       "...                ...                        ...                       ...   \n",
       "147634       -6.226001               2.810613e-06              1.091601e-06   \n",
       "147635       -6.122047               3.142742e-06              1.390251e-06   \n",
       "147636       -6.069098               3.517855e-06              1.638613e-06   \n",
       "147637       -6.048025               3.920874e-06              1.827872e-06   \n",
       "147638       -6.068349               4.328784e-06              1.940073e-06   \n",
       "\n",
       "        flux_long_delta    max_60   mean_60   max_180  \n",
       "0                   NaN       NaN       NaN       NaN  \n",
       "1         -2.706827e-09       NaN       NaN       NaN  \n",
       "2          5.744084e-09       NaN       NaN       NaN  \n",
       "3         -3.650712e-09 -6.151678 -6.153487       NaN  \n",
       "4         -4.963113e-09 -6.151678 -6.153598       NaN  \n",
       "...                 ...       ...       ...       ...  \n",
       "147634     8.360598e-07 -5.097139 -5.630177 -5.097139  \n",
       "147635     6.877003e-07 -5.097139 -5.624355 -5.097139  \n",
       "147636     5.078155e-07 -5.097139 -5.617594 -5.097139  \n",
       "147637     3.834707e-07 -5.097139 -5.610246 -5.097139  \n",
       "147638     1.637186e-07 -5.097139 -5.602539 -5.097139  \n",
       "\n",
       "[147639 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quickpeek(df, topn=10):\n",
    "\n",
    "    print(\"# head:\", df.head())\n",
    "    print(\"\\n# dtypes:\\n\", df.dtypes)\n",
    "    print(\"\\n# describe:\\n\", df.describe())\n",
    "\n",
    "    # missing %\n",
    "    print(\"\\n# missing (%):\")\n",
    "    miss = (df.isna().mean() * 100).round(2).sort_values(ascending=False)\n",
    "    print(miss.head(topn).to_string())\n",
    "\n",
    "    # 🔹 Suppression des colonnes entièrement vides\n",
    "    colonnes_vides = df.columns[df.isna().all()].tolist()\n",
    "    if colonnes_vides:\n",
    "        print(f\"\\n🗑 Suppression de {len(colonnes_vides)} colonne(s) vide(s) : {colonnes_vides}\")\n",
    "        df.drop(columns=colonnes_vides, inplace=True)\n",
    "    else:\n",
    "        print(\"\\n✅ Aucune colonne entièrement vide trouvée.\")\n",
    "\n",
    "    if \"time\" in df:\n",
    "        # conversion robuste: tente direct, sinon passe par string\n",
    "        try:\n",
    "            t = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "        except Exception:\n",
    "            t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "        print(\"\\n# time range:\", t.min(), \"->\", t.max())\n",
    "        t_valid = t.dropna()\n",
    "        print(\"# time monotonic:\", t_valid.is_monotonic_increasing)\n",
    "\n",
    "        # comptage par jour\n",
    "        try:\n",
    "            per_day = t.dt.floor(\"D\").value_counts().sort_index()\n",
    "        except Exception:\n",
    "            if \"date\" in df.columns:\n",
    "                per_day = pd.to_datetime(df[\"date\"], errors=\"coerce\").value_counts().sort_index()\n",
    "            else:\n",
    "                per_day = pd.Series(dtype=\"int64\")\n",
    "\n",
    "        if len(per_day):\n",
    "            print(\"\\n# last days (rows/day):\\n\", per_day.tail(10).to_string())\n",
    "\n",
    "    return df  # On retourne le DataFrame propre\n",
    "quickpeek(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec80e1ff-3a26-4c12-8846-6c70a9e373c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Chargement du fichier xrs_clean_ml.parquet...\n",
      "✅ Données chargées : 147639 lignes, 25 colonnes\n"
     ]
    }
   ],
   "source": [
    "print(\"📥 Chargement du fichier xrs_clean_ml.parquet...\")\n",
    "parquet_path = Path(r\"C:\\Users\\gate\\Documents\\Jedha\\Projet\\4\\mlops-solar-flares\\data\\xrs_clean_ml.parquet\")\n",
    "df = pd.read_parquet(parquet_path, engine=\"pyarrow\")\n",
    "print(f\"✅ Données chargées : {df.shape[0]} lignes, {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb16736-ba0c-4a8f-ab2c-e9209cf66e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cible prête.\n",
      "✂️ Split train/test (80/20, ordre temporel conservé)...\n",
      "  - Train : 118111\n",
      "  - Test  : 29528\n",
      "✅ Features sélectionnées (sans fuite) :\n",
      "  Num : ['flux_short_wm2', 'hour', 'minute_of_day', 'dow']\n",
      "  Cat : ['source', 'energy_long', 'energy_short']\n",
      "🧹 Nettoyage des valeurs manquantes...\n",
      "  flux_short_wm2: médiane=0.000000\n",
      "  hour: médiane=11.000000\n",
      "  minute_of_day: médiane=719.000000\n",
      "  dow: médiane=3.000000\n",
      "  source: mode='NCEI-SunPy'\n",
      "  energy_long: mode='0.1-0.8 nm'\n",
      "  energy_short: mode='0.05-0.4 nm'\n",
      "✅ Données nettoyées\n",
      "⚙️ Création du preprocessor simplifié...\n",
      "🔄 Transformation des données...\n",
      "✅ Transformation terminée. Shapes : (118111, 7) (29528, 7)\n",
      "🎯 Préparation des cibles...\n",
      "✅ Encodage labels OK. Classes : ['A', 'B', 'C', 'M', 'X']\n",
      "   Répartition train : {'B': 64972, 'C': 50460, 'M': 1054}\n",
      "   Répartition test  : {'C': 22730, 'B': 6313, 'M': 297, 'A': 169}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cible \n",
    "# ============================\n",
    "def classify_flare(flux):\n",
    "    if pd.isna(flux): return None\n",
    "    elif flux < 1e-7: return \"A\"\n",
    "    elif flux < 1e-6: return \"B\"\n",
    "    elif flux < 1e-5: return \"C\"\n",
    "    elif flux < 1e-4: return \"M\"\n",
    "    else: return \"X\"\n",
    "\n",
    "if TARGET_NAME not in df.columns:\n",
    "    if \"flux_long_wm2\" not in df.columns:\n",
    "        raise KeyError(\"Colonne 'flux_long_wm2' manquante : impossible de construire la cible.\")\n",
    "    print(\"🛠 Création de la variable cible 'flare_class' à partir de flux_long_wm2...\")\n",
    "    df[TARGET_NAME] = df[\"flux_long_wm2\"].apply(classify_flare)\n",
    "print(\"✅ Cible prête.\")\n",
    "\n",
    "# ============================\n",
    "# Split temporel\n",
    "# ============================\n",
    "print(\"✂️ Split train/test (80/20, ordre temporel conservé)...\")\n",
    "Y = df[TARGET_NAME].astype(\"string\")\n",
    "X = df.drop(columns=[TARGET_NAME])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=0, shuffle=False\n",
    ")\n",
    "print(f\"  - Train : {len(X_train)}\")\n",
    "print(f\"  - Test  : {len(X_test)}\")\n",
    "\n",
    "# ============================\n",
    "# Définition des features (⚠️ sans flux_long_wm2 pour éviter la fuite)\n",
    "# ============================\n",
    "# Candidats habituels :\n",
    "numeric_features_all      = [\"flux_short_wm2\", \"hour\", \"minute_of_day\", \"dow\"]\n",
    "categorical_features_all  = [\"source\", \"energy_long\", \"energy_short\"]\n",
    "\n",
    "# Garder seulement celles qui existent réellement\n",
    "numeric_features     = [c for c in numeric_features_all if c in X_train.columns]\n",
    "categorical_features = [c for c in categorical_features_all if c in X_train.columns]\n",
    "\n",
    "print(\"✅ Features sélectionnées (sans fuite) :\")\n",
    "print(\"  Num :\", numeric_features)\n",
    "print(\"  Cat :\", categorical_features)\n",
    "\n",
    "# ============================\n",
    "# Nettoyage manuel des valeurs manquantes AVANT preprocessing\n",
    "# ============================\n",
    "print(\"🧹 Nettoyage des valeurs manquantes...\")\n",
    "\n",
    "def clean_missing_values(X_train, X_test, numeric_cols, categorical_cols):\n",
    "    \"\"\"Nettoie manuellement les valeurs manquantes pour éviter les bugs SimpleImputer\"\"\"\n",
    "    X_train_clean = X_train.copy()\n",
    "    X_test_clean = X_test.copy()\n",
    "    \n",
    "    # Pour les features numériques : remplacer par la médiane du train\n",
    "    for col in numeric_cols:\n",
    "        if col in X_train_clean.columns:\n",
    "            # Conversion en float64 propre\n",
    "            X_train_clean[col] = pd.to_numeric(X_train_clean[col], errors=\"coerce\")\n",
    "            X_test_clean[col] = pd.to_numeric(X_test_clean[col], errors=\"coerce\")\n",
    "            \n",
    "            # Calculer la médiane sur le train\n",
    "            median_val = X_train_clean[col].median()\n",
    "            if pd.isna(median_val):\n",
    "                median_val = 0.0  # fallback si tout est NaN\n",
    "            \n",
    "            # Remplacer les NaN\n",
    "            X_train_clean[col] = X_train_clean[col].fillna(median_val)\n",
    "            X_test_clean[col] = X_test_clean[col].fillna(median_val)\n",
    "            \n",
    "            print(f\"  {col}: médiane={median_val:.6f}\")\n",
    "    \n",
    "    # Pour les features catégorielles : remplacer par le mode du train\n",
    "    for col in categorical_cols:\n",
    "        if col in X_train_clean.columns:\n",
    "            # Conversion en object propre\n",
    "            X_train_clean[col] = X_train_clean[col].astype(str)\n",
    "            X_test_clean[col] = X_test_clean[col].astype(str)\n",
    "            \n",
    "            # Calculer le mode sur le train (ignorer les 'nan' string)\n",
    "            mode_candidates = X_train_clean[col][X_train_clean[col] != 'nan'].mode()\n",
    "            if len(mode_candidates) > 0:\n",
    "                mode_val = mode_candidates.iloc[0]\n",
    "            else:\n",
    "                mode_val = \"unknown\"  # fallback\n",
    "            \n",
    "            # Remplacer les NaN (maintenant string 'nan')\n",
    "            X_train_clean[col] = X_train_clean[col].replace('nan', mode_val)\n",
    "            X_test_clean[col] = X_test_clean[col].replace('nan', mode_val)\n",
    "            \n",
    "            print(f\"  {col}: mode='{mode_val}'\")\n",
    "    \n",
    "    return X_train_clean, X_test_clean\n",
    "\n",
    "# Appliquer le nettoyage\n",
    "X_train_clean, X_test_clean = clean_missing_values(\n",
    "    X_train, X_test, numeric_features, categorical_features\n",
    ")\n",
    "\n",
    "# Restreindre aux colonnes utiles (ordre fixe)\n",
    "X_train_final = X_train_clean[numeric_features + categorical_features].copy()\n",
    "X_test_final = X_test_clean[numeric_features + categorical_features].copy()\n",
    "\n",
    "print(\"✅ Données nettoyées\")\n",
    "\n",
    "# ============================\n",
    "# Préprocesseur simplifié (sans SimpleImputer)\n",
    "# ============================\n",
    "print(\"⚙️ Création du preprocessor simplifié...\")\n",
    "\n",
    "numeric_transformer = StandardScaler()  # Plus de SimpleImputer\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# Transformation\n",
    "# ============================\n",
    "print(\"🔄 Transformation des données...\")\n",
    "try:\n",
    "    X_train_t = preprocessor.fit_transform(X_train_final)\n",
    "    X_test_t  = preprocessor.transform(X_test_final)\n",
    "    print(\"✅ Transformation terminée. Shapes :\", X_train_t.shape, X_test_t.shape)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur transformation: {e}\")\n",
    "    print(\"Debug - Vérification des données:\")\n",
    "    print(\"X_train dtypes:\", X_train_final.dtypes.to_dict())\n",
    "    print(\"X_test dtypes:\", X_test_final.dtypes.to_dict())\n",
    "    \n",
    "    # Vérifier s'il y a encore des NaN\n",
    "    for col in X_train_final.columns:\n",
    "        nan_count_train = X_train_final[col].isna().sum()\n",
    "        nan_count_test = X_test_final[col].isna().sum()\n",
    "        if nan_count_train > 0 or nan_count_test > 0:\n",
    "            print(f\"  {col}: {nan_count_train} NaN train, {nan_count_test} NaN test\")\n",
    "    raise\n",
    "\n",
    "# ============================\n",
    "# Préparation cibles & encodage labels\n",
    "# ============================\n",
    "print(\"🎯 Préparation des cibles...\")\n",
    "mask_train = Y_train.notna()\n",
    "mask_test  = Y_test.notna()\n",
    "\n",
    "Xtr = X_train_t[mask_train.values]\n",
    "Xte = X_test_t[mask_test.values]\n",
    "ytr = Y_train[mask_train].astype(str).values\n",
    "yte = Y_test[mask_test].astype(str).values\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(ALL_CLASSES)                 # mapping figé A,B,C,M,X -> 0..4\n",
    "ytr_enc = le.transform(ytr)\n",
    "yte_enc = le.transform(yte)\n",
    "\n",
    "print(\"✅ Encodage labels OK. Classes :\", list(le.classes_))\n",
    "print(\"   Répartition train :\", pd.Series(ytr).value_counts().to_dict())\n",
    "print(\"   Répartition test  :\", pd.Series(yte).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddbca5-84a0-470c-a68c-12cb3166ad12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f883845-e52d-478a-8e1f-f96e27eee6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066830b0-94a4-400c-b308-b114f8d3c4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207625e1-9101-486b-a5e0-61880a9afb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f4f65bf-e401-4135-a6b1-e2554322cbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === RECHARGER VOS DONNÉES / SPLITS ICI ===\n",
    "# Xtr, Xte, ytr_enc, yte_enc, ALL_CLASSES = ...\n",
    "\n",
    "# === Helpers (perdus au restart) ===\n",
    "def compact_labels(y):\n",
    "    present = np.unique(y)\n",
    "    to_compact  = {c:i for i,c in enumerate(present)}\n",
    "    to_original = {i:c for c,i in to_compact.items()}\n",
    "    y_comp = np.vectorize(to_compact.get)(y)\n",
    "    return y_comp, present, to_compact, to_original\n",
    "\n",
    "def remap_back(y_hat_comp, to_original):\n",
    "    return np.vectorize(to_original.get)(y_hat_comp)\n",
    "\n",
    "def evaluate_and_print(name, clf, Xtr, ytr_enc, Xte, yte_enc, present, to_original, ALL_CLASSES):\n",
    "    ytr_hat = remap_back(clf.predict(Xtr), to_original)\n",
    "    yte_hat = remap_back(clf.predict(Xte), to_original)\n",
    "\n",
    "    acc_tr  = accuracy_score(ytr_enc, ytr_hat)\n",
    "    bacc_tr = balanced_accuracy_score(ytr_enc, ytr_hat)\n",
    "    f1m_tr  = f1_score(ytr_enc, ytr_hat, average=\"macro\")\n",
    "    f1w_tr  = f1_score(ytr_enc, ytr_hat, average=\"weighted\")\n",
    "\n",
    "    acc_te  = accuracy_score(yte_enc, yte_hat)\n",
    "    bacc_te = balanced_accuracy_score(yte_enc, yte_hat)\n",
    "    f1m_te  = f1_score(yte_enc, yte_hat, average=\"macro\")\n",
    "    f1w_te  = f1_score(yte_enc, yte_hat, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n========== {name} ==========\")\n",
    "    print(\"📊 Train :\", f\"acc={acc_tr:.4f} | bacc={bacc_tr:.4f} | f1m={f1m_tr:.4f} | f1w={f1w_tr:.4f}\")\n",
    "    print(\"📊 Test  :\", f\"acc={acc_te:.4f} | bacc={bacc_te:.4f} | f1m={f1m_te:.4f} | f1w={f1w_te:.4f}\")\n",
    "\n",
    "    print(\"\\n🧾 Classification report (test)\")\n",
    "    print(classification_report(yte_enc, yte_hat,\n",
    "                                labels=np.arange(len(ALL_CLASSES)),\n",
    "                                target_names=ALL_CLASSES,\n",
    "                                zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(yte_enc, yte_hat, labels=np.arange(len(ALL_CLASSES)))\n",
    "    print(\"\\n🧩 Confusion matrix (counts)\\n\",\n",
    "          pd.DataFrame(cm, index=[f\"true_{c}\" for c in ALL_CLASSES],\n",
    "                          columns=[f\"pred_{c}\" for c in ALL_CLASSES]).to_string())\n",
    "\n",
    "    row_sums = cm.sum(axis=1, keepdims=True)\n",
    "    cmn = np.divide(cm, row_sums, out=np.zeros_like(cm, dtype=float), where=row_sums!=0)\n",
    "    print(\"\\n🧩 Confusion matrix (per-class)\\n\",\n",
    "          pd.DataFrame(cmn, index=[f\"true_{c}\" for c in ALL_CLASSES],\n",
    "                            columns=[f\"pred_{c}\" for c in ALL_CLASSES]).round(3).to_string())\n",
    "\n",
    "    return {\"acc_train\":acc_tr,\"bacc_train\":bacc_tr,\"f1m_train\":f1m_tr,\"f1w_train\":f1w_tr,\n",
    "            \"acc_test\":acc_te,\"bacc_test\":bacc_te,\"f1m_test\":f1m_te,\"f1w_test\":f1w_te}, yte_hat\n",
    "\n",
    "# === Objets communs recréés à chaque fois ===\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_enc)\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# === Conteneurs de résultats ===\n",
    "results_list = []    # tableaux de scores\n",
    "fitted_pool  = {}    # modèles entraînés + mapping\n",
    "\n",
    "def add_model_result(name, clf, present, to_original, res_dict, yhat):\n",
    "    results_list.append({\"model\": name, **res_dict})\n",
    "    fitted_pool[name] = (clf, to_original, present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09799604-92b2-43b7-9fa3-a2bf89b35d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 0) Préparation conteneurs pour tous les modèles\n",
    "# ==========================================================\n",
    "results_list = []       # stocke les dicts avec les scores\n",
    "fitted_pool = {}        # stocke les modèles entraînés + mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f3e1fa-69a1-412d-8fbd-3dfd86cb912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 1) Fonction d'ajout d'un modèle dans les pools\n",
    "# ==========================================================\n",
    "def add_model_result(name, clf, present, to_original, res_dict, yte_hat):\n",
    "    results_list.append(res_dict)\n",
    "    fitted_pool[name] = (clf, to_original, present)  # on garde aussi \"present\" pour prédictions futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83567fd-76bd-4d3b-bd85-b8e41b96bbb2",
   "metadata": {},
   "source": [
    "_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5af2ab-6f24-47cc-be10-93d806f1aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== LogisticRegression ==========\n",
      "📊 Train : acc=0.8285 | bacc=0.8756 | f1m=0.7997 | f1w=0.8271\n",
      "📊 Test  : acc=0.6399 | bacc=0.6214 | f1m=0.4321 | f1w=0.6664\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.38      0.92      0.54      6313\n",
      "           C       0.96      0.56      0.71     22730\n",
      "           M       0.32      1.00      0.48       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64     29509\n",
      "   macro avg       0.33      0.50      0.35     29509\n",
      "weighted avg       0.83      0.64      0.67     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5839     474       0       0\n",
      "true_C       0    9340   12747     643       0\n",
      "true_M       0       0       0     297       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.925   0.075   0.000     0.0\n",
      "true_C     0.0   0.411   0.561   0.028     0.0\n",
      "true_M     0.0   0.000   0.000   1.000     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 2) Logistic Regression\n",
    "# ==========================================================\n",
    "ytr_comp, present_lr, to_compact_lr, to_original_lr = compact_labels(ytr_enc)\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"lbfgs\")\n",
    "logreg.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_lr, yhat_lr = evaluate_and_print(\"LogisticRegression\", logreg, Xtr, ytr_enc, Xte, yte_enc,\n",
    "                                     present_lr, to_original_lr, ALL_CLASSES)\n",
    "add_model_result(\"LogisticRegression\", logreg, present_lr, to_original_lr, res_lr, yhat_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "709d4a30-2275-4646-848f-8b9d1a19dbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR best params: {'C': 2.0, 'class_weight': None} best CV f1_macro: 0.7996\n",
      "\n",
      "========== LogisticRegression (tuned) ==========\n",
      "📊 Train : acc=0.8286 | bacc=0.8757 | f1m=0.7999 | f1w=0.8272\n",
      "📊 Test  : acc=0.6407 | bacc=0.6216 | f1m=0.4322 | f1w=0.6672\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.38      0.92      0.54      6313\n",
      "           C       0.96      0.56      0.71     22730\n",
      "           M       0.31      1.00      0.48       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64     29509\n",
      "   macro avg       0.33      0.50      0.35     29509\n",
      "weighted avg       0.83      0.64      0.67     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5835     478       0       0\n",
      "true_C       0    9310   12774     646       0\n",
      "true_M       0       0       0     297       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.924   0.076   0.000     0.0\n",
      "true_C     0.0   0.410   0.562   0.028     0.0\n",
      "true_M     0.0   0.000   0.000   1.000     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 2) Logistic Regression (tuned)\n",
    "# ==========================================================\n",
    "# 1) Compactage des labels (gère classes absentes)\n",
    "ytr_comp, present_lr, to_compact_lr, to_original_lr = compact_labels(ytr_enc)\n",
    "\n",
    "# 2) Pondération des classes sur labels compactés\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_comp)\n",
    "\n",
    "# 3) Modèle de base (multinomial)\n",
    "lr_base = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    multi_class=\"auto\",\n",
    "    n_jobs=None,           # (lbfgs n'accepte pas n_jobs)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4) CV 3-fold\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 5) Petite grille directionnelle (sobre)\n",
    "grid_lr = {\n",
    "    \"C\": [0.5, 1.0, 2.0],           # force/relâche la régularisation L2\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "# 6) GridSearchCV\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=lr_base,\n",
    "    param_grid=grid_lr,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 7) Fit avec sample_weight\n",
    "gs_lr.fit(Xtr, ytr_comp, sample_weight=sample_weight_tr)\n",
    "\n",
    "# 8) Résultats de la recherche\n",
    "print(\"LR best params:\", gs_lr.best_params_,\n",
    "      \"best CV f1_macro:\", round(gs_lr.best_score_, 4))\n",
    "\n",
    "# 9) Refit final + évaluation\n",
    "lr_best = gs_lr.best_estimator_\n",
    "res_lr, yhat_lr = evaluate_and_print(\n",
    "    \"LogisticRegression (tuned)\",\n",
    "    lr_best,\n",
    "    Xtr, ytr_enc,\n",
    "    Xte, yte_enc,\n",
    "    present_lr, to_original_lr, ALL_CLASSES\n",
    ")\n",
    "\n",
    "# 10) Stockage pour comparatif global\n",
    "add_model_result(\"LogisticRegression (tuned)\",\n",
    "                 lr_best, present_lr, to_original_lr,\n",
    "                 res_lr, yhat_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "497adac9-adc8-4999-956f-5b2118d612b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== DecisionTree ==========\n",
      "📊 Train : acc=0.9843 | bacc=0.9880 | f1m=0.9892 | f1w=0.9842\n",
      "📊 Test  : acc=0.6941 | bacc=0.5513 | f1m=0.5123 | f1w=0.7181\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.40      0.81      0.54      6313\n",
      "           C       0.92      0.67      0.77     22730\n",
      "           M       0.75      0.73      0.74       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.69     29509\n",
      "   macro avg       0.42      0.44      0.41     29509\n",
      "weighted avg       0.80      0.69      0.72     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5126    1187       0       0\n",
      "true_C       0    7519   15140      71       0\n",
      "true_M       0       0      81     216       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.812   0.188   0.000     0.0\n",
      "true_C     0.0   0.331   0.666   0.003     0.0\n",
      "true_M     0.0   0.000   0.273   0.727     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 3) Decision Tree\n",
    "# ==========================================================\n",
    "ytr_comp, present_dt, to_compact_dt, to_original_dt = compact_labels(ytr_enc)\n",
    "dt = DecisionTreeClassifier(class_weight=\"balanced\", random_state=0)\n",
    "dt.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_dt, yhat_dt = evaluate_and_print(\"DecisionTree\", dt, Xtr, ytr_enc, Xte, yte_enc,\n",
    "                                     present_dt, to_original_dt, ALL_CLASSES)\n",
    "add_model_result(\"DecisionTree\", dt, present_dt, to_original_dt, res_dt, yhat_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb66605f-5f0b-48fc-a8a9-db12707c893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT best params: {'ccp_alpha': 0.0, 'max_depth': None, 'min_samples_leaf': 1} best CV f1_macro: 0.8673\n",
      "\n",
      "========== DecisionTree (tuned) ==========\n",
      "📊 Train : acc=0.9842 | bacc=0.9879 | f1m=0.9892 | f1w=0.9842\n",
      "📊 Test  : acc=0.6933 | bacc=0.5535 | f1m=0.5142 | f1w=0.7174\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.40      0.82      0.54      6313\n",
      "           C       0.92      0.66      0.77     22730\n",
      "           M       0.76      0.73      0.75       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.69     29509\n",
      "   macro avg       0.42      0.44      0.41     29509\n",
      "weighted avg       0.80      0.69      0.72     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5152    1161       0       0\n",
      "true_C       0    7573   15089      68       0\n",
      "true_M       0       0      79     218       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.816   0.184   0.000     0.0\n",
      "true_C     0.0   0.333   0.664   0.003     0.0\n",
      "true_M     0.0   0.000   0.266   0.734     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 3) Decision Tree (tuned)\n",
    "# ==========================================================\n",
    "# Pondération des échantillons (équilibrage des classes)\n",
    "# 1) Définir le modèle + grille AVANT de créer gs_dt\n",
    "dt = DecisionTreeClassifier(class_weight=\"balanced\", random_state=0)\n",
    "grid_dt = {\n",
    "    \"max_depth\": [None, 12, 8, 5],\n",
    "    \"min_samples_leaf\": [1, 5, 20],\n",
    "    \"ccp_alpha\": [0.0, 1e-4, 5e-4]\n",
    "}\n",
    "\n",
    "# 2) Créer gs_dt\n",
    "gs_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=grid_dt,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 3) Fit (maintenant gs_dt existe bien)\n",
    "gs_dt.fit(Xtr, ytr_enc, sample_weight=sample_weight_tr)\n",
    "print(\"DT best params:\", gs_dt.best_params_, \"best CV f1_macro:\", round(gs_dt.best_score_,4))\n",
    "\n",
    "# 4) Refit final + report\n",
    "dt_best = gs_dt.best_estimator_\n",
    "res_dt, yhat_dt = evaluate_and_print(\n",
    "    \"DecisionTree (tuned)\", dt_best,\n",
    "    Xtr, ytr_enc, Xte, yte_enc,\n",
    "    present=np.unique(ytr_enc),\n",
    "    to_original={i:i for i in range(len(ALL_CLASSES))},\n",
    "    ALL_CLASSES=ALL_CLASSES\n",
    ")\n",
    "add_model_result(\"DecisionTree (tuned)\", dt_best, np.unique(ytr_enc),\n",
    "                 {i:i for i in range(len(ALL_CLASSES))}, res_dt, yhat_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f334c8dc-82f0-46e1-938a-d328837d6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== RandomForest ==========\n",
      "📊 Train : acc=0.9843 | bacc=0.9880 | f1m=0.9892 | f1w=0.9842\n",
      "📊 Test  : acc=0.6993 | bacc=0.4442 | f1m=0.4285 | f1w=0.7212\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.41      0.83      0.55      6313\n",
      "           C       0.92      0.67      0.78     22730\n",
      "           M       0.68      0.27      0.39       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.70     29509\n",
      "   macro avg       0.40      0.36      0.34     29509\n",
      "weighted avg       0.81      0.70      0.72     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5270    1043       0       0\n",
      "true_C       0    7405   15287      38       0\n",
      "true_M       0       0     217      80       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.835   0.165   0.000     0.0\n",
      "true_C     0.0   0.326   0.673   0.002     0.0\n",
      "true_M     0.0   0.000   0.731   0.269     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 4) Random Forest \n",
    "# ==========================================================\n",
    "ytr_comp, present_rf, to_compact_rf, to_original_rf = compact_labels(ytr_enc)\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", n_jobs=-1, random_state=0)\n",
    "rf.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_rf, yhat_rf = evaluate_and_print(\"RandomForest\", rf, Xtr, ytr_enc, Xte, yte_enc,\n",
    "                                     present_rf, to_original_rf, ALL_CLASSES)\n",
    "add_model_result(\"RandomForest\", rf, present_rf, to_original_rf, res_rf, yhat_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ef8ce86-eb69-4443-80e3-2e6ba7467459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF best params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 200} best CV f1_macro: 0.9032\n",
      "\n",
      "========== RandomForest (tuned) ==========\n",
      "📊 Train : acc=0.9620 | bacc=0.9735 | f1m=0.9664 | f1w=0.9619\n",
      "📊 Test  : acc=0.7097 | bacc=0.4790 | f1m=0.4615 | f1w=0.7310\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.42      0.82      0.56      6313\n",
      "           C       0.92      0.69      0.79     22730\n",
      "           M       0.66      0.40      0.50       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.71     29509\n",
      "   macro avg       0.40      0.38      0.37     29509\n",
      "weighted avg       0.81      0.71      0.73     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5208    1105       0       0\n",
      "true_C       0    7053   15616      61       0\n",
      "true_M       0       0     177     120       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.825   0.175   0.000     0.0\n",
      "true_C     0.0   0.310   0.687   0.003     0.0\n",
      "true_M     0.0   0.000   0.596   0.404     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 4) Random Forest (tuned)\n",
    "# ==========================================================\n",
    "# Pondération des échantillons (équilibrage des classes)\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_enc)\n",
    "\n",
    "# Modèle de base\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation 3-fold stratifiée\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Petite grille \"directionnelle\" (élargis si besoin)\n",
    "grid_rf = {\n",
    "    \"n_estimators\": [200,],\n",
    "    \"max_depth\": [None, 5,],\n",
    "    \"min_samples_leaf\": [1,2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]  # ou None si tu veux tester\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=grid_rf,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit avec pondération des classes\n",
    "gs_rf.fit(Xtr, ytr_enc, sample_weight=sample_weight_tr)\n",
    "\n",
    "# Résultats de la recherche\n",
    "print(\"RF best params:\", gs_rf.best_params_,\n",
    "      \"best CV f1_macro:\", round(gs_rf.best_score_, 4))\n",
    "\n",
    "# Refit final + évaluation\n",
    "rf_best = gs_rf.best_estimator_\n",
    "res_rf, yhat_rf = evaluate_and_print(\n",
    "    \"RandomForest (tuned)\",\n",
    "    rf_best,\n",
    "    Xtr, ytr_enc,\n",
    "    Xte, yte_enc,\n",
    "    present=np.unique(ytr_enc),\n",
    "    to_original={i: i for i in range(len(ALL_CLASSES))},\n",
    "    ALL_CLASSES=ALL_CLASSES\n",
    ")\n",
    "\n",
    "# Stockage pour comparaison ultérieure (si tu utilises ce helper)\n",
    "add_model_result(\n",
    "    \"RandomForest (tuned)\",\n",
    "    rf_best,\n",
    "    np.unique(ytr_enc),\n",
    "    {i: i for i in range(len(ALL_CLASSES))},\n",
    "    res_rf,\n",
    "    yhat_rf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98e43fee-b225-418a-bc1d-65f1a7edd581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== GradientBoosting ==========\n",
      "📊 Train : acc=0.8611 | bacc=0.8759 | f1m=0.8812 | f1w=0.8609\n",
      "📊 Test  : acc=0.7382 | bacc=0.6036 | f1m=0.5546 | f1w=0.7583\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.45      0.89      0.60      6313\n",
      "           C       0.96      0.70      0.81     22730\n",
      "           M       0.81      0.82      0.81       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.74     29509\n",
      "   macro avg       0.44      0.48      0.44     29509\n",
      "weighted avg       0.84      0.74      0.76     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5641     672       0       0\n",
      "true_C       0    6772   15899      59       0\n",
      "true_M       0       0      53     244       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.894   0.106   0.000     0.0\n",
      "true_C     0.0   0.298   0.699   0.003     0.0\n",
      "true_M     0.0   0.000   0.178   0.822     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 5) Gradient Boosting \n",
    "# ==========================================================\n",
    "ytr_comp, present_gb, to_compact_gb, to_original_gb = compact_labels(ytr_enc)\n",
    "gb = GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "gb.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_gb, yhat_gb = evaluate_and_print(\"GradientBoosting\", gb, Xtr, ytr_enc, Xte, yte_enc,\n",
    "                                     present_gb, to_original_gb, ALL_CLASSES)\n",
    "add_model_result(\"GradientBoosting\", gb, present_gb, to_original_gb, res_gb, yhat_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dd3ddc3-9d69-4a1f-a727-64b9e6df406d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB best params: {'learning_rate': 0.2, 'max_depth': 8, 'n_estimators': 100} best CV f1_macro: 0.8883\n",
      "\n",
      "========== GradientBoosting (tuned) ==========\n",
      "📊 Train : acc=0.9236 | bacc=0.9476 | f1m=0.9478 | f1w=0.9236\n",
      "📊 Test  : acc=0.7244 | bacc=0.5745 | f1m=0.5265 | f1w=0.7450\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.43      0.84      0.57      6313\n",
      "           C       0.93      0.70      0.80     22730\n",
      "           M       0.71      0.76      0.74       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72     29509\n",
      "   macro avg       0.42      0.46      0.42     29509\n",
      "weighted avg       0.82      0.72      0.75     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5274    1039       0       0\n",
      "true_C       0    6764   15874      92       0\n",
      "true_M       0       0      70     227       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.835   0.165   0.000     0.0\n",
      "true_C     0.0   0.298   0.698   0.004     0.0\n",
      "true_M     0.0   0.000   0.236   0.764     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 5) Gradient Boosting (tuned)\n",
    "# ==========================================================\n",
    "# Pondération des échantillons (équilibrage des classes)\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_enc)\n",
    "\n",
    "# Modèle de base (proche de ce qui marchait le mieux chez toi)\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation 3-fold stratifiée\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Petite grille \"directionnelle\" (élargis si besoin)\n",
    "grid_gb = {\n",
    "    \"n_estimators\":  [50, 100],\n",
    "    \"learning_rate\": [0.2,0.4],\n",
    "    \"max_depth\":     [4,6,8],\n",
    "    # optionnel :\n",
    "    # \"subsample\":     [1.0, 0.8],\n",
    "    # \"max_features\":  [\"sqrt\", None],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "gs_gb = GridSearchCV(\n",
    "    estimator=gb,\n",
    "    param_grid=grid_gb,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit avec pondération des classes\n",
    "gs_gb.fit(Xtr, ytr_enc, sample_weight=sample_weight_tr)\n",
    "\n",
    "# Résultats de la recherche\n",
    "print(\"GB best params:\", gs_gb.best_params_,\n",
    "      \"best CV f1_macro:\", round(gs_gb.best_score_, 4))\n",
    "\n",
    "# Refit final + évaluation (mapping identité car on est déjà sur 0..4)\n",
    "gb_best = gs_gb.best_estimator_\n",
    "res_gb, yhat_gb = evaluate_and_print(\n",
    "    \"GradientBoosting (tuned)\",\n",
    "    gb_best,\n",
    "    Xtr, ytr_enc,\n",
    "    Xte, yte_enc,\n",
    "    present=np.unique(ytr_enc),\n",
    "    to_original={i: i for i in range(len(ALL_CLASSES))},\n",
    "    ALL_CLASSES=ALL_CLASSES\n",
    ")\n",
    "\n",
    "# Stockage pour comparaison ultérieure\n",
    "add_model_result(\"GradientBoosting (tuned)\", gb_best,\n",
    "                 np.unique(ytr_enc),\n",
    "                 {i: i for i in range(len(ALL_CLASSES))},\n",
    "                 res_gb, yhat_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58e504d3-75ba-4444-9755-7259b527198f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== XGBoost ==========\n",
      "📊 Train : acc=0.8799 | bacc=0.9068 | f1m=0.9063 | f1w=0.8795\n",
      "📊 Test  : acc=0.7191 | bacc=0.5690 | f1m=0.5354 | f1w=0.7412\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.43      0.88      0.58      6313\n",
      "           C       0.95      0.68      0.79     22730\n",
      "           M       0.84      0.71      0.77       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72     29509\n",
      "   macro avg       0.44      0.46      0.43     29509\n",
      "weighted avg       0.83      0.72      0.74     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5577     736       0       0\n",
      "true_C       0    7258   15432      40       0\n",
      "true_M       0       0      85     212       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.883   0.117   0.000     0.0\n",
      "true_C     0.0   0.319   0.679   0.002     0.0\n",
      "true_M     0.0   0.000   0.286   0.714     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 6) XGBoost \n",
    "# ==========================================================\n",
    "ytr_comp, present_xgb, to_compact_xgb, to_original_xgb = compact_labels(ytr_enc)\n",
    "k = len(present_xgb)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    num_class=k,\n",
    "    n_jobs=-1,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "xgb.fit(Xtr, ytr_comp)\n",
    "\n",
    "res_xgb, yhat_xgb = evaluate_and_print(\n",
    "    \"XGBoost\", xgb, Xtr, ytr_enc, Xte, yte_enc,\n",
    "    present_xgb, to_original_xgb, ALL_CLASSES\n",
    ")\n",
    "\n",
    "add_model_result(\"XGBoost\", xgb, present_xgb, to_original_xgb, res_xgb, yhat_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "976fabd0-7d95-45e9-9644-41995d992df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB best params: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8} best CV f1_macro: 0.8927\n",
      "\n",
      "========== XGBoost (tuned) ==========\n",
      "📊 Train : acc=0.8805 | bacc=0.9187 | f1m=0.9059 | f1w=0.8805\n",
      "📊 Test  : acc=0.7379 | bacc=0.6045 | f1m=0.5442 | f1w=0.7574\n",
      "\n",
      "🧾 Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00       169\n",
      "           B       0.45      0.85      0.59      6313\n",
      "           C       0.94      0.71      0.81     22730\n",
      "           M       0.72      0.86      0.78       297\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.74     29509\n",
      "   macro avg       0.42      0.48      0.44     29509\n",
      "weighted avg       0.83      0.74      0.76     29509\n",
      "\n",
      "\n",
      "🧩 Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A       0     169       0       0       0\n",
      "true_B       0    5382     931       0       0\n",
      "true_C       0    6490   16140     100       0\n",
      "true_M       0       0      43     254       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "🧩 Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     0.0   1.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.853   0.147   0.000     0.0\n",
      "true_C     0.0   0.286   0.710   0.004     0.0\n",
      "true_M     0.0   0.000   0.145   0.855     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 6) XGBoost (si dispo)\n",
    "# ==========================================================\n",
    "# 1) Compactage des labels (gère classes absentes)\n",
    "ytr_comp, present_xgb, to_compact_xgb, to_original_xgb = compact_labels(ytr_enc)\n",
    "k = len(present_xgb)\n",
    "\n",
    "# 2) Pondération des classes sur les labels compactés\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_comp)\n",
    "\n",
    "# 3) Modèle de base\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    num_class=k,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4) CV 3-fold\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 5) Petite grille directionnelle (rapide)\n",
    "grid_xgb = {\n",
    "    \"n_estimators\":      [150, 200],\n",
    "    \"max_depth\":         [4, 6],\n",
    "    \"learning_rate\":     [0.05, 0.1],\n",
    "    \"subsample\":         [0.8, 1.0],\n",
    "    \"colsample_bytree\":  [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# 6) GridSearchCV\n",
    "gs_xgb = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=grid_xgb,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 7) Fit avec sample_weight\n",
    "gs_xgb.fit(Xtr, ytr_comp, sample_weight=sample_weight_tr)\n",
    "\n",
    "# 8) Résultats de la recherche\n",
    "print(\"XGB best params:\", gs_xgb.best_params_,\n",
    "      \"best CV f1_macro:\", round(gs_xgb.best_score_, 4))\n",
    "\n",
    "# 9) Refit final + évaluation\n",
    "xgb_best = gs_xgb.best_estimator_\n",
    "res_xgb, yhat_xgb = evaluate_and_print(\n",
    "    \"XGBoost (tuned)\",\n",
    "    xgb_best,\n",
    "    Xtr, ytr_enc,\n",
    "    Xte, yte_enc,\n",
    "    present_xgb,\n",
    "    to_original_xgb,\n",
    "    ALL_CLASSES\n",
    ")\n",
    "\n",
    "# 10) Stockage pour comparatif global\n",
    "add_model_result(\"XGBoost (tuned)\",\n",
    "                 xgb_best,\n",
    "                 present_xgb,\n",
    "                 to_original_xgb,\n",
    "                 res_xgb,\n",
    "                 yhat_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "066500bb-6209-439a-8293-0b59189bbc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏁 Tableau comparatif (tri par F1-macro test) :\n",
      "                     model  acc_train  bacc_train  f1m_train  f1w_train  acc_test  bacc_test  f1m_test  f1w_test\n",
      "          GradientBoosting   0.861142    0.875911   0.881204   0.860869  0.738215   0.603643  0.554605  0.758304\n",
      "           XGBoost (tuned)   0.880475    0.918658   0.905948   0.880514  0.737944   0.604455  0.544241  0.757364\n",
      "                   XGBoost   0.879917    0.906753   0.906282   0.879519  0.719137   0.569037  0.535365  0.741151\n",
      "  GradientBoosting (tuned)   0.923596    0.947636   0.947752   0.923580  0.724355   0.574525  0.526499  0.745048\n",
      "      DecisionTree (tuned)   0.984196    0.987945   0.989154   0.984162  0.693314   0.553484  0.514238  0.717430\n",
      "              DecisionTree   0.984281    0.987967   0.989211   0.984247  0.694093   0.551332  0.512349  0.718053\n",
      "      RandomForest (tuned)   0.961961    0.973518   0.966360   0.961929  0.709750   0.479007  0.461487  0.731018\n",
      "LogisticRegression (tuned)   0.828597    0.875722   0.799886   0.827209  0.640686   0.621568  0.432164  0.667172\n",
      "        LogisticRegression   0.828529    0.875581   0.799701   0.827093  0.639906   0.621429  0.432113  0.666396\n",
      "              RandomForest   0.984281    0.987950   0.989211   0.984247  0.699346   0.444173  0.428538  0.721181\n",
      "\n",
      "⭐ Meilleur modèle du run : GradientBoosting\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Tableau comparatif final\n",
    "# ==========================\n",
    "def build_leaderboard():\n",
    "    # 1) Source prioritaire: results_table (contient déjà \"model\")\n",
    "    if \"results_table\" in globals() and isinstance(results_table, list) and len(results_table) > 0:\n",
    "        df = pd.DataFrame(results_table)\n",
    "    # 2) Sinon, on tente de reconstruire avec fitted_pool + results_list\n",
    "    elif (\"results_list\" in globals() and isinstance(results_list, list) and len(results_list) > 0\n",
    "          and \"fitted_pool\" in globals() and isinstance(fitted_pool, dict) and len(fitted_pool) > 0):\n",
    "        model_names = list(fitted_pool.keys())\n",
    "        m = min(len(model_names), len(results_list))\n",
    "        df = pd.DataFrame([{\"model\": model_names[i], **results_list[i]} for i in range(m)])\n",
    "    else:\n",
    "        print(\"⚠️ Aucun résultat à afficher (results_table/results_list vides).\")\n",
    "        return\n",
    "\n",
    "    df = df.sort_values([\"f1m_test\", \"bacc_test\", \"acc_test\"], ascending=False).reset_index(drop=True)\n",
    "    print(\"\\n🏁 Tableau comparatif (tri par F1-macro test) :\")\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    if \"model\" in df.columns:\n",
    "        best_name = df.iloc[0][\"model\"]\n",
    "        print(f\"\\n⭐ Meilleur modèle du run : {best_name}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Colonne 'model' absente : pense à utiliser add_model_result(...) dans chaque bloc.\")\n",
    "\n",
    "build_leaderboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d916773-28ca-42ff-95d4-63e2b6ceb865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ LogisticRegression — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 01:11:00+00:00     M       31\n",
      "2025-08-11 01:12:00+00:00 2025-08-11 01:16:00+00:00     C        5\n",
      "2025-08-11 01:17:00+00:00 2025-08-11 01:27:00+00:00     M       11\n",
      "2025-08-11 01:28:00+00:00 2025-08-11 03:03:00+00:00     C       96\n",
      "2025-08-11 03:04:00+00:00 2025-08-11 03:09:00+00:00     M        6\n",
      "2025-08-11 03:10:00+00:00 2025-08-11 03:46:00+00:00     C       37\n",
      "2025-08-11 03:47:00+00:00 2025-08-11 04:03:00+00:00     M       17\n",
      "2025-08-11 04:04:00+00:00 2025-08-11 04:55:00+00:00     C       52\n",
      "2025-08-11 04:56:00+00:00 2025-08-11 05:01:00+00:00     M        6\n",
      "2025-08-11 05:02:00+00:00 2025-08-11 05:30:00+00:00     C       29\n",
      "2025-08-11 05:31:00+00:00 2025-08-11 05:42:00+00:00     M       12\n",
      "2025-08-11 05:43:00+00:00 2025-08-11 06:02:00+00:00     C       20\n",
      "2025-08-11 06:03:00+00:00 2025-08-11 06:14:00+00:00     M       12\n",
      "2025-08-11 06:15:00+00:00 2025-08-11 08:37:00+00:00     C      143\n",
      "2025-08-11 08:38:00+00:00 2025-08-11 08:54:00+00:00     M       17\n",
      "2025-08-11 08:55:00+00:00 2025-08-11 10:33:00+00:00     C       99\n",
      "2025-08-11 10:34:00+00:00 2025-08-11 10:39:00+00:00     M        6\n",
      "2025-08-11 10:40:00+00:00 2025-08-11 10:52:00+00:00     C       13\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:55:00+00:00     M        3\n",
      "2025-08-11 10:56:00+00:00 2025-08-11 11:43:00+00:00     C       48\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:33:00+00:00     C       48\n",
      "2025-08-11 12:34:00+00:00 2025-08-11 12:38:00+00:00     M        5\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    590\n",
      "M    128\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.013\n",
      "C    0.766\n",
      "M    0.220\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 82.17%\n",
      " - M: 17.83%\n",
      " - X: 0.00%\n",
      "\n",
      "================ LogisticRegression (tuned) — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 01:11:00+00:00     M       31\n",
      "2025-08-11 01:12:00+00:00 2025-08-11 01:16:00+00:00     C        5\n",
      "2025-08-11 01:17:00+00:00 2025-08-11 01:27:00+00:00     M       11\n",
      "2025-08-11 01:28:00+00:00 2025-08-11 03:03:00+00:00     C       96\n",
      "2025-08-11 03:04:00+00:00 2025-08-11 03:09:00+00:00     M        6\n",
      "2025-08-11 03:10:00+00:00 2025-08-11 03:46:00+00:00     C       37\n",
      "2025-08-11 03:47:00+00:00 2025-08-11 04:03:00+00:00     M       17\n",
      "2025-08-11 04:04:00+00:00 2025-08-11 04:55:00+00:00     C       52\n",
      "2025-08-11 04:56:00+00:00 2025-08-11 05:01:00+00:00     M        6\n",
      "2025-08-11 05:02:00+00:00 2025-08-11 05:30:00+00:00     C       29\n",
      "2025-08-11 05:31:00+00:00 2025-08-11 05:42:00+00:00     M       12\n",
      "2025-08-11 05:43:00+00:00 2025-08-11 06:02:00+00:00     C       20\n",
      "2025-08-11 06:03:00+00:00 2025-08-11 06:14:00+00:00     M       12\n",
      "2025-08-11 06:15:00+00:00 2025-08-11 08:37:00+00:00     C      143\n",
      "2025-08-11 08:38:00+00:00 2025-08-11 08:54:00+00:00     M       17\n",
      "2025-08-11 08:55:00+00:00 2025-08-11 10:33:00+00:00     C       99\n",
      "2025-08-11 10:34:00+00:00 2025-08-11 10:39:00+00:00     M        6\n",
      "2025-08-11 10:40:00+00:00 2025-08-11 10:52:00+00:00     C       13\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:55:00+00:00     M        3\n",
      "2025-08-11 10:56:00+00:00 2025-08-11 11:43:00+00:00     C       48\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:33:00+00:00     C       48\n",
      "2025-08-11 12:34:00+00:00 2025-08-11 12:38:00+00:00     M        5\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    590\n",
      "M    128\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.013\n",
      "C    0.766\n",
      "M    0.221\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 82.17%\n",
      " - M: 17.83%\n",
      " - X: 0.00%\n",
      "\n",
      "================ DecisionTree — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:48:00+00:00     C      188\n",
      "2025-08-11 03:49:00+00:00 2025-08-11 03:54:00+00:00     M        6\n",
      "2025-08-11 03:55:00+00:00 2025-08-11 06:06:00+00:00     C      132\n",
      "2025-08-11 06:07:00+00:00 2025-08-11 06:07:00+00:00     M        1\n",
      "2025-08-11 06:08:00+00:00 2025-08-11 07:25:00+00:00     C       78\n",
      "2025-08-11 07:26:00+00:00 2025-08-11 07:29:00+00:00     B        4\n",
      "2025-08-11 07:30:00+00:00 2025-08-11 08:39:00+00:00     C       70\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 08:46:00+00:00     C        2\n",
      "2025-08-11 08:47:00+00:00 2025-08-11 08:47:00+00:00     M        1\n",
      "2025-08-11 08:48:00+00:00 2025-08-11 10:53:00+00:00     C      126\n",
      "2025-08-11 10:54:00+00:00 2025-08-11 10:54:00+00:00     M        1\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:38:00+00:00     C       53\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    698\n",
      "M     16\n",
      "B      4\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.006\n",
      "C    0.972\n",
      "M    0.022\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.56%\n",
      " - C: 97.21%\n",
      " - M: 2.23%\n",
      " - X: 0.00%\n",
      "\n",
      "================ DecisionTree (tuned) — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:05:00+00:00     C      145\n",
      "2025-08-11 03:06:00+00:00 2025-08-11 03:06:00+00:00     M        1\n",
      "2025-08-11 03:07:00+00:00 2025-08-11 03:48:00+00:00     C       42\n",
      "2025-08-11 03:49:00+00:00 2025-08-11 03:54:00+00:00     M        6\n",
      "2025-08-11 03:55:00+00:00 2025-08-11 03:56:00+00:00     C        2\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 03:57:00+00:00     M        1\n",
      "2025-08-11 03:58:00+00:00 2025-08-11 08:01:00+00:00     C      244\n",
      "2025-08-11 08:02:00+00:00 2025-08-11 08:02:00+00:00     B        1\n",
      "2025-08-11 08:03:00+00:00 2025-08-11 08:03:00+00:00     C        1\n",
      "2025-08-11 08:04:00+00:00 2025-08-11 08:04:00+00:00     B        1\n",
      "2025-08-11 08:05:00+00:00 2025-08-11 08:39:00+00:00     C       35\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 10:52:00+00:00     C      128\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:35:00+00:00     C       50\n",
      "2025-08-11 12:36:00+00:00 2025-08-11 12:38:00+00:00     M        3\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    696\n",
      "M     20\n",
      "B      2\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.003\n",
      "C    0.969\n",
      "M    0.028\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.28%\n",
      " - C: 96.94%\n",
      " - M: 2.79%\n",
      " - X: 0.00%\n",
      "\n",
      "================ RandomForest — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:48:00+00:00     C      188\n",
      "2025-08-11 03:49:00+00:00 2025-08-11 03:53:00+00:00     M        5\n",
      "2025-08-11 03:54:00+00:00 2025-08-11 08:39:00+00:00     C      286\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 10:52:00+00:00     C      128\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:36:00+00:00     C       51\n",
      "2025-08-11 12:37:00+00:00 2025-08-11 12:37:00+00:00     M        1\n",
      "2025-08-11 12:38:00+00:00 2025-08-11 12:38:00+00:00     C        1\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    703\n",
      "M     15\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.004\n",
      "C    0.973\n",
      "M    0.022\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 97.91%\n",
      " - M: 2.09%\n",
      " - X: 0.00%\n",
      "\n",
      "================ RandomForest (tuned) — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:47:00+00:00     C      187\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:57:00+00:00     M       10\n",
      "2025-08-11 03:58:00+00:00 2025-08-11 08:38:00+00:00     C      281\n",
      "2025-08-11 08:39:00+00:00 2025-08-11 08:46:00+00:00     M        8\n",
      "2025-08-11 08:47:00+00:00 2025-08-11 10:52:00+00:00     C      126\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:35:00+00:00     C       50\n",
      "2025-08-11 12:36:00+00:00 2025-08-11 12:38:00+00:00     M        3\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    693\n",
      "M     25\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.005\n",
      "C    0.962\n",
      "M    0.033\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 96.52%\n",
      " - M: 3.48%\n",
      " - X: 0.00%\n",
      "\n",
      "================ GradientBoosting — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:04:00+00:00     C      144\n",
      "2025-08-11 03:05:00+00:00 2025-08-11 03:06:00+00:00     M        2\n",
      "2025-08-11 03:07:00+00:00 2025-08-11 03:47:00+00:00     C       41\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:56:00+00:00     M        9\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 08:39:00+00:00     C      283\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 11:43:00+00:00     C      179\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:38:00+00:00     C       53\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    700\n",
      "M     18\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.007\n",
      "C    0.962\n",
      "M    0.030\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 97.49%\n",
      " - M: 2.51%\n",
      " - X: 0.00%\n",
      "\n",
      "================ GradientBoosting (tuned) — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:04:00+00:00     C      144\n",
      "2025-08-11 03:05:00+00:00 2025-08-11 03:05:00+00:00     M        1\n",
      "2025-08-11 03:06:00+00:00 2025-08-11 03:47:00+00:00     C       42\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:52:00+00:00     M        5\n",
      "2025-08-11 03:53:00+00:00 2025-08-11 03:56:00+00:00     C        4\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 03:57:00+00:00     M        1\n",
      "2025-08-11 03:58:00+00:00 2025-08-11 08:39:00+00:00     C      282\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:46:00+00:00     M        7\n",
      "2025-08-11 08:47:00+00:00 2025-08-11 10:52:00+00:00     C      126\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:36:00+00:00     C       51\n",
      "2025-08-11 12:37:00+00:00 2025-08-11 12:38:00+00:00     M        2\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    698\n",
      "M     20\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.002\n",
      "C    0.970\n",
      "M    0.028\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 97.21%\n",
      " - M: 2.79%\n",
      " - X: 0.00%\n",
      "\n",
      "================ XGBoost — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:48:00+00:00     C      188\n",
      "2025-08-11 03:49:00+00:00 2025-08-11 03:54:00+00:00     M        6\n",
      "2025-08-11 03:55:00+00:00 2025-08-11 08:39:00+00:00     C      285\n",
      "2025-08-11 08:40:00+00:00 2025-08-11 08:44:00+00:00     M        5\n",
      "2025-08-11 08:45:00+00:00 2025-08-11 10:52:00+00:00     C      128\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:38:00+00:00     C       53\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    703\n",
      "M     15\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.002\n",
      "C    0.977\n",
      "M    0.021\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 97.91%\n",
      " - M: 2.09%\n",
      " - X: 0.00%\n",
      "\n",
      "================ XGBoost (tuned) — 718 minutes ================\n",
      "\n",
      "⏱️ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:04:00+00:00     C      144\n",
      "2025-08-11 03:05:00+00:00 2025-08-11 03:05:00+00:00     M        1\n",
      "2025-08-11 03:06:00+00:00 2025-08-11 03:47:00+00:00     C       42\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:56:00+00:00     M        9\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 08:38:00+00:00     C      282\n",
      "2025-08-11 08:39:00+00:00 2025-08-11 08:47:00+00:00     M        9\n",
      "2025-08-11 08:48:00+00:00 2025-08-11 10:52:00+00:00     C      125\n",
      "2025-08-11 10:53:00+00:00 2025-08-11 10:54:00+00:00     M        2\n",
      "2025-08-11 10:55:00+00:00 2025-08-11 11:43:00+00:00     C       49\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:35:00+00:00     C       50\n",
      "2025-08-11 12:36:00+00:00 2025-08-11 12:38:00+00:00     M        3\n",
      "\n",
      "📊 Comptes classes prédites (718 min) :\n",
      "pred_class\n",
      "C    692\n",
      "M     26\n",
      "\n",
      "📈 Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.001\n",
      "C    0.961\n",
      "M    0.038\n",
      "X    0.000\n",
      "\n",
      "🏆 % minutes où chaque classe est 1ère proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 96.38%\n",
      " - M: 3.62%\n",
      " - X: 0.00%\n",
      "\n",
      "🏁 Part des classes prédites sur 718 min (par modèle) :\n",
      "                            p_A   p_B    p_C    p_M  p_X\n",
      "model                                                   \n",
      "DecisionTree                0.0  0.56  97.21   2.23  0.0\n",
      "DecisionTree (tuned)        0.0  0.28  96.94   2.79  0.0\n",
      "GradientBoosting            0.0  0.00  97.49   2.51  0.0\n",
      "GradientBoosting (tuned)    0.0  0.00  97.21   2.79  0.0\n",
      "LogisticRegression          0.0  0.00  82.17  17.83  0.0\n",
      "LogisticRegression (tuned)  0.0  0.00  82.17  17.83  0.0\n",
      "RandomForest                0.0  0.00  97.91   2.09  0.0\n",
      "RandomForest (tuned)        0.0  0.00  96.52   3.48  0.0\n",
      "XGBoost                     0.0  0.00  97.91   2.09  0.0\n",
      "XGBoost (tuned)             0.0  0.00  96.38   3.62  0.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) helpers génériques\n",
    "# =========================\n",
    "H_NEXT = 718  # 12h \"observables\" dans ton dataset (peut être 720 si complet)\n",
    "\n",
    "def safe_to_datetime(s):\n",
    "    return pd.to_datetime(s.astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "def get_last_minutes_block(X_test, mask_test, Xte, minutes=H_NEXT):\n",
    "    \"\"\"Retourne X12_t (features transformées) et t12 (timestamps) pour les 'minutes' dernières minutes réelles du test.\"\"\"\n",
    "    # timeline côté X_test\n",
    "    if \"time\" in X_test.columns:\n",
    "        t_all = safe_to_datetime(X_test[\"time\"])\n",
    "    elif isinstance(X_test.index, pd.DatetimeIndex):\n",
    "        t_all = pd.to_datetime(X_test.index, utc=True, errors=\"coerce\").to_series()\n",
    "    elif \"date\" in X_test.columns:\n",
    "        t_all = safe_to_datetime(X_test[\"date\"])\n",
    "    else:\n",
    "        raise KeyError(\"Pas de colonne temps ('time' ou 'date') dans X_test.\")\n",
    "\n",
    "    # indices du test (après filtre y non-NaN) et tri par temps\n",
    "    idx_test = X_test.index[mask_test]\n",
    "    t_test_sorted = (\n",
    "        pd.DataFrame({\"time\": t_all.loc[idx_test].values}, index=idx_test)\n",
    "        .dropna()\n",
    "        .sort_values(\"time\")\n",
    "    )\n",
    "    # prendre les 'minutes' dernières\n",
    "    last_idx = t_test_sorted.tail(minutes).index\n",
    "    # positions dans Xte (qui est X_test_t[mask_test])\n",
    "    pos_map = pd.Series(range(len(idx_test)), index=idx_test)\n",
    "    sel_pos = pos_map.loc[last_idx].sort_values()\n",
    "    X_last = Xte[sel_pos.values]\n",
    "    t_last = t_test_sorted.loc[last_idx, \"time\"].sort_values().reset_index(drop=True)\n",
    "    return X_last, t_last\n",
    "\n",
    "def softmax_from_decision(scores):\n",
    "    scores = np.array(scores)\n",
    "    if scores.ndim == 1:\n",
    "        scores = np.column_stack([-scores, scores])\n",
    "    m = scores.max(axis=1, keepdims=True)\n",
    "    exp = np.exp(scores - m)\n",
    "    return exp / exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "def safe_predict_proba(estimator, X):\n",
    "    \"\"\"Renvoie (proba, classes_idx) où classes_idx = estimator.classes_ (indices compacts).\"\"\"\n",
    "    if hasattr(estimator, \"predict_proba\"):\n",
    "        p = estimator.predict_proba(X)\n",
    "        return p, estimator.classes_\n",
    "    elif hasattr(estimator, \"decision_function\"):\n",
    "        p = softmax_from_decision(estimator.decision_function(X))\n",
    "        # si le modèle ne donne pas la même shape que len(classes_), on harmonise\n",
    "        classes_ = getattr(estimator, \"classes_\", np.arange(p.shape[1]))\n",
    "        return p, classes_\n",
    "    else:\n",
    "        # fallback uniform (à éviter en prod, mais utile pour garder le flux)\n",
    "        k = len(getattr(estimator, \"classes_\", [0,1]))\n",
    "        n = X.shape[0]\n",
    "        return np.full((n, k), 1.0/k), getattr(estimator, \"classes_\", np.arange(k))\n",
    "\n",
    "def build_718_table_for_model(name, fitted_entry, X_last, t_last, ALL_CLASSES):\n",
    "    \"\"\"\n",
    "    Construit le DataFrame minute->probas/classes pour 'name' depuis fitted_pool[name].\n",
    "    fitted_entry = (clf, to_original, present)\n",
    "    \"\"\"\n",
    "    clf, to_original, present = fitted_entry\n",
    "\n",
    "    # proba sur classes COMPACTES présentes pendant l'entraînement (ex: [0,1,2] => B,C,M)\n",
    "    proba_compact, compact_classes = safe_predict_proba(clf, X_last)  # shape: (N, k_present)\n",
    "\n",
    "    # mapping compact -> global index (0..len(ALL_CLASSES)-1)\n",
    "    compact_to_global = np.vectorize(to_original.get)(compact_classes)  # ex: [1,2,3] (B,C,M)\n",
    "\n",
    "    # construire un tableau proba sur TOUTES les classes globales A..X (même si absentes)\n",
    "    dfp = pd.DataFrame(0.0, index=np.arange(len(t_last)), columns=ALL_CLASSES)\n",
    "    # nom des colonnes pour les classes présentes\n",
    "    present_names = ALL_CLASSES[compact_to_global]\n",
    "    # injecter les proba au bon endroit\n",
    "    for j, cname in enumerate(present_names):\n",
    "        dfp[cname] = proba_compact[:, j]\n",
    "\n",
    "    # ajouter time + classes dérivées\n",
    "    dfp.insert(0, \"time\", t_last.values)\n",
    "    dfp[\"pred_class\"]  = ALL_CLASSES[dfp[ALL_CLASSES].values.argmax(axis=1)]\n",
    "    dfp[\"pred_strong\"] = dfp[\"pred_class\"].isin([\"M\",\"X\"]).astype(int)\n",
    "\n",
    "    # tri par temps (sécurité)\n",
    "    dfp = dfp.dropna(subset=[\"time\"]).copy()\n",
    "    dfp[\"time\"] = pd.to_datetime(dfp[\"time\"], utc=True, errors=\"coerce\")\n",
    "    dfp = dfp.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    # plages continues\n",
    "    change = dfp[\"pred_class\"].ne(dfp[\"pred_class\"].shift(1))\n",
    "    dfp[\"_grp\"] = change.cumsum()\n",
    "    spans = (\n",
    "        dfp.groupby(\"_grp\", as_index=False)\n",
    "           .agg(start=(\"time\", \"first\"),\n",
    "                end=(\"time\", \"last\"),\n",
    "                **{\"class\": (\"pred_class\", \"first\")},\n",
    "                minutes=(\"time\", \"size\"))\n",
    "           .drop(columns=[\"_grp\"])\n",
    "    )\n",
    "    return dfp, spans\n",
    "\n",
    "def describe_718(dfp, spans, name, ALL_CLASSES):\n",
    "    print(f\"\\n================ {name} — 718 minutes ================\")\n",
    "    print(\"\\n⏱️ Plages continues :\")\n",
    "    print(spans.to_string(index=False))\n",
    "\n",
    "    print(\"\\n📊 Comptes classes prédites (718 min) :\")\n",
    "    print(dfp[\"pred_class\"].value_counts().to_string())\n",
    "\n",
    "    print(\"\\n📈 Probas moyennes (718 min) :\")\n",
    "    print(dfp[ALL_CLASSES].mean().round(3).to_string())\n",
    "\n",
    "    print(\"\\n🏆 % minutes où chaque classe est 1ère proba :\")\n",
    "    for c in ALL_CLASSES:\n",
    "        others = [x for x in ALL_CLASSES if x != c]\n",
    "        share = (dfp[c] >= dfp[others].max(axis=1)).mean() * 100\n",
    "        print(f\" - {c}: {share:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# 1) extraire X_last & t_last une seule fois\n",
    "# =========================\n",
    "X12_t, t12 = get_last_minutes_block(X_test, mask_test, Xte, minutes=H_NEXT)\n",
    "\n",
    "# =========================\n",
    "# 2) générer pour chaque modèle du pool\n",
    "# =========================\n",
    "pred_tables_718 = {}\n",
    "spans_718 = {}\n",
    "\n",
    "for name, fitted_entry in fitted_pool.items():\n",
    "    df_12h, spans = build_718_table_for_model(name, fitted_entry, X12_t, t12, ALL_CLASSES)\n",
    "    pred_tables_718[name] = df_12h\n",
    "    spans_718[name] = spans\n",
    "    # impression détaillée (tu peux commenter si trop verbeux)\n",
    "    describe_718(df_12h, spans, name, ALL_CLASSES)\n",
    "\n",
    "# =========================\n",
    "# 3) tableau comparatif des parts de classes (718 min)\n",
    "# =========================\n",
    "summary = []\n",
    "for name, dfp in pred_tables_718.items():\n",
    "    vc = dfp[\"pred_class\"].value_counts(normalize=True).reindex(ALL_CLASSES, fill_value=0.0)\n",
    "    summary.append({\"model\": name, **{f\"p_{c}\": vc.get(c, 0.0) for c in ALL_CLASSES}})\n",
    "\n",
    "summary_df = pd.DataFrame(summary).sort_values(\"model\")\n",
    "print(\"\\n🏁 Part des classes prédites sur 718 min (par modèle) :\")\n",
    "print((summary_df.set_index(\"model\") * 100).round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689f425-396b-4b74-bf3b-f9e455c9f819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4819c6-9cb7-41a1-b74f-13be01051253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed32f7b-7927-496d-811e-200dfeb5903e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c49f3-3c42-4d15-a53e-323d9070a73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28838c-db19-4b41-92c5-e6e9b4583b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1087c3e-90ce-4b0d-b165-8ca7f5d6a778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448775d5-ab73-41c3-bc70-10e2cae699bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae771a-3e5f-42e1-a80d-9327e4cca098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504ba66-b457-44f4-b296-f1ab3d9d9e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e5477-4c8e-42b1-b391-3225baa66aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
