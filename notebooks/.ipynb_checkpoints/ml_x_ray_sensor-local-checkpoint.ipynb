{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418648b9-dd97-45f2-b404-aba90b897644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb4b18a2-86d5-431d-8f5c-91fdcdfabfa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json, time\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import os, mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from evidently import Report, Dataset, DataDefinition, MulticlassClassification\n",
    "from evidently.presets import ClassificationPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab7daa5-b6c7-404f-883e-1d20cce142df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Chargement du fichier xrs_clean.parquet...\n",
      "âœ… DonnÃ©es chargÃ©es : 147639 lignes, 11 colonnes\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“¥ Chargement du fichier xrs_clean.parquet...\")\n",
    "\n",
    "parquet_path = Path(r\"C:\\Users\\gate\\Documents\\Jedha\\Projet\\4\\mlops-solar-flares\\data\\xrs_clean.parquet\")\n",
    "df = parquet_path\n",
    "df = pd.read_parquet(parquet_path, engine=\"pyarrow\")\n",
    "print(f\"âœ… DonnÃ©es chargÃ©es : {df.shape[0]} lignes, {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b84587a-232a-4029-bbd0-0ea2bc21e52b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# head: <bound method NDFrame.head of                             time  flux_long_wm2  flux_short_wm2 satellite  \\\n",
      "0      2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09      <NA>   \n",
      "1      2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09      <NA>   \n",
      "2      2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09      <NA>   \n",
      "3      2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09      <NA>   \n",
      "4      2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09      <NA>   \n",
      "...                          ...            ...             ...       ...   \n",
      "147634 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07   GOES-18   \n",
      "147635 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07   GOES-18   \n",
      "147636 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07   GOES-18   \n",
      "147637 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07   GOES-18   \n",
      "147638 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07   GOES-18   \n",
      "\n",
      "       energy_long energy_short      source        date  hour  minute_of_day  \\\n",
      "0       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              0   \n",
      "1       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              1   \n",
      "2       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              2   \n",
      "3       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              3   \n",
      "4       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              4   \n",
      "...            ...          ...         ...         ...   ...            ...   \n",
      "147634  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            754   \n",
      "147635  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            755   \n",
      "147636  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            756   \n",
      "147637  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            757   \n",
      "147638  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            758   \n",
      "\n",
      "        dow  \n",
      "0         3  \n",
      "1         3  \n",
      "2         3  \n",
      "3         3  \n",
      "4         3  \n",
      "...     ...  \n",
      "147634    0  \n",
      "147635    0  \n",
      "147636    0  \n",
      "147637    0  \n",
      "147638    0  \n",
      "\n",
      "[147639 rows x 11 columns]>\n",
      "\n",
      "# dtypes:\n",
      " time              datetime64[ns, UTC]\n",
      "flux_long_wm2                 float32\n",
      "flux_short_wm2                float32\n",
      "satellite              string[python]\n",
      "energy_long                    object\n",
      "energy_short                   object\n",
      "source                 string[python]\n",
      "date                   string[python]\n",
      "hour                            int16\n",
      "minute_of_day                   int16\n",
      "dow                              int8\n",
      "dtype: object\n",
      "\n",
      "# describe: <bound method NDFrame.describe of                             time  flux_long_wm2  flux_short_wm2 satellite  \\\n",
      "0      2025-05-01 00:00:00+00:00   7.021782e-07    1.000000e-09      <NA>   \n",
      "1      2025-05-01 00:01:00+00:00   6.994713e-07    1.000000e-09      <NA>   \n",
      "2      2025-05-01 00:02:00+00:00   7.052154e-07    1.000000e-09      <NA>   \n",
      "3      2025-05-01 00:03:00+00:00   7.015647e-07    1.000000e-09      <NA>   \n",
      "4      2025-05-01 00:04:00+00:00   6.966016e-07    1.000000e-09      <NA>   \n",
      "...                          ...            ...             ...       ...   \n",
      "147634 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07   GOES-18   \n",
      "147635 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07   GOES-18   \n",
      "147636 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07   GOES-18   \n",
      "147637 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07   GOES-18   \n",
      "147638 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07   GOES-18   \n",
      "\n",
      "       energy_long energy_short      source        date  hour  minute_of_day  \\\n",
      "0       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              0   \n",
      "1       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              1   \n",
      "2       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              2   \n",
      "3       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              3   \n",
      "4       0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01     0              4   \n",
      "...            ...          ...         ...         ...   ...            ...   \n",
      "147634  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            754   \n",
      "147635  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            755   \n",
      "147636  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            756   \n",
      "147637  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            757   \n",
      "147638  0.1-0.8 nm  0.05-0.4 nm        <NA>  2025-08-11    12            758   \n",
      "\n",
      "        dow  \n",
      "0         3  \n",
      "1         3  \n",
      "2         3  \n",
      "3         3  \n",
      "4         3  \n",
      "...     ...  \n",
      "147634    0  \n",
      "147635    0  \n",
      "147636    0  \n",
      "147637    0  \n",
      "147638    0  \n",
      "\n",
      "[147639 rows x 11 columns]>\n",
      "\n",
      "# missing (%):\n",
      "satellite         91.68\n",
      "source             8.32\n",
      "flux_long_wm2      1.11\n",
      "flux_short_wm2     1.11\n",
      "time               0.00\n",
      "energy_long        0.00\n",
      "energy_short       0.00\n",
      "date               0.00\n",
      "hour               0.00\n",
      "minute_of_day      0.00\n",
      "\n",
      "# time range: 2025-05-01 00:00:00+00:00 -> 2025-08-11 12:38:00+00:00\n",
      "# time monotonic: True\n",
      "\n",
      "# last days (rows/day):\n",
      " time\n",
      "2025-08-02 00:00:00+00:00    1440\n",
      "2025-08-03 00:00:00+00:00    1440\n",
      "2025-08-04 00:00:00+00:00    1440\n",
      "2025-08-05 00:00:00+00:00    1440\n",
      "2025-08-06 00:00:00+00:00    1440\n",
      "2025-08-07 00:00:00+00:00    1440\n",
      "2025-08-08 00:00:00+00:00    1440\n",
      "2025-08-09 00:00:00+00:00    1440\n",
      "2025-08-10 00:00:00+00:00    1440\n",
      "2025-08-11 00:00:00+00:00     759\n"
     ]
    }
   ],
   "source": [
    "def quickpeek(df, topn=10):\n",
    "\n",
    "    print(\"# head:\", df.head)\n",
    "    print(\"\\n# dtypes:\\n\", df.dtypes)\n",
    "    print(\"\\n# describe:\", df.describe)\n",
    "\n",
    "    # missing %\n",
    "    print(\"\\n# missing (%):\")\n",
    "    miss = (df.isna().mean()*100).round(2).sort_values(ascending=False)\n",
    "    print(miss.head(topn).to_string())\n",
    "\n",
    "    if \"time\" in df:\n",
    "        # conversion robuste: tente direct, sinon passe par string\n",
    "        try:\n",
    "            t = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "        except Exception:\n",
    "            t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "        print(\"\\n# time range:\", t.min(), \"->\", t.max())\n",
    "\n",
    "        t_valid = t.dropna()\n",
    "        print(\"# time monotonic:\", t_valid.is_monotonic_increasing)\n",
    "\n",
    "        # comptage par jour sans dÃ©pendre du backend Arrow\n",
    "        try:\n",
    "            per_day = t.dt.floor(\"D\").value_counts().sort_index()\n",
    "        except Exception:\n",
    "            # fallback: utiliser la colonne 'date' si dispo\n",
    "            if \"date\" in df.columns:\n",
    "                per_day = pd.to_datetime(df[\"date\"], errors=\"coerce\").value_counts().sort_index()\n",
    "            else:\n",
    "                per_day = pd.Series(dtype=\"int64\")\n",
    "\n",
    "        if len(per_day):\n",
    "            print(\"\\n# last days (rows/day):\\n\", per_day.tail(10).to_string())\n",
    "\n",
    "\n",
    "quickpeek(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be565e26-3422-49c6-b772-1ec3fd1a3418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›  CrÃ©ation de la variable cible 'flare_class'...\n",
      "âœ… Variable cible ajoutÃ©e.\n"
     ]
    }
   ],
   "source": [
    "TARGET_NAME  = \"flare_class\"\n",
    "ALL_CLASSES  = np.array([\"A\", \"B\", \"C\", \"M\", \"X\"], dtype=object)\n",
    "print(\"ðŸ›  CrÃ©ation de la variable cible 'flare_class'...\")\n",
    "\n",
    "def rule_predict(flux):\n",
    "    \"\"\"\n",
    "    Classe une Ã©ruption selon le pic de flux X (W/mÂ², 1-8 Ã…) \n",
    "    en utilisant les seuils NOAA officiels, avec A inclus.\n",
    "    \"\"\"\n",
    "    if pd.isna(flux):\n",
    "        return None\n",
    "    elif flux < 1e-7:       # A : < 10â»â· W/mÂ²\n",
    "        return \"A\"\n",
    "    elif flux < 1e-6:       # B : 10â»â· â‰¤ flux < 10â»â¶\n",
    "        return \"B\"\n",
    "    elif flux < 1e-5:       # C : 10â»â¶ â‰¤ flux < 10â»âµ\n",
    "        return \"C\"\n",
    "    elif flux < 1e-4:       # M : 10â»âµ â‰¤ flux < 10â»â´\n",
    "        return \"M\"\n",
    "    else:                   # X : â‰¥ 10â»â´\n",
    "        return \"X\"\n",
    "\n",
    "df[\"flare_class\"] = df[\"flux_long_wm2\"].apply(rule_predict)\n",
    "\n",
    "print(\"âœ… Variable cible ajoutÃ©e.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b95740f-1add-4e07-96ee-743180a4f2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“… Conversion + features temporelles (safe)â€¦\n",
      "âœ… Features crÃ©Ã©es. NaN % (top 10):\n",
      "flux_short_wm2         1.11\n",
      "flux_short_lag1        1.11\n",
      "log_flux_short_lag1    1.11\n",
      "flux_short_mean_1h     1.07\n",
      "flux_short_std_1h      1.07\n",
      "flux_short_max_1h      1.07\n",
      "flux_short_mean_3h     1.01\n",
      "flux_short_max_3h      1.01\n",
      "hour                   0.00\n",
      "minute_of_day          0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“… Conversion + features temporelles (safe)â€¦\")\n",
    "\n",
    "# -- 0) Temps propre + tri --\n",
    "if \"time\" in df.columns:\n",
    "    t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "elif isinstance(df.index, pd.DatetimeIndex):\n",
    "    t = pd.to_datetime(df.index, utc=True, errors=\"coerce\")\n",
    "elif \"date\" in df.columns:\n",
    "    t = pd.to_datetime(df[\"date\"].astype(str), utc=True, errors=\"coerce\")\n",
    "else:\n",
    "    raise KeyError(\"Pas de colonne/indice temps ('time' ou 'date').\")\n",
    "\n",
    "df = df.assign(time=t).sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "# -- 1) Colonnes temporelles dÃ©rivÃ©es --\n",
    "df[\"hour\"]           = df[\"time\"].dt.hour.astype(\"int16\")\n",
    "df[\"minute_of_day\"]  = (df[\"time\"].dt.hour * 60 + df[\"time\"].dt.minute).astype(\"int16\")\n",
    "df[\"dow\"]            = df[\"time\"].dt.dayofweek.astype(\"int8\")          # 0=lundi\n",
    "df[\"day_of_year\"]    = df[\"time\"].dt.dayofyear.astype(\"int16\")\n",
    "rad_doy              = 2 * np.pi * (df[\"day_of_year\"] - 1) / 365.25\n",
    "df[\"sin_doy\"]        = np.sin(rad_doy)\n",
    "df[\"cos_doy\"]        = np.cos(rad_doy)\n",
    "# Option: indicateur jour/nuit\n",
    "df[\"is_daytime\"]     = ((df[\"hour\"] >= 6) & (df[\"hour\"] <= 18)).astype(\"int8\")\n",
    "\n",
    "# -- 2) Features flux_short (passÃ© uniquement) --\n",
    "s = pd.to_numeric(df[\"flux_short_wm2\"], errors=\"coerce\")\n",
    "\n",
    "lag1 = s.shift(1)\n",
    "\n",
    "# rolling calculÃ© sur la sÃ©rie dÃ©calÃ©e (pas de fuite)\n",
    "roll_1h = lag1.rolling(window=12, min_periods=1)\n",
    "roll_3h = lag1.rolling(window=36, min_periods=1)\n",
    "\n",
    "df[\"flux_short_lag1\"]      = lag1\n",
    "df[\"flux_short_mean_1h\"]   = roll_1h.mean()\n",
    "df[\"flux_short_std_1h\"]    = roll_1h.std()\n",
    "df[\"flux_short_max_1h\"]    = roll_1h.max()\n",
    "df[\"flux_short_mean_3h\"]   = roll_3h.mean()\n",
    "df[\"flux_short_max_3h\"]    = roll_3h.max()\n",
    "df[\"log_flux_short_lag1\"]  = np.log10(lag1.clip(lower=1e-9))\n",
    "\n",
    "# -- 3) Au lieu d'un dropna global, on coupe seulement l'historique minimum --\n",
    "HISTORY_CUTOFF = 36  # 3h si donnÃ©es par minute; ajuste si besoin\n",
    "if len(df) > HISTORY_CUTOFF:\n",
    "    df = df.iloc[HISTORY_CUTOFF:].reset_index(drop=True)\n",
    "\n",
    "# -- 4) Diag NaN (pour vÃ©rif) --\n",
    "na_rate = (df[[\n",
    "    \"flux_short_wm2\",\"flux_short_lag1\",\"flux_short_mean_1h\",\"flux_short_std_1h\",\n",
    "    \"flux_short_max_1h\",\"flux_short_mean_3h\",\"flux_short_max_3h\",\"log_flux_short_lag1\",\n",
    "    \"hour\",\"minute_of_day\",\"dow\",\"sin_doy\",\"cos_doy\",\"is_daytime\"\n",
    "]].isna().mean()*100).round(2).sort_values(ascending=False)\n",
    "\n",
    "print(\"âœ… Features crÃ©Ã©es. NaN % (top 10):\")\n",
    "print(na_rate.head(10).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4097e4f3-055a-4498-a375-b930d6fa43bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Nettoyage des colonnes inutiles...\n",
      "âœ… Colonnes supprimÃ©es : ['satellite']\n",
      "âœ… Types harmonisÃ©s.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ§¹ Nettoyage des colonnes inutiles...\")\n",
    "# 1) Suppression de colonnes inutiles\n",
    "colonnes_a_supprimer = []\n",
    "if \"satellite\" in df.columns:\n",
    "    colonnes_a_supprimer.append(\"satellite\")\n",
    "\n",
    "df = df.drop(columns=colonnes_a_supprimer, errors=\"ignore\")\n",
    "print(f\"âœ… Colonnes supprimÃ©es : {colonnes_a_supprimer if colonnes_a_supprimer else 'Aucune'}\")\n",
    "\n",
    "# 2) Harmonisation des types (basÃ© sur ton nouveau set de features)\n",
    "numeric_features = [\n",
    "    \"flux_short_wm2\", \"hour\", \"minute_of_day\", \"dow\", \"sin_doy\",\n",
    "    \"flux_short_lag1\", \"flux_short_mean_1h\", \"flux_short_std_1h\",\n",
    "    \"flux_short_max_1h\", \"flux_short_mean_3h\", \"flux_short_max_3h\",\n",
    "    \"log_flux_short_lag1\"\n",
    "]\n",
    "categorical_features = [\"source\", \"energy_long\", \"energy_short\"]\n",
    "\n",
    "for col in numeric_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "\n",
    "print(\"âœ… Types harmonisÃ©s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f41389-f109-476c-a1dd-d75a0a28cd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Fichier sauvegardÃ© : C:\\Users\\gate\\Documents\\Jedha\\Projet\\4\\mlops-solar-flares\\data\\xrs_clean_ml.parquet\n"
     ]
    }
   ],
   "source": [
    "output_path = parquet_path.parent / \"xrs_clean_ml.parquet\"\n",
    "df.to_parquet(output_path, engine=\"pyarrow\", index=False)\n",
    "print(f\"ðŸ’¾ Fichier sauvegardÃ© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671f269e-0273-4feb-b1c3-dbaebb9ab0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# head:                        time  flux_long_wm2  flux_short_wm2 energy_long  \\\n",
      "0 2025-05-01 00:36:00+00:00   6.979719e-07    1.000000e-09  0.1-0.8 nm   \n",
      "1 2025-05-01 00:37:00+00:00   6.952811e-07    1.000000e-09  0.1-0.8 nm   \n",
      "2 2025-05-01 00:38:00+00:00   6.964259e-07    1.000000e-09  0.1-0.8 nm   \n",
      "3 2025-05-01 00:39:00+00:00   7.000616e-07    1.000000e-09  0.1-0.8 nm   \n",
      "4 2025-05-01 00:40:00+00:00   6.999362e-07    1.000000e-09  0.1-0.8 nm   \n",
      "\n",
      "  energy_short      source        date  hour  minute_of_day  dow  ...  \\\n",
      "0  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           36.0  3.0  ...   \n",
      "1  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           37.0  3.0  ...   \n",
      "2  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           38.0  3.0  ...   \n",
      "3  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           39.0  3.0  ...   \n",
      "4  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           40.0  3.0  ...   \n",
      "\n",
      "    sin_doy   cos_doy  is_daytime  flux_short_lag1  flux_short_mean_1h  \\\n",
      "0  0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
      "1  0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
      "2  0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
      "3  0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
      "4  0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
      "\n",
      "   flux_short_std_1h  flux_short_max_1h  flux_short_mean_3h  \\\n",
      "0                0.0       1.000000e-09        1.016178e-09   \n",
      "1                0.0       1.000000e-09        1.016178e-09   \n",
      "2                0.0       1.000000e-09        1.016178e-09   \n",
      "3                0.0       1.000000e-09        1.016178e-09   \n",
      "4                0.0       1.000000e-09        1.016178e-09   \n",
      "\n",
      "   flux_short_max_3h  log_flux_short_lag1  \n",
      "0       1.582413e-09                 -9.0  \n",
      "1       1.582413e-09                 -9.0  \n",
      "2       1.582413e-09                 -9.0  \n",
      "3       1.582413e-09                 -9.0  \n",
      "4       1.582413e-09                 -9.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "# dtypes:\n",
      " time                   datetime64[ns, UTC]\n",
      "flux_long_wm2                      float32\n",
      "flux_short_wm2                     float64\n",
      "energy_long                 string[python]\n",
      "energy_short                string[python]\n",
      "source                      string[python]\n",
      "date                        string[python]\n",
      "hour                               float64\n",
      "minute_of_day                      float64\n",
      "dow                                float64\n",
      "flare_class                         object\n",
      "day_of_year                          int16\n",
      "sin_doy                            float64\n",
      "cos_doy                            float64\n",
      "is_daytime                            int8\n",
      "flux_short_lag1                    float64\n",
      "flux_short_mean_1h                 float64\n",
      "flux_short_std_1h                  float64\n",
      "flux_short_max_1h                  float64\n",
      "flux_short_mean_3h                 float64\n",
      "flux_short_max_3h                  float64\n",
      "log_flux_short_lag1                float64\n",
      "dtype: object\n",
      "\n",
      "# describe:\n",
      "        flux_long_wm2  flux_short_wm2           hour  minute_of_day  \\\n",
      "count   1.459590e+05    1.459590e+05  147603.000000  147603.000000   \n",
      "mean    1.458734e-06    5.522871e-08      11.473669     717.920306   \n",
      "std     1.933495e-06    2.454358e-07       6.919764     415.541806   \n",
      "min     0.000000e+00    0.000000e+00       0.000000       0.000000   \n",
      "25%     7.573025e-07    1.000000e-09       5.000000     358.000000   \n",
      "50%     1.012920e-06    1.067829e-08      11.000000     716.000000   \n",
      "75%     1.448522e-06    3.325844e-08      17.000000    1078.000000   \n",
      "max     3.827447e-05    7.218636e-06      23.000000    1439.000000   \n",
      "\n",
      "                 dow    day_of_year        sin_doy        cos_doy  \\\n",
      "count  147603.000000  147603.000000  147603.000000  147603.000000   \n",
      "mean        3.043109     171.777139       0.177186      -0.857267   \n",
      "std         2.001335      29.590805       0.461627       0.143525   \n",
      "min         0.000000     121.000000      -0.626727      -0.999979   \n",
      "25%         1.000000     146.000000      -0.228058      -0.976509   \n",
      "50%         3.000000     172.000000       0.198648      -0.904405   \n",
      "75%         5.000000     197.000000       0.602988      -0.789905   \n",
      "max         6.000000     223.000000       0.880683      -0.473706   \n",
      "\n",
      "          is_daytime  flux_short_lag1  flux_short_mean_1h  flux_short_std_1h  \\\n",
      "count  147603.000000     1.459590e+05        1.460310e+05       1.460230e+05   \n",
      "mean        0.541717     5.522286e-08        5.520075e-08       1.704558e-08   \n",
      "std         0.498258     2.454269e-07        2.292148e-07       8.977560e-08   \n",
      "min         0.000000     0.000000e+00        0.000000e+00       0.000000e+00   \n",
      "25%         0.000000     1.000000e-09        1.324068e-09       5.948234e-10   \n",
      "50%         1.000000     1.067723e-08        1.125092e-08       2.204077e-09   \n",
      "75%         1.000000     3.325743e-08        3.440137e-08       6.233978e-09   \n",
      "max         1.000000     7.218636e-06        7.148259e-06       3.430924e-06   \n",
      "\n",
      "       flux_short_max_1h  flux_short_mean_3h  flux_short_max_3h  \\\n",
      "count       1.460310e+05        1.461110e+05       1.461110e+05   \n",
      "mean        8.305696e-08        5.520538e-08       1.357695e-07   \n",
      "std         3.249647e-07        1.984707e-07       4.446940e-07   \n",
      "min         0.000000e+00        0.000000e+00       0.000000e+00   \n",
      "25%         2.897411e-09        2.190732e-09       7.592487e-09   \n",
      "50%         1.711485e-08        1.257076e-08       2.704402e-08   \n",
      "75%         4.742508e-08        3.666942e-08       7.448698e-08   \n",
      "max         7.218636e-06        5.132329e-06       7.218636e-06   \n",
      "\n",
      "       log_flux_short_lag1  \n",
      "count        145959.000000  \n",
      "mean             -8.051616  \n",
      "std               0.793489  \n",
      "min              -9.000000  \n",
      "25%              -9.000000  \n",
      "50%              -7.971541  \n",
      "75%              -7.478111  \n",
      "max              -5.141545  \n",
      "\n",
      "# missing (%):\n",
      "source                 8.32\n",
      "log_flux_short_lag1    1.11\n",
      "flux_short_wm2         1.11\n",
      "flux_short_lag1        1.11\n",
      "flare_class            1.11\n",
      "flux_long_wm2          1.11\n",
      "flux_short_max_1h      1.07\n",
      "flux_short_std_1h      1.07\n",
      "flux_short_mean_1h     1.07\n",
      "flux_short_max_3h      1.01\n",
      "\n",
      "âœ… Aucune colonne entiÃ¨rement vide trouvÃ©e.\n",
      "\n",
      "# time range: 2025-05-01 00:36:00+00:00 -> 2025-08-11 12:38:00+00:00\n",
      "# time monotonic: True\n",
      "\n",
      "# last days (rows/day):\n",
      " time\n",
      "2025-08-02 00:00:00+00:00    1440\n",
      "2025-08-03 00:00:00+00:00    1440\n",
      "2025-08-04 00:00:00+00:00    1440\n",
      "2025-08-05 00:00:00+00:00    1440\n",
      "2025-08-06 00:00:00+00:00    1440\n",
      "2025-08-07 00:00:00+00:00    1440\n",
      "2025-08-08 00:00:00+00:00    1440\n",
      "2025-08-09 00:00:00+00:00    1440\n",
      "2025-08-10 00:00:00+00:00    1440\n",
      "2025-08-11 00:00:00+00:00     759\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flux_long_wm2</th>\n",
       "      <th>flux_short_wm2</th>\n",
       "      <th>energy_long</th>\n",
       "      <th>energy_short</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute_of_day</th>\n",
       "      <th>dow</th>\n",
       "      <th>...</th>\n",
       "      <th>sin_doy</th>\n",
       "      <th>cos_doy</th>\n",
       "      <th>is_daytime</th>\n",
       "      <th>flux_short_lag1</th>\n",
       "      <th>flux_short_mean_1h</th>\n",
       "      <th>flux_short_std_1h</th>\n",
       "      <th>flux_short_max_1h</th>\n",
       "      <th>flux_short_mean_3h</th>\n",
       "      <th>flux_short_max_3h</th>\n",
       "      <th>log_flux_short_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-01 00:36:00+00:00</td>\n",
       "      <td>6.979719e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880683</td>\n",
       "      <td>-0.473706</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.016178e-09</td>\n",
       "      <td>1.582413e-09</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-01 00:37:00+00:00</td>\n",
       "      <td>6.952811e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880683</td>\n",
       "      <td>-0.473706</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.016178e-09</td>\n",
       "      <td>1.582413e-09</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-01 00:38:00+00:00</td>\n",
       "      <td>6.964259e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880683</td>\n",
       "      <td>-0.473706</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.016178e-09</td>\n",
       "      <td>1.582413e-09</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-01 00:39:00+00:00</td>\n",
       "      <td>7.000616e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880683</td>\n",
       "      <td>-0.473706</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.016178e-09</td>\n",
       "      <td>1.582413e-09</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-01 00:40:00+00:00</td>\n",
       "      <td>6.999362e-07</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>NCEI-SunPy</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880683</td>\n",
       "      <td>-0.473706</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.016178e-09</td>\n",
       "      <td>1.582413e-09</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147598</th>\n",
       "      <td>2025-08-11 12:34:00+00:00</td>\n",
       "      <td>5.304605e-06</td>\n",
       "      <td>5.942913e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626727</td>\n",
       "      <td>-0.779239</td>\n",
       "      <td>1</td>\n",
       "      <td>4.549486e-07</td>\n",
       "      <td>1.373538e-07</td>\n",
       "      <td>1.332366e-07</td>\n",
       "      <td>4.549486e-07</td>\n",
       "      <td>8.135605e-08</td>\n",
       "      <td>4.549486e-07</td>\n",
       "      <td>-6.342038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147599</th>\n",
       "      <td>2025-08-11 12:35:00+00:00</td>\n",
       "      <td>5.992305e-06</td>\n",
       "      <td>7.550105e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626727</td>\n",
       "      <td>-0.779239</td>\n",
       "      <td>1</td>\n",
       "      <td>5.942913e-07</td>\n",
       "      <td>1.826791e-07</td>\n",
       "      <td>1.838596e-07</td>\n",
       "      <td>5.942913e-07</td>\n",
       "      <td>9.633450e-08</td>\n",
       "      <td>5.942913e-07</td>\n",
       "      <td>-6.226001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147600</th>\n",
       "      <td>2025-08-11 12:36:00+00:00</td>\n",
       "      <td>6.500120e-06</td>\n",
       "      <td>8.529071e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626727</td>\n",
       "      <td>-0.779239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.550105e-07</td>\n",
       "      <td>2.414877e-07</td>\n",
       "      <td>2.412320e-07</td>\n",
       "      <td>7.550105e-07</td>\n",
       "      <td>1.157367e-07</td>\n",
       "      <td>7.550105e-07</td>\n",
       "      <td>-6.122047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147601</th>\n",
       "      <td>2025-08-11 12:37:00+00:00</td>\n",
       "      <td>6.883591e-06</td>\n",
       "      <td>8.953128e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626727</td>\n",
       "      <td>-0.779239</td>\n",
       "      <td>1</td>\n",
       "      <td>8.529071e-07</td>\n",
       "      <td>3.084449e-07</td>\n",
       "      <td>2.897125e-07</td>\n",
       "      <td>8.529071e-07</td>\n",
       "      <td>1.378470e-07</td>\n",
       "      <td>8.529071e-07</td>\n",
       "      <td>-6.069098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147602</th>\n",
       "      <td>2025-08-11 12:38:00+00:00</td>\n",
       "      <td>7.047310e-06</td>\n",
       "      <td>8.543802e-07</td>\n",
       "      <td>0.1-0.8 nm</td>\n",
       "      <td>0.05-0.4 nm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626727</td>\n",
       "      <td>-0.779239</td>\n",
       "      <td>1</td>\n",
       "      <td>8.953128e-07</td>\n",
       "      <td>3.782425e-07</td>\n",
       "      <td>3.228239e-07</td>\n",
       "      <td>8.953128e-07</td>\n",
       "      <td>1.611068e-07</td>\n",
       "      <td>8.953128e-07</td>\n",
       "      <td>-6.048025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147603 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time  flux_long_wm2  flux_short_wm2 energy_long  \\\n",
       "0      2025-05-01 00:36:00+00:00   6.979719e-07    1.000000e-09  0.1-0.8 nm   \n",
       "1      2025-05-01 00:37:00+00:00   6.952811e-07    1.000000e-09  0.1-0.8 nm   \n",
       "2      2025-05-01 00:38:00+00:00   6.964259e-07    1.000000e-09  0.1-0.8 nm   \n",
       "3      2025-05-01 00:39:00+00:00   7.000616e-07    1.000000e-09  0.1-0.8 nm   \n",
       "4      2025-05-01 00:40:00+00:00   6.999362e-07    1.000000e-09  0.1-0.8 nm   \n",
       "...                          ...            ...             ...         ...   \n",
       "147598 2025-08-11 12:34:00+00:00   5.304605e-06    5.942913e-07  0.1-0.8 nm   \n",
       "147599 2025-08-11 12:35:00+00:00   5.992305e-06    7.550105e-07  0.1-0.8 nm   \n",
       "147600 2025-08-11 12:36:00+00:00   6.500120e-06    8.529071e-07  0.1-0.8 nm   \n",
       "147601 2025-08-11 12:37:00+00:00   6.883591e-06    8.953128e-07  0.1-0.8 nm   \n",
       "147602 2025-08-11 12:38:00+00:00   7.047310e-06    8.543802e-07  0.1-0.8 nm   \n",
       "\n",
       "       energy_short      source        date  hour  minute_of_day  dow  ...  \\\n",
       "0       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           36.0  3.0  ...   \n",
       "1       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           37.0  3.0  ...   \n",
       "2       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           38.0  3.0  ...   \n",
       "3       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           39.0  3.0  ...   \n",
       "4       0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           40.0  3.0  ...   \n",
       "...             ...         ...         ...   ...            ...  ...  ...   \n",
       "147598  0.05-0.4 nm        <NA>  2025-08-11  12.0          754.0  0.0  ...   \n",
       "147599  0.05-0.4 nm        <NA>  2025-08-11  12.0          755.0  0.0  ...   \n",
       "147600  0.05-0.4 nm        <NA>  2025-08-11  12.0          756.0  0.0  ...   \n",
       "147601  0.05-0.4 nm        <NA>  2025-08-11  12.0          757.0  0.0  ...   \n",
       "147602  0.05-0.4 nm        <NA>  2025-08-11  12.0          758.0  0.0  ...   \n",
       "\n",
       "         sin_doy   cos_doy  is_daytime  flux_short_lag1  flux_short_mean_1h  \\\n",
       "0       0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
       "1       0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
       "2       0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
       "3       0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
       "4       0.880683 -0.473706           0     1.000000e-09        1.000000e-09   \n",
       "...          ...       ...         ...              ...                 ...   \n",
       "147598 -0.626727 -0.779239           1     4.549486e-07        1.373538e-07   \n",
       "147599 -0.626727 -0.779239           1     5.942913e-07        1.826791e-07   \n",
       "147600 -0.626727 -0.779239           1     7.550105e-07        2.414877e-07   \n",
       "147601 -0.626727 -0.779239           1     8.529071e-07        3.084449e-07   \n",
       "147602 -0.626727 -0.779239           1     8.953128e-07        3.782425e-07   \n",
       "\n",
       "        flux_short_std_1h  flux_short_max_1h  flux_short_mean_3h  \\\n",
       "0            0.000000e+00       1.000000e-09        1.016178e-09   \n",
       "1            0.000000e+00       1.000000e-09        1.016178e-09   \n",
       "2            0.000000e+00       1.000000e-09        1.016178e-09   \n",
       "3            0.000000e+00       1.000000e-09        1.016178e-09   \n",
       "4            0.000000e+00       1.000000e-09        1.016178e-09   \n",
       "...                   ...                ...                 ...   \n",
       "147598       1.332366e-07       4.549486e-07        8.135605e-08   \n",
       "147599       1.838596e-07       5.942913e-07        9.633450e-08   \n",
       "147600       2.412320e-07       7.550105e-07        1.157367e-07   \n",
       "147601       2.897125e-07       8.529071e-07        1.378470e-07   \n",
       "147602       3.228239e-07       8.953128e-07        1.611068e-07   \n",
       "\n",
       "        flux_short_max_3h  log_flux_short_lag1  \n",
       "0            1.582413e-09            -9.000000  \n",
       "1            1.582413e-09            -9.000000  \n",
       "2            1.582413e-09            -9.000000  \n",
       "3            1.582413e-09            -9.000000  \n",
       "4            1.582413e-09            -9.000000  \n",
       "...                   ...                  ...  \n",
       "147598       4.549486e-07            -6.342038  \n",
       "147599       5.942913e-07            -6.226001  \n",
       "147600       7.550105e-07            -6.122047  \n",
       "147601       8.529071e-07            -6.069098  \n",
       "147602       8.953128e-07            -6.048025  \n",
       "\n",
       "[147603 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quickpeek(df, topn=10):\n",
    "\n",
    "    print(\"# head:\", df.head())\n",
    "    print(\"\\n# dtypes:\\n\", df.dtypes)\n",
    "    print(\"\\n# describe:\\n\", df.describe())\n",
    "\n",
    "    # missing %\n",
    "    print(\"\\n# missing (%):\")\n",
    "    miss = (df.isna().mean() * 100).round(2).sort_values(ascending=False)\n",
    "    print(miss.head(topn).to_string())\n",
    "\n",
    "    # ðŸ”¹ Suppression des colonnes entiÃ¨rement vides\n",
    "    colonnes_vides = df.columns[df.isna().all()].tolist()\n",
    "    if colonnes_vides:\n",
    "        print(f\"\\nðŸ—‘ Suppression de {len(colonnes_vides)} colonne(s) vide(s) : {colonnes_vides}\")\n",
    "        df.drop(columns=colonnes_vides, inplace=True)\n",
    "    else:\n",
    "        print(\"\\nâœ… Aucune colonne entiÃ¨rement vide trouvÃ©e.\")\n",
    "\n",
    "    if \"time\" in df:\n",
    "        # conversion robuste: tente direct, sinon passe par string\n",
    "        try:\n",
    "            t = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "        except Exception:\n",
    "            t = pd.to_datetime(df[\"time\"].astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "        print(\"\\n# time range:\", t.min(), \"->\", t.max())\n",
    "        t_valid = t.dropna()\n",
    "        print(\"# time monotonic:\", t_valid.is_monotonic_increasing)\n",
    "\n",
    "        # comptage par jour\n",
    "        try:\n",
    "            per_day = t.dt.floor(\"D\").value_counts().sort_index()\n",
    "        except Exception:\n",
    "            if \"date\" in df.columns:\n",
    "                per_day = pd.to_datetime(df[\"date\"], errors=\"coerce\").value_counts().sort_index()\n",
    "            else:\n",
    "                per_day = pd.Series(dtype=\"int64\")\n",
    "\n",
    "        if len(per_day):\n",
    "            print(\"\\n# last days (rows/day):\\n\", per_day.tail(10).to_string())\n",
    "\n",
    "    return df  # On retourne le DataFrame propre\n",
    "quickpeek(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54cede2f-877e-4fe0-b459-aac86bb3f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ DerniÃ¨res lignes du fichier :\n",
      "                     time  flux_long_wm2  flux_short_wm2 energy_long energy_short source       date  hour  minute_of_day  dow flare_class  day_of_year   sin_doy   cos_doy  is_daytime  flux_short_lag1  flux_short_mean_1h  flux_short_std_1h  flux_short_max_1h  flux_short_mean_3h  flux_short_max_3h  log_flux_short_lag1\n",
      "2025-08-11 12:29:00+00:00       0.000002    8.580523e-08  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          749.0  0.0           C          223 -0.626727 -0.779239           1     8.022680e-08        6.054497e-08       1.180990e-08       8.116984e-08        5.594103e-08       8.116984e-08            -7.095681\n",
      "2025-08-11 12:30:00+00:00       0.000002    1.043969e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          750.0  0.0           C          223 -0.626727 -0.779239           1     8.580523e-08        6.257249e-08       1.388949e-08       8.580523e-08        5.660375e-08       8.580523e-08            -7.066486\n",
      "2025-08-11 12:31:00+00:00       0.000003    2.087382e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          751.0  0.0           C          223 -0.626727 -0.779239           1     1.043969e-07        6.616177e-08       1.837793e-08       1.043969e-07        5.787996e-08       1.043969e-07            -6.981312\n",
      "2025-08-11 12:32:00+00:00       0.000004    3.514351e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          752.0  0.0           C          223 -0.626727 -0.779239           1     2.087382e-07        7.882645e-08       4.475203e-08       2.087382e-07        6.206778e-08       2.087382e-07            -6.680398\n",
      "2025-08-11 12:33:00+00:00       0.000004    4.549486e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          753.0  0.0           C          223 -0.626727 -0.779239           1     3.514351e-07        1.037625e-07       8.953171e-08       3.514351e-07        7.028950e-08       3.514351e-07            -6.454155\n",
      "2025-08-11 12:34:00+00:00       0.000005    5.942913e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          754.0  0.0           C          223 -0.626727 -0.779239           1     4.549486e-07        1.373538e-07       1.332366e-07       4.549486e-07        8.135605e-08       4.549486e-07            -6.342038\n",
      "2025-08-11 12:35:00+00:00       0.000006    7.550105e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          755.0  0.0           C          223 -0.626727 -0.779239           1     5.942913e-07        1.826791e-07       1.838596e-07       5.942913e-07        9.633450e-08       5.942913e-07            -6.226001\n",
      "2025-08-11 12:36:00+00:00       0.000007    8.529071e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          756.0  0.0           C          223 -0.626727 -0.779239           1     7.550105e-07        2.414877e-07       2.412320e-07       7.550105e-07        1.157367e-07       7.550105e-07            -6.122047\n",
      "2025-08-11 12:37:00+00:00       0.000007    8.953128e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          757.0  0.0           C          223 -0.626727 -0.779239           1     8.529071e-07        3.084449e-07       2.897125e-07       8.529071e-07        1.378470e-07       8.529071e-07            -6.069098\n",
      "2025-08-11 12:38:00+00:00       0.000007    8.543802e-07  0.1-0.8 nm  0.05-0.4 nm   <NA> 2025-08-11  12.0          758.0  0.0           C          223 -0.626727 -0.779239           1     8.953128e-07        3.782425e-07       3.228239e-07       8.953128e-07        1.611068e-07       8.953128e-07            -6.048025\n",
      "\n",
      "ðŸ“„ PremiÃ¨res lignes du fichier triÃ© par 'time' :\n",
      "                       time  flux_long_wm2  flux_short_wm2 energy_long energy_short      source        date  hour  minute_of_day  dow flare_class  day_of_year   sin_doy   cos_doy  is_daytime  flux_short_lag1  flux_short_mean_1h  flux_short_std_1h  flux_short_max_1h  flux_short_mean_3h  flux_short_max_3h  log_flux_short_lag1\n",
      "0 2025-05-01 00:36:00+00:00   6.979719e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           36.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "1 2025-05-01 00:37:00+00:00   6.952811e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           37.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "2 2025-05-01 00:38:00+00:00   6.964259e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           38.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "3 2025-05-01 00:39:00+00:00   7.000616e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           39.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "4 2025-05-01 00:40:00+00:00   6.999362e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           40.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "5 2025-05-01 00:41:00+00:00   6.941411e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           41.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "6 2025-05-01 00:42:00+00:00   6.976728e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           42.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "7 2025-05-01 00:43:00+00:00   7.020463e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           43.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "8 2025-05-01 00:44:00+00:00   7.050160e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           44.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n",
      "9 2025-05-01 00:45:00+00:00   7.064747e-07    1.000000e-09  0.1-0.8 nm  0.05-0.4 nm  NCEI-SunPy  2025-05-01   0.0           45.0  3.0           B          121  0.880683 -0.473706           0     1.000000e-09        1.000000e-09                0.0       1.000000e-09        1.016178e-09       1.582413e-09                 -9.0\n"
     ]
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# DerniÃ¨res lignes triÃ©es par temps\n",
    "print(\"\\nðŸ“„ DerniÃ¨res lignes du fichier :\")\n",
    "print(df.sort_values(\"time\").tail(10).to_string(index=False))\n",
    "\n",
    "# PremiÃ¨res lignes triÃ©es par temps\n",
    "print(\"\\nðŸ“„ PremiÃ¨res lignes du fichier triÃ© par 'time' :\")\n",
    "print(df.sort_values(\"time\").head(10).reset_index(drop=True).to_string(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497ebe3-e3af-41ec-9432-7e353af8672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19e3c019-3e72-4f70-8378-43eae048a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cible prÃªte.\n",
      "âœ‚ï¸ Coupure au temps 2025-08-04 20:48:00+00:00 | train=138,012 | test=9,591\n",
      "  Train counts: {'B': 71093, 'C': 64161, 'M': 1095, 'A': 19}\n",
      "  Test counts : {'C': 9029, 'M': 256, 'B': 156, 'A': 150}\n",
      "ðŸ§© Padding X (report only) prÃªt: 2 ligne(s).\n",
      "âœ… Features sÃ©lectionnÃ©es (sans fuite) :\n",
      "  Num : ['flux_short_wm2', 'hour', 'minute_of_day', 'dow']\n",
      "  Cat : ['source', 'energy_long', 'energy_short']\n",
      "ðŸ§¹ Nettoyage des valeurs manquantes...\n",
      "  flux_short_wm2: mÃ©diane=0.000000\n",
      "  hour: mÃ©diane=11.000000\n",
      "  minute_of_day: mÃ©diane=719.000000\n",
      "  dow: mÃ©diane=3.000000\n",
      "  source: mode='NCEI-SunPy'\n",
      "  energy_long: mode='0.1-0.8 nm'\n",
      "  energy_short: mode='0.05-0.4 nm'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gate\\AppData\\Local\\Temp\\ipykernel_24196\\1581244355.py:78: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_times = pd.date_range(start=start_pad, periods=N_PAD_X, freq=\"H\", tz=\"UTC\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DonnÃ©es nettoyÃ©es\n",
      "âš™ï¸ CrÃ©ation du preprocessor simplifiÃ©...\n",
      "ðŸ”„ Transformation des donnÃ©es...\n",
      "âœ… Transformation terminÃ©e. Shapes : (138012, 8) (9591, 8)\n",
      "ðŸŽ¯ PrÃ©paration des cibles...\n",
      "âœ… Encodage labels OK. Classes : ['A', 'B', 'C', 'M', 'X']\n",
      "   RÃ©partition train : {'B': 71093, 'C': 64161, 'M': 1095, 'A': 19}\n",
      "   RÃ©partition test  : {'C': 9029, 'M': 256, 'B': 156, 'A': 150}\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cible \n",
    "# ============================\n",
    "def classify_flare(flux):\n",
    "    if pd.isna(flux): return None\n",
    "    elif flux < 1e-7: return \"A\"\n",
    "    elif flux < 1e-6: return \"B\"\n",
    "    elif flux < 1e-5: return \"C\"\n",
    "    elif flux < 1e-4: return \"M\"\n",
    "    else: return \"X\"\n",
    "\n",
    "if TARGET_NAME not in df.columns:\n",
    "    if \"flux_long_wm2\" not in df.columns:\n",
    "        raise KeyError(\"Colonne 'flux_long_wm2' manquante : impossible de construire la cible.\")\n",
    "    print(\"ðŸ›  CrÃ©ation de la variable cible 'flare_class' Ã  partir de flux_long_wm2...\")\n",
    "    df[TARGET_NAME] = df[\"flux_long_wm2\"].apply(classify_flare)\n",
    "print(\"âœ… Cible prÃªte.\")\n",
    "# ============================\n",
    "# Split temporel\n",
    "# ============================\n",
    "\"\"\"\n",
    "print(\"âœ‚ï¸ Split train/test (80/20, ordre temporel conservÃ©)...\")\n",
    "Y = df[TARGET_NAME].astype(\"string\")\n",
    "X = df.drop(columns=[TARGET_NAME])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=0, shuffle=False\n",
    ")\n",
    "print(f\"  - Train : {len(X_train)}\")\n",
    "print(f\"  - Test  : {len(X_test)}\")\n",
    "\"\"\"\n",
    "# ============================\n",
    "# Split temporel + contrainte sur A + padding X (report only)\n",
    "# ============================\n",
    "assert \"time\" in df.columns, \"La colonne 'time' doit exister et Ãªtre de type datetime.\"\n",
    "df = df.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "TARGET_COL = TARGET_NAME           # ex: \"flare_class\"\n",
    "TEST_FRAC  = 0.20                  # cible 80/20 si possible\n",
    "MIN_IN_TRAIN = {\"A\": 20}           # au moins 20 'A' dans le train (adapte si besoin)\n",
    "MIN_TEST_FRAC = 0.05               # garde au moins 5% pour le test si 80/20 impossible\n",
    "\n",
    "y_all = df[TARGET_COL].astype(str)\n",
    "n = len(df)\n",
    "idx_80 = int(round(n * (1 - TEST_FRAC)))\n",
    "idx_test_min = int(round(n * MIN_TEST_FRAC))\n",
    "\n",
    "# cumul par classe pour trouver la 1Ã¨re position oÃ¹ on atteint les seuils demandÃ©s\n",
    "dummies = pd.get_dummies(y_all)\n",
    "for c, k in MIN_IN_TRAIN.items():\n",
    "    if c not in dummies.columns:\n",
    "        dummies[c] = 0\n",
    "cum = dummies.cumsum()\n",
    "\n",
    "ok = pd.Series(True, index=cum.index)\n",
    "for c, k in MIN_IN_TRAIN.items():\n",
    "    ok &= (cum[c] >= int(k))\n",
    "\n",
    "if ok.any():\n",
    "    first_ok_pos = int(np.argmax(ok.values))   # 1er index oÃ¹ la contrainte est satisfaite\n",
    "else:\n",
    "    first_ok_pos = 0  # jamais atteint -> on laissera le split 80/20 par dÃ©faut\n",
    "\n",
    "# choix du cutoff: 80/20 si possible, sinon on dÃ©cale pour respecter le mini A\n",
    "cutoff_idx = max(idx_80, first_ok_pos)\n",
    "\n",
    "# ne pas dÃ©passer la fin (laisser au moins MIN_TEST_FRAC en test)\n",
    "cutoff_idx = min(cutoff_idx, n - max(1, idx_test_min))\n",
    "cutoff_idx = max(1, min(cutoff_idx, n - 1))  # bornes de sÃ©curitÃ©\n",
    "\n",
    "cutoff_time = df.loc[cutoff_idx, \"time\"]\n",
    "\n",
    "# applique le split\n",
    "X_train = df.iloc[:cutoff_idx].drop(columns=[TARGET_COL])\n",
    "Y_train = df.iloc[:cutoff_idx][TARGET_COL].astype(\"string\")\n",
    "X_test  = df.iloc[cutoff_idx:].drop(columns=[TARGET_COL])\n",
    "Y_test  = df.iloc[cutoff_idx:][TARGET_COL].astype(\"string\")\n",
    "\n",
    "print(f\"âœ‚ï¸ Coupure au temps {cutoff_time} | train={len(X_train):,} | test={len(X_test):,}\")\n",
    "print(\"  Train counts:\", Y_train.value_counts().to_dict())\n",
    "print(\"  Test counts :\", Y_test.value_counts().to_dict())\n",
    "\n",
    "# ============================\n",
    "# Padding X pour le REPORTING UNIQUEMENT (n'impacte pas train/test)\n",
    "# ============================\n",
    "# ðŸ‘‰ Renseigne ici des timestamps externes rÃ©els si tu en as (NOAA/SWPC).\n",
    "# Par dÃ©faut on gÃ©nÃ¨re 2 timestamps factices juste aprÃ¨s la fin du test.\n",
    "N_PAD_X = 2  # mets 0 si tu ne veux pas de padding\n",
    "if N_PAD_X > 0:\n",
    "    start_pad = pd.to_datetime(X_test[\"time\"].max()) + pd.Timedelta(minutes=1)\n",
    "    pad_times = pd.date_range(start=start_pad, periods=N_PAD_X, freq=\"H\", tz=\"UTC\")\n",
    "\n",
    "    REPORT_PAD_X = pd.DataFrame({\n",
    "        \"when_utc\": pad_times,\n",
    "        \"target\": [\"X\"] * N_PAD_X,        # vÃ©ritÃ© terrain (pour visuels/rapports)\n",
    "        \"prediction\": [\"X\"] * N_PAD_X,    # âš ï¸ pour le REPORT UNIQUEMENT\n",
    "        \"_external\": True\n",
    "    })\n",
    "else:\n",
    "    REPORT_PAD_X = pd.DataFrame(columns=[\"when_utc\", \"target\", \"prediction\", \"_external\"])\n",
    "\n",
    "print(f\"ðŸ§© Padding X (report only) prÃªt: {len(REPORT_PAD_X)} ligne(s).\")\n",
    "\n",
    "def apply_report_padding(cur_df, pad_df=REPORT_PAD_X):\n",
    "    \"\"\"\n",
    "    Ã€ appeler APRÃˆS avoir construit cur_df = DataFrame({'target': y_test_txt, 'prediction': yhat_txt})\n",
    "    Retourne cur_df enrichi des lignes pad X pour le reporting (Evidently / HTML).\n",
    "    \"\"\"\n",
    "    if pad_df is None or len(pad_df) == 0:\n",
    "        return cur_df.copy()\n",
    "    cols = [c for c in [\"target\", \"prediction\", \"when_utc\", \"_external\"] if c in pad_df.columns]\n",
    "    return pd.concat([cur_df, pad_df[cols]], ignore_index=True)\n",
    "\n",
    "# ============================\n",
    "# DÃ©finition des features (âš ï¸ sans flux_long_wm2 pour Ã©viter la fuite)\n",
    "# ============================\n",
    "# Candidats habituels :\n",
    "numeric_features_all      = [\"flux_short_wm2\", \"hour\", \"minute_of_day\", \"dow\"]\n",
    "categorical_features_all  = [\"source\", \"energy_long\", \"energy_short\"]\n",
    "\n",
    "# Garder seulement celles qui existent rÃ©ellement\n",
    "numeric_features     = [c for c in numeric_features_all if c in X_train.columns]\n",
    "categorical_features = [c for c in categorical_features_all if c in X_train.columns]\n",
    "\n",
    "print(\"âœ… Features sÃ©lectionnÃ©es (sans fuite) :\")\n",
    "print(\"  Num :\", numeric_features)\n",
    "print(\"  Cat :\", categorical_features)\n",
    "\n",
    "# ============================\n",
    "# Nettoyage manuel des valeurs manquantes AVANT preprocessing\n",
    "# ============================\n",
    "print(\"ðŸ§¹ Nettoyage des valeurs manquantes...\")\n",
    "\n",
    "def clean_missing_values(X_train, X_test, numeric_cols, categorical_cols):\n",
    "    \"\"\"Nettoie manuellement les valeurs manquantes pour Ã©viter les bugs SimpleImputer\"\"\"\n",
    "    X_train_clean = X_train.copy()\n",
    "    X_test_clean = X_test.copy()\n",
    "    \n",
    "    # Pour les features numÃ©riques : remplacer par la mÃ©diane du train\n",
    "    for col in numeric_cols:\n",
    "        if col in X_train_clean.columns:\n",
    "            # Conversion en float64 propre\n",
    "            X_train_clean[col] = pd.to_numeric(X_train_clean[col], errors=\"coerce\")\n",
    "            X_test_clean[col] = pd.to_numeric(X_test_clean[col], errors=\"coerce\")\n",
    "            \n",
    "            # Calculer la mÃ©diane sur le train\n",
    "            median_val = X_train_clean[col].median()\n",
    "            if pd.isna(median_val):\n",
    "                median_val = 0.0  # fallback si tout est NaN\n",
    "            \n",
    "            # Remplacer les NaN\n",
    "            X_train_clean[col] = X_train_clean[col].fillna(median_val)\n",
    "            X_test_clean[col] = X_test_clean[col].fillna(median_val)\n",
    "            \n",
    "            print(f\"  {col}: mÃ©diane={median_val:.6f}\")\n",
    "    \n",
    "    # Pour les features catÃ©gorielles : remplacer par le mode du train\n",
    "    for col in categorical_cols:\n",
    "        if col in X_train_clean.columns:\n",
    "            # Conversion en object propre\n",
    "            X_train_clean[col] = X_train_clean[col].astype(str)\n",
    "            X_test_clean[col] = X_test_clean[col].astype(str)\n",
    "            \n",
    "            # Calculer le mode sur le train (ignorer les 'nan' string)\n",
    "            mode_candidates = X_train_clean[col][X_train_clean[col] != 'nan'].mode()\n",
    "            if len(mode_candidates) > 0:\n",
    "                mode_val = mode_candidates.iloc[0]\n",
    "            else:\n",
    "                mode_val = \"unknown\"  # fallback\n",
    "            \n",
    "            # Remplacer les NaN (maintenant string 'nan')\n",
    "            X_train_clean[col] = X_train_clean[col].replace('nan', mode_val)\n",
    "            X_test_clean[col] = X_test_clean[col].replace('nan', mode_val)\n",
    "            \n",
    "            print(f\"  {col}: mode='{mode_val}'\")\n",
    "    \n",
    "    return X_train_clean, X_test_clean\n",
    "\n",
    "# Appliquer le nettoyage\n",
    "X_train_clean, X_test_clean = clean_missing_values(\n",
    "    X_train, X_test, numeric_features, categorical_features\n",
    ")\n",
    "\n",
    "# Restreindre aux colonnes utiles (ordre fixe)\n",
    "X_train_final = X_train_clean[numeric_features + categorical_features].copy()\n",
    "X_test_final = X_test_clean[numeric_features + categorical_features].copy()\n",
    "\n",
    "print(\"âœ… DonnÃ©es nettoyÃ©es\")\n",
    "\n",
    "# ============================\n",
    "# PrÃ©processeur simplifiÃ© (sans SimpleImputer)\n",
    "# ============================\n",
    "print(\"âš™ï¸ CrÃ©ation du preprocessor simplifiÃ©...\")\n",
    "\n",
    "numeric_transformer = StandardScaler()  # Plus de SimpleImputer\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# Transformation\n",
    "# ============================\n",
    "print(\"ðŸ”„ Transformation des donnÃ©es...\")\n",
    "try:\n",
    "    X_train_t = preprocessor.fit_transform(X_train_final)\n",
    "    X_test_t  = preprocessor.transform(X_test_final)\n",
    "    print(\"âœ… Transformation terminÃ©e. Shapes :\", X_train_t.shape, X_test_t.shape)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur transformation: {e}\")\n",
    "    print(\"Debug - VÃ©rification des donnÃ©es:\")\n",
    "    print(\"X_train dtypes:\", X_train_final.dtypes.to_dict())\n",
    "    print(\"X_test dtypes:\", X_test_final.dtypes.to_dict())\n",
    "    \n",
    "    # VÃ©rifier s'il y a encore des NaN\n",
    "    for col in X_train_final.columns:\n",
    "        nan_count_train = X_train_final[col].isna().sum()\n",
    "        nan_count_test = X_test_final[col].isna().sum()\n",
    "        if nan_count_train > 0 or nan_count_test > 0:\n",
    "            print(f\"  {col}: {nan_count_train} NaN train, {nan_count_test} NaN test\")\n",
    "    raise\n",
    "\n",
    "# ============================\n",
    "# PrÃ©paration cibles & encodage labels\n",
    "# ============================\n",
    "print(\"ðŸŽ¯ PrÃ©paration des cibles...\")\n",
    "mask_train = Y_train.notna()\n",
    "mask_test  = Y_test.notna()\n",
    "\n",
    "Xtr = X_train_t[mask_train.values]\n",
    "Xte = X_test_t[mask_test.values]\n",
    "ytr = Y_train[mask_train].astype(str).values\n",
    "yte = Y_test[mask_test].astype(str).values\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(ALL_CLASSES)                 # mapping figÃ© A,B,C,M,X -> 0..4\n",
    "ytr_enc = le.transform(ytr)\n",
    "yte_enc = le.transform(yte)\n",
    "\n",
    "print(\"âœ… Encodage labels OK. Classes :\", list(le.classes_))\n",
    "print(\"   RÃ©partition train :\", pd.Series(ytr).value_counts().to_dict())\n",
    "print(\"   RÃ©partition test  :\", pd.Series(yte).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60bed8d7-77cd-4788-be64-cda97edc5484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : {'A': 19, 'B': 71093, 'C': 64161, 'M': 1095, 'X': 0}\n",
      "Test  : {'A': 150, 'B': 156, 'C': 9029, 'M': 256, 'X': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train :\", {c: sum(ytr_enc == i) for i, c in enumerate(ALL_CLASSES)})\n",
    "print(\"Test  :\", {c: sum(yte_enc == i) for i, c in enumerate(ALL_CLASSES)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b62364a9-92c0-4bfa-9049-6f8d0a973b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === On suppose que Xtr, Xte, ytr_enc, yte_enc, ALL_CLASSES existent dÃ©jÃ  ===\n",
    "\n",
    "# --- Helpers manquants ---\n",
    "def make_sample_weight(weights_by_name, y_enc, all_classes):\n",
    "    \"\"\"Construit sample_weight Ã  partir d'un dict de poids par label (noms).\"\"\"\n",
    "    idx2name = {i: c for i, c in enumerate(all_classes)}\n",
    "    weights_by_idx = {i: float(weights_by_name.get(idx2name[i], 1.0)) for i in range(len(all_classes))}\n",
    "    return np.vectorize(weights_by_idx.get)(y_enc)\n",
    "\n",
    "def predict_with_thresholds(clf, X, all_classes, class_thresholds=None):\n",
    "    \"\"\"\n",
    "    PrÃ©dit avec seuils par classe (ex: {'X':0.05}). \n",
    "    Retourne (y_hat_indices_globaux, proba_full[K=nb classes globales]).\n",
    "    \"\"\"\n",
    "    proba = clf.predict_proba(X)           # (n, k_present)\n",
    "    present = clf.classes_                 # indices prÃ©sents\n",
    "    K = len(all_classes)\n",
    "    proba_full = np.zeros((proba.shape[0], K), dtype=float)\n",
    "    proba_full[:, present] = proba\n",
    "    y_hat = np.argmax(proba_full, axis=1)\n",
    "\n",
    "    if class_thresholds:\n",
    "        for cname, thr in class_thresholds.items():\n",
    "            if cname in list(all_classes):\n",
    "                j = int(np.where(all_classes == cname)[0][0])\n",
    "                mask = proba_full[:, j] >= float(thr)\n",
    "                y_hat[mask] = j\n",
    "    return y_hat, proba_full\n",
    "\n",
    "def evaluate_with_custom_preds(name, ytr_true, ytr_hat, yte_true, yte_hat, ALL_CLASSES):\n",
    "    \"\"\"Ã‰value Ã  partir de prÃ©dictions dÃ©jÃ  calculÃ©es (utile avec des seuils).\"\"\"\n",
    "    acc_tr  = accuracy_score(ytr_true, ytr_hat)\n",
    "    bacc_tr = balanced_accuracy_score(ytr_true, ytr_hat)\n",
    "    f1m_tr  = f1_score(ytr_true, ytr_hat, average=\"macro\")\n",
    "    f1w_tr  = f1_score(ytr_true, ytr_hat, average=\"weighted\")\n",
    "\n",
    "    acc_te  = accuracy_score(yte_true, yte_hat)\n",
    "    bacc_te = balanced_accuracy_score(yte_true, yte_hat)\n",
    "    f1m_te  = f1_score(yte_true, yte_hat, average=\"macro\")\n",
    "    f1w_te  = f1_score(yte_true, yte_hat, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n========== {name} ==========\")\n",
    "    print(\"ðŸ“Š Train :\", f\"acc={acc_tr:.4f} | bacc={bacc_tr:.4f} | f1m={f1m_tr:.4f} | f1w={f1w_tr:.4f}\")\n",
    "    print(\"ðŸ“Š Test  :\",  f\"acc={acc_te:.4f} | bacc={bacc_te:.4f} | f1m={f1m_te:.4f} | f1w={f1w_te:.4f}\")\n",
    "\n",
    "    print(\"\\nðŸ§¾ Classification report (test)\")\n",
    "    print(classification_report(\n",
    "        yte_true, yte_hat,\n",
    "        labels=np.arange(len(ALL_CLASSES)),\n",
    "        target_names=ALL_CLASSES,\n",
    "        zero_division=0\n",
    "    ))\n",
    "\n",
    "    cm = confusion_matrix(yte_true, yte_hat, labels=np.arange(len(ALL_CLASSES)))\n",
    "    print(\"\\nðŸ§© Confusion matrix (counts)\\n\",\n",
    "          pd.DataFrame(cm,\n",
    "              index=[f\"true_{c}\" for c in ALL_CLASSES],\n",
    "              columns=[f\"pred_{c}\" for c in ALL_CLASSES]).to_string())\n",
    "    row_sums = cm.sum(axis=1, keepdims=True)\n",
    "    cmn = np.divide(cm, row_sums, out=np.zeros_like(cm, dtype=float), where=row_sums!=0)\n",
    "    print(\"\\nðŸ§© Confusion matrix (per-class)\\n\",\n",
    "          pd.DataFrame(cmn,\n",
    "              index=[f\"true_{c}\" for c in ALL_CLASSES],\n",
    "              columns=[f\"pred_{c}\" for c in ALL_CLASSES]).round(3).to_string())\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"acc_train\": acc_tr, \"bacc_train\": bacc_tr, \"f1m_train\": f1m_tr, \"f1w_train\": f1w_tr,\n",
    "        \"acc_test\":  acc_te, \"bacc_test\":  bacc_te, \"f1m_test\":  f1m_te, \"f1w_test\":  f1w_te\n",
    "    }\n",
    "\n",
    "# --- Objets communs ---\n",
    "sample_weight_tr = compute_sample_weight(class_weight=\"balanced\", y=ytr_enc)\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# --- Conteneurs : crÃ©er s'ils n'existent pas dÃ©jÃ  (Ã©vite d'Ã©craser aprÃ¨s un premier run) ---\n",
    "if \"results_list\" not in globals():\n",
    "    results_list = []\n",
    "if \"fitted_pool\" not in globals():\n",
    "    fitted_pool = {}\n",
    "\n",
    "def add_model_result(name, clf, present, to_original, res_dict, yhat):\n",
    "    results_list.append({\"model\": name, **res_dict})\n",
    "    fitted_pool[name] = (clf, to_original, present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1125c1b7-a85a-4e28-88ab-54871910332a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== GradientBoosting (X-focus + seuil X) ==========\n",
      "ðŸ“Š Train : acc=0.8374 | bacc=0.9062 | f1m=0.9004 | f1w=0.8371\n",
      "ðŸ“Š Test  : acc=0.9763 | bacc=0.7660 | f1m=0.8145 | f1w=0.9738\n",
      "\n",
      "ðŸ§¾ Classification report (test)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00       150\n",
      "           B       0.84      0.38      0.52       156\n",
      "           C       0.98      0.99      0.99      9029\n",
      "           M       0.82      0.69      0.75       256\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98      9591\n",
      "   macro avg       0.73      0.61      0.65      9591\n",
      "weighted avg       0.97      0.98      0.97      9591\n",
      "\n",
      "\n",
      "ðŸ§© Confusion matrix (counts)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     150       0       0       0       0\n",
      "true_B       0      59      97       0       0\n",
      "true_C       0      11    8978      40       0\n",
      "true_M       0       0      79     177       0\n",
      "true_X       0       0       0       0       0\n",
      "\n",
      "ðŸ§© Confusion matrix (per-class)\n",
      "         pred_A  pred_B  pred_C  pred_M  pred_X\n",
      "true_A     1.0   0.000   0.000   0.000     0.0\n",
      "true_B     0.0   0.378   0.622   0.000     0.0\n",
      "true_C     0.0   0.001   0.994   0.004     0.0\n",
      "true_M     0.0   0.000   0.309   0.691     0.0\n",
      "true_X     0.0   0.000   0.000   0.000     0.0\n"
     ]
    }
   ],
   "source": [
    "# --- GBM focalisÃ© X : poids + seuil ---\n",
    "weights_X_focus = {\"A\":1.0, \"B\":1.0, \"C\":1.0, \"M\":2.0, \"X\":1.0}\n",
    "sw_xfocus = make_sample_weight(weights_X_focus, ytr_enc, ALL_CLASSES)\n",
    "\n",
    "gbx = GradientBoostingClassifier(\n",
    "    n_estimators=150, learning_rate=0.1, max_depth=3, random_state=0\n",
    ")\n",
    "gbx.fit(Xtr, ytr_enc, sample_weight=sw_xfocus)\n",
    "\n",
    "thresholds = {\"X\": 0.05}  # ajuste selon FP/TP souhaitÃ©s\n",
    "ytr_hat_gbx, _ = predict_with_thresholds(gbx, Xtr, ALL_CLASSES, thresholds)\n",
    "yte_hat_gbx, _ = predict_with_thresholds(gbx, Xte, ALL_CLASSES, thresholds)\n",
    "\n",
    "res_gbx = evaluate_with_custom_preds(\n",
    "    \"GradientBoosting (X-focus + seuil X)\", ytr_enc, ytr_hat_gbx, yte_enc, yte_hat_gbx, ALL_CLASSES\n",
    ")\n",
    "\n",
    "# mapping identitaire (labels dÃ©jÃ  0..len-1)\n",
    "to_original_id = {i: i for i in range(len(ALL_CLASSES))}\n",
    "add_model_result(\"GradientBoosting (X-focus + seuil X)\", gbx, np.unique(ytr_enc), to_original_id, res_gbx, yte_hat_gbx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f4f998d-bee9-4760-bf74-dc4f33bff3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Macro F1 (prÃ©sentes=['A', 'B', 'C', 'M']): 0.815\n",
      "ðŸŽ¯ Macro F1 (toutes=['A', 'B', 'C', 'M', 'X']): 0.652\n",
      "ðŸŽ¯ Balanced Acc (prÃ©sentes): 0.766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00       150\n",
      "           B       0.84      0.38      0.52       156\n",
      "           C       0.98      0.99      0.99      9029\n",
      "           M       0.82      0.69      0.75       256\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98      9591\n",
      "   macro avg       0.73      0.61      0.65      9591\n",
      "weighted avg       0.97      0.98      0.97      9591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "present_labels = np.unique(yte_enc)                 # classes rÃ©ellement prÃ©sentes en test\n",
    "all_labels = np.arange(len(ALL_CLASSES))            # A,B,C,M,X indexÃ©s 0..4\n",
    "\n",
    "f1_macro_present = f1_score(yte_enc, yte_hat_gbx, average=\"macro\")\n",
    "bacc_present     = balanced_accuracy_score(yte_enc, yte_hat_gbx)\n",
    "f1_macro_all     = f1_score(yte_enc, yte_hat_gbx, average=\"macro\",\n",
    "                            labels=all_labels, zero_division=0)\n",
    "\n",
    "print(f\"ðŸŽ¯ Macro F1 (prÃ©sentes={list(ALL_CLASSES[present_labels])}): {f1_macro_present:.3f}\")\n",
    "print(f\"ðŸŽ¯ Macro F1 (toutes={list(ALL_CLASSES)}): {f1_macro_all:.3f}\")\n",
    "print(f\"ðŸŽ¯ Balanced Acc (prÃ©sentes): {bacc_present:.3f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    yte_enc, yte_hat_gbx,\n",
    "    labels=all_labels,              # <-- on force le report sur toutes les classes\n",
    "    target_names=ALL_CLASSES,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9c0f9-9265-4bc0-ab3b-ea797e2ee547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b881a2d6-7f7a-4aca-b154-8c69c68b16d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ GradientBoosting (X-focus + seuil X) â€” 718 minutes ================\n",
      "\n",
      "â±ï¸ Plages continues :\n",
      "                    start                       end class  minutes\n",
      "2025-08-11 00:41:00+00:00 2025-08-11 03:04:00+00:00     C      144\n",
      "2025-08-11 03:05:00+00:00 2025-08-11 03:05:00+00:00     M        1\n",
      "2025-08-11 03:06:00+00:00 2025-08-11 03:47:00+00:00     C       42\n",
      "2025-08-11 03:48:00+00:00 2025-08-11 03:56:00+00:00     M        9\n",
      "2025-08-11 03:57:00+00:00 2025-08-11 08:38:00+00:00     C      282\n",
      "2025-08-11 08:39:00+00:00 2025-08-11 08:45:00+00:00     M        7\n",
      "2025-08-11 08:46:00+00:00 2025-08-11 11:43:00+00:00     C      178\n",
      "2025-08-11 11:44:00+00:00 2025-08-11 11:45:00+00:00     M        2\n",
      "2025-08-11 11:46:00+00:00 2025-08-11 12:35:00+00:00     C       50\n",
      "2025-08-11 12:36:00+00:00 2025-08-11 12:38:00+00:00     M        3\n",
      "\n",
      "ðŸ“Š Comptes classes prÃ©dites (718 min) :\n",
      "pred_class\n",
      "C    696\n",
      "M     22\n",
      "\n",
      "ðŸ“ˆ Probas moyennes (718 min) :\n",
      "A    0.000\n",
      "B    0.002\n",
      "C    0.969\n",
      "M    0.030\n",
      "X    0.000\n",
      "\n",
      "ðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\n",
      " - A: 0.00%\n",
      " - B: 0.00%\n",
      " - C: 96.94%\n",
      " - M: 3.06%\n",
      " - X: 0.00%\n",
      "\n",
      "ðŸ Part des classes prÃ©dites sur 718 min (par modÃ¨le) :\n",
      "                                      p_A  p_B    p_C   p_M  p_X\n",
      "model                                                           \n",
      "GradientBoosting (X-focus + seuil X)  0.0  0.0  96.94  3.06  0.0\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# helpers gÃ©nÃ©riques\n",
    "# =========================\n",
    "H_NEXT = 718  # ~12h observables (ajuste Ã  720 si besoin)\n",
    "\n",
    "def safe_to_datetime(s):\n",
    "    return pd.to_datetime(s.astype(str), utc=True, errors=\"coerce\")\n",
    "\n",
    "def get_last_minutes_block(X_test, mask_test, Xte, minutes=H_NEXT):\n",
    "    \"\"\"\n",
    "    Retourne (X_last, t_last) pour les 'minutes' derniÃ¨res minutes rÃ©elles du test.\n",
    "    Xte = features transformÃ©es correspondant Ã  X_test[mask_test]\n",
    "    \"\"\"\n",
    "    # timeline cÃ´tÃ© X_test\n",
    "    if \"time\" in X_test.columns:\n",
    "        t_all = safe_to_datetime(X_test[\"time\"])\n",
    "    elif isinstance(X_test.index, pd.DatetimeIndex):\n",
    "        t_all = pd.to_datetime(X_test.index, utc=True, errors=\"coerce\").to_series()\n",
    "    elif \"date\" in X_test.columns:\n",
    "        t_all = safe_to_datetime(X_test[\"date\"])\n",
    "    else:\n",
    "        raise KeyError(\"Pas de colonne temps ('time' ou 'date') dans X_test.\")\n",
    "\n",
    "    # indices du test valides (aprÃ¨s filtre) + tri par temps\n",
    "    idx_test = X_test.index[mask_test]\n",
    "    t_test_sorted = (\n",
    "        pd.DataFrame({\"time\": t_all.loc[idx_test].values}, index=idx_test)\n",
    "          .dropna()\n",
    "          .sort_values(\"time\")\n",
    "    )\n",
    "\n",
    "    # prendre les 'minutes' derniÃ¨res\n",
    "    last_idx = t_test_sorted.tail(minutes).index\n",
    "\n",
    "    # positions dans Xte (Xte est l'ordre de X_test[mask_test])\n",
    "    pos_map = pd.Series(range(len(idx_test)), index=idx_test)\n",
    "    sel_pos = pos_map.loc[last_idx].sort_values()\n",
    "\n",
    "    X_last = Xte[sel_pos.values]\n",
    "    t_last = t_test_sorted.loc[last_idx, \"time\"].sort_values().reset_index(drop=True)\n",
    "    return X_last, t_last\n",
    "\n",
    "def softmax_from_decision(scores):\n",
    "    scores = np.array(scores)\n",
    "    if scores.ndim == 1:\n",
    "        scores = np.column_stack([-scores, scores])\n",
    "    m = scores.max(axis=1, keepdims=True)\n",
    "    exp = np.exp(scores - m)\n",
    "    return exp / exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "def safe_predict_proba(estimator, X):\n",
    "    \"\"\"\n",
    "    Renvoie (proba, classes_idx_compacts).\n",
    "    \"\"\"\n",
    "    if hasattr(estimator, \"predict_proba\"):\n",
    "        p = estimator.predict_proba(X)\n",
    "        return p, estimator.classes_\n",
    "    elif hasattr(estimator, \"decision_function\"):\n",
    "        p = softmax_from_decision(estimator.decision_function(X))\n",
    "        classes_ = getattr(estimator, \"classes_\", np.arange(p.shape[1]))\n",
    "        return p, classes_\n",
    "    else:\n",
    "        # fallback uniforme\n",
    "        k = len(getattr(estimator, \"classes_\", [0, 1]))\n",
    "        n = X.shape[0]\n",
    "        return np.full((n, k), 1.0 / k), getattr(estimator, \"classes_\", np.arange(k))\n",
    "\n",
    "def build_718_table_for_model(name, fitted_entry, X_last, t_last, ALL_CLASSES):\n",
    "    \"\"\"\n",
    "    Construit le DataFrame minute->probas/classes pour 'name'.\n",
    "    fitted_entry = (clf, to_original, present)\n",
    "    \"\"\"\n",
    "    allc = np.array(ALL_CLASSES)\n",
    "    clf, to_original, present = fitted_entry\n",
    "\n",
    "    # proba sur classes COMPACTES (entraÃ®nement)\n",
    "    proba_compact, compact_classes = safe_predict_proba(clf, X_last)  # (N, k_present)\n",
    "\n",
    "    # mapping compact -> global index (0..len(ALL_CLASSES)-1)\n",
    "    compact_to_global = np.vectorize(to_original.get)(compact_classes)\n",
    "\n",
    "    # tableau proba sur toutes les classes globales\n",
    "    dfp = pd.DataFrame(0.0, index=np.arange(len(t_last)), columns=allc.tolist())\n",
    "\n",
    "    # injecter les proba aux bonnes colonnes\n",
    "    for j, gidx in enumerate(compact_to_global):\n",
    "        cname = allc[gidx]\n",
    "        dfp[cname] = proba_compact[:, j]\n",
    "\n",
    "    # time + classes dÃ©rivÃ©es\n",
    "    dfp.insert(0, \"time\", t_last.values)\n",
    "    dfp[\"pred_class\"]  = allc[dfp[allc].values.argmax(axis=1)]\n",
    "    dfp[\"pred_strong\"] = dfp[\"pred_class\"].isin([\"M\", \"X\"]).astype(int)\n",
    "\n",
    "    # tri par temps (sÃ©curitÃ©)\n",
    "    dfp = dfp.dropna(subset=[\"time\"]).copy()\n",
    "    dfp[\"time\"] = pd.to_datetime(dfp[\"time\"], utc=True, errors=\"coerce\")\n",
    "    dfp = dfp.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    # plages continues\n",
    "    change = dfp[\"pred_class\"].ne(dfp[\"pred_class\"].shift(1))\n",
    "    dfp[\"_grp\"] = change.cumsum()\n",
    "    spans = (\n",
    "        dfp.groupby(\"_grp\", as_index=False)\n",
    "           .agg(start=(\"time\", \"first\"),\n",
    "                end=(\"time\", \"last\"),\n",
    "                **{\"class\": (\"pred_class\", \"first\")},\n",
    "                minutes=(\"time\", \"size\"))\n",
    "           .drop(columns=[\"_grp\"])\n",
    "    )\n",
    "    return dfp, spans\n",
    "\n",
    "def describe_718(dfp, spans, name, ALL_CLASSES):\n",
    "    print(f\"\\n================ {name} â€” 718 minutes ================\")\n",
    "    print(\"\\nâ±ï¸ Plages continues :\")\n",
    "    print(spans.to_string(index=False))\n",
    "\n",
    "    print(\"\\nðŸ“Š Comptes classes prÃ©dites (718 min) :\")\n",
    "    print(dfp[\"pred_class\"].value_counts().to_string())\n",
    "\n",
    "    print(\"\\nðŸ“ˆ Probas moyennes (718 min) :\")\n",
    "    print(dfp[list(ALL_CLASSES)].mean().round(3).to_string())\n",
    "\n",
    "    print(\"\\nðŸ† % minutes oÃ¹ chaque classe est 1Ã¨re proba :\")\n",
    "    for c in ALL_CLASSES:\n",
    "        others = [x for x in ALL_CLASSES if x != c]\n",
    "        share = (dfp[c] >= dfp[others].max(axis=1)).mean() * 100\n",
    "        print(f\" - {c}: {share:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# extraire X_last & t_last une seule fois\n",
    "# =========================\n",
    "X12_t, t12 = get_last_minutes_block(X_test, mask_test, Xte, minutes=H_NEXT)\n",
    "\n",
    "# =========================\n",
    "# gÃ©nÃ©rer pour chaque modÃ¨le du pool\n",
    "# =========================\n",
    "pred_tables_718 = {}\n",
    "spans_718 = {}\n",
    "\n",
    "for name, fitted_entry in fitted_pool.items():\n",
    "    df_12h, spans = build_718_table_for_model(name, fitted_entry, X12_t, t12, ALL_CLASSES)\n",
    "    pred_tables_718[name] = df_12h\n",
    "    spans_718[name] = spans\n",
    "    # impression dÃ©taillÃ©e (commenter si trop verbeux)\n",
    "    describe_718(df_12h, spans, name, ALL_CLASSES)\n",
    "\n",
    "# =========================\n",
    "# tableau comparatif des parts de classes (718 min)\n",
    "# =========================\n",
    "summary = []\n",
    "for name, dfp in pred_tables_718.items():\n",
    "    vc = dfp[\"pred_class\"].value_counts(normalize=True).reindex(ALL_CLASSES, fill_value=0.0)\n",
    "    summary.append({\"model\": name, **{f\"p_{c}\": float(vc.get(c, 0.0)) for c in ALL_CLASSES}})\n",
    "\n",
    "if not summary:\n",
    "    print(\"\\nâš ï¸ Aucun modÃ¨le dans fitted_pool â†’ pas de rÃ©sumÃ©.\")\n",
    "else:\n",
    "    summary_df = (pd.DataFrame(summary)\n",
    "                    .set_index(\"model\")\n",
    "                    .sort_index())\n",
    "    print(\"\\nðŸ Part des classes prÃ©dites sur 718 min (par modÃ¨le) :\")\n",
    "    print((summary_df * 100).round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99de4fb7-29a8-4c14-9067-22dd0f555493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Train: acc=0.8374 | bacc=0.9062 | f1_macro=0.9004 | f1_weighted=0.8371\n",
      "ðŸ“Š Test : acc=0.9763 | bacc=0.7660 | f1_macro=0.8145 | f1_weighted=0.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T:\\Anaconda\\envs\\solarflares\\lib\\site-packages\\_distutils_hack\\__init__.py:15: UserWarning:\n",
      "\n",
      "Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "\n",
      "T:\\Anaconda\\envs\\solarflares\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning:\n",
      "\n",
      "Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "\n",
      "Registered model 'solar-flares-classifier' already exists. Creating a new version of this model...\n",
      "2025/08/12 10:57:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: solar-flares-classifier, version 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¸ï¸ Non promu (reste en Staging) â€” test_f1_macro=0.8145 < 0.9\n",
      "âœ… modÃ¨le sauvegardÃ© & ðŸ“¡ MLflow loggÃ© (Evidently + CM + report) + Registry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'solar-flares-classifier'.\n"
     ]
    }
   ],
   "source": [
    "# ================== 0) Config ==================\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", \"http://mlflow:5000\"))\n",
    "mlflow.set_experiment(\"solar-flares\")\n",
    "\n",
    "PROD_THRESHOLD = 0.90  # gate de promotion auto\n",
    "\n",
    "# ================== 1) MÃ©triques ==================\n",
    "metrics = {\n",
    "    \"train_acc\": accuracy_score(ytr_enc, ytr_hat_gbx),\n",
    "    \"train_bacc\": balanced_accuracy_score(ytr_enc, ytr_hat_gbx),\n",
    "    \"train_f1_macro\": f1_score(ytr_enc, ytr_hat_gbx, average=\"macro\"),\n",
    "    \"train_f1_weighted\": f1_score(ytr_enc, ytr_hat_gbx, average=\"weighted\"),\n",
    "    \"test_acc\": accuracy_score(yte_enc, yte_hat_gbx),\n",
    "    \"test_bacc\": balanced_accuracy_score(yte_enc, yte_hat_gbx),\n",
    "    \"test_f1_macro\": f1_score(yte_enc, yte_hat_gbx, average=\"macro\"),\n",
    "    \"test_f1_weighted\": f1_score(yte_enc, yte_hat_gbx, average=\"weighted\"),\n",
    "}\n",
    "print(f\"ðŸ“Š Train: acc={metrics['train_acc']:.4f} | bacc={metrics['train_bacc']:.4f} | \"\n",
    "      f\"f1_macro={metrics['train_f1_macro']:.4f} | f1_weighted={metrics['train_f1_weighted']:.4f}\")\n",
    "print(f\"ðŸ“Š Test : acc={metrics['test_acc']:.4f} | bacc={metrics['test_bacc']:.4f} | \"\n",
    "      f\"f1_macro={metrics['test_f1_macro']:.4f} | f1_weighted={metrics['test_f1_weighted']:.4f}\")\n",
    "\n",
    "# ================== 2) Params & contexte ==================\n",
    "params = {\n",
    "    \"algo\": \"GradientBoostingClassifier\",\n",
    "    \"n_estimators\": 150,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 3,\n",
    "    \"random_state\": 0,\n",
    "    \"thresholds\": {\"X\": 0.05},\n",
    "    \"class_weights\": {\"A\":1.0, \"B\":1.0, \"C\":1.0, \"M\":2.0, \"X\":1.0},\n",
    "    \"n_train\": int(len(ytr_enc)),\n",
    "    \"n_test\": int(len(yte_enc)),\n",
    "}\n",
    "context = {\n",
    "    \"ALL_CLASSES\": list(ALL_CLASSES),\n",
    "    \"train_class_dist\": pd.Series(ytr).value_counts().to_dict(),\n",
    "    \"test_class_dist\": pd.Series(yte).value_counts().to_dict(),\n",
    "}\n",
    "\n",
    "# ================== 3) Artefacts locaux ==================\n",
    "# Confusion matrix (test)\n",
    "cm = confusion_matrix(yte_enc, yte_hat_gbx, labels=np.arange(len(ALL_CLASSES)))\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "ax.set_title(\"Confusion matrix (test)\")\n",
    "plt.colorbar(im, ax=ax)\n",
    "ticks = np.arange(len(ALL_CLASSES))\n",
    "ax.set_xticks(ticks); ax.set_xticklabels(ALL_CLASSES, rotation=45, ha=\"right\")\n",
    "ax.set_yticks(ticks); ax.set_yticklabels(ALL_CLASSES)\n",
    "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Classification report (test)\n",
    "report_txt = classification_report(\n",
    "    yte_enc, yte_hat_gbx,\n",
    "    labels=np.arange(len(ALL_CLASSES)),\n",
    "    target_names=ALL_CLASSES,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# ===== Evidently 0.7 â€” robuste aux classes manquantes et labels string =====\n",
    "idx2name = {i: c for i, c in enumerate(ALL_CLASSES)}\n",
    "\n",
    "# (1) DataFrames ref/test en TEXTE\n",
    "ref_txt = pd.DataFrame({\n",
    "    \"target\": ytr,\n",
    "    \"prediction\": [idx2name[i] for i in ytr_hat_gbx]\n",
    "})\n",
    "cur_txt = pd.DataFrame({\n",
    "    \"target\": yte,\n",
    "    \"prediction\": [idx2name[i] for i in yte_hat_gbx]\n",
    "})\n",
    "\n",
    "# (2) Ensemble des labels rÃ©ellement prÃ©sents (ref âˆª cur)\n",
    "labels_present = sorted(set(ref_txt[\"target\"]) | set(ref_txt[\"prediction\"]) |\n",
    "                        set(cur_txt[\"target\"]) | set(cur_txt[\"prediction\"]))\n",
    "name2id = {c: i for i, c in enumerate(labels_present)}   # 'A'->0, 'B'->1, ...\n",
    "id2name = {i: c for c, i in name2id.items()}             # 0->'A', 1->'B', ...\n",
    "\n",
    "# (3) Mapping vers IDs entiers (Ã©vite les KeyError 'A')\n",
    "def to_ids(df):\n",
    "    out = pd.DataFrame({\n",
    "        \"target\": df[\"target\"].map(name2id),\n",
    "        \"prediction\": df[\"prediction\"].map(name2id),\n",
    "    })\n",
    "    return out.dropna().astype(int)\n",
    "\n",
    "ref_ids = to_ids(ref_txt)\n",
    "cur_ids = to_ids(cur_txt)\n",
    "\n",
    "if len(ref_ids) == 0 or len(cur_ids) == 0:\n",
    "    print(\"âš ï¸ AprÃ¨s mapping, DataFrame vide pour Evidently. VÃ©rifie labels_present:\", labels_present)\n",
    "\n",
    "# (4) DÃ©finition Evidently\n",
    "data_def = DataDefinition(classification=[\n",
    "    MulticlassClassification(\n",
    "        target=\"target\",\n",
    "        prediction_labels=\"prediction\",\n",
    "        labels=list(range(len(labels_present)))  # ex: [0,1,2,3]\n",
    "    )\n",
    "])\n",
    "\n",
    "ref_ds = Dataset.from_pandas(ref_ids, data_definition=data_def)\n",
    "cur_ds = Dataset.from_pandas(cur_ids, data_definition=data_def)\n",
    "\n",
    "# (5) GÃ©nÃ©ration du rapport (fallback en \"current only\" si comparaison Ã©choue)\n",
    "ev = Report([ClassificationPreset()])\n",
    "try:\n",
    "    snap = ev.run(cur_ds, ref_ds)   # comparaison current vs reference\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ Evidently comparaison a Ã©chouÃ© -> current only. Raison:\", repr(e))\n",
    "    snap = ev.run(cur_ds)\n",
    "\n",
    "# (6) Sauvegardes (HTML + JSON fallback)\n",
    "EVIDENTLY_HTML = \"evidently_report.html\"\n",
    "EVIDENTLY_JSON = \"evidently_report.json\"\n",
    "\n",
    "# HTML (OK en 0.7+)\n",
    "snap.save_html(EVIDENTLY_HTML)\n",
    "\n",
    "# JSON : tenter .json(), sinon payload â€œmaisonâ€\n",
    "saved_json = False\n",
    "try:\n",
    "    if hasattr(snap, \"json\"):\n",
    "        with open(EVIDENTLY_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(snap.json())\n",
    "        saved_json = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not saved_json:\n",
    "    # --- Fallback JSON (pour le tracking MLflow) ---\n",
    "    cm = confusion_matrix(yte_enc, yte_hat_gbx, labels=np.arange(len(ALL_CLASSES)))\n",
    "    clf_dict = classification_report(\n",
    "        yte_enc, yte_hat_gbx,\n",
    "        labels=np.arange(len(ALL_CLASSES)),\n",
    "        target_names=ALL_CLASSES,\n",
    "        zero_division=0,\n",
    "        output_dict=True\n",
    "    )\n",
    "    summary_payload = {\n",
    "        \"labels_present\": labels_present,\n",
    "        \"n_reference\": int(len(ref_ids)),\n",
    "        \"n_current\": int(len(cur_ids)),\n",
    "        \"sklearn_report_test\": clf_dict,\n",
    "        \"confusion_matrix_test\": cm.tolist(),\n",
    "        \"metrics_logged\": {\n",
    "            \"train_acc\": float(metrics[\"train_acc\"]),\n",
    "            \"train_bacc\": float(metrics[\"train_bacc\"]),\n",
    "            \"train_f1_macro\": float(metrics[\"train_f1_macro\"]),\n",
    "            \"test_acc\": float(metrics[\"test_acc\"]),\n",
    "            \"test_bacc\": float(metrics[\"test_bacc\"]),\n",
    "            \"test_f1_macro\": float(metrics[\"test_f1_macro\"]),\n",
    "        },\n",
    "    }\n",
    "    import json\n",
    "    with open(EVIDENTLY_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary_payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ================== 4) Sauvegarde locale du modÃ¨le ==================\n",
    "MODEL_PATH = Path(\"./models/model.pkl\")\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(gbx, MODEL_PATH)\n",
    "\n",
    "# ================== 5) Log MLflow + Registry avec gate ==================\n",
    "# Fermer proprement un run restÃ© ouvert (aprÃ¨s un crash ou une exÃ©cution interrompue)\n",
    "if mlflow.active_run() is not None:\n",
    "    print(\"â„¹ï¸ Fin de l'ancien run:\", mlflow.active_run().info.run_id)\n",
    "    mlflow.end_run()\n",
    "run_name = f\"GBM_X_focus_threshold_{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # params / mÃ©triques / contexte\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.log_dict(context, \"context.json\")\n",
    "\n",
    "    # artefacts\n",
    "    mlflow.log_text(report_txt, \"classification_report_test.txt\")\n",
    "    mlflow.log_figure(fig, \"confusion_matrix_test.png\"); plt.close(fig)\n",
    "    mlflow.log_artifact(EVIDENTLY_HTML, artifact_path=\"evidently\")\n",
    "    mlflow.log_artifact(EVIDENTLY_JSON, artifact_path=\"evidently\")\n",
    "    mlflow.log_artifact(str(MODEL_PATH))\n",
    "\n",
    "    # signature + modÃ¨le versionnÃ© dans le run\n",
    "    sig = infer_signature(pd.DataFrame(Xtr[:200]), gbx.predict(Xtr[:200]))\n",
    "    mlflow.sklearn.log_model(gbx, artifact_path=\"model\", signature=sig)\n",
    "\n",
    "    # Enregistrement au Model Registry\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    reg = mlflow.register_model(model_uri, \"solar-flares-classifier\")\n",
    "\n",
    "    # Gate de promo: prod si f1_macro_test >= PROD_THRESHOLD\n",
    "    mlflow.set_tag(\"prod_threshold\", PROD_THRESHOLD)\n",
    "    promoted = metrics[\"test_f1_macro\"] >= PROD_THRESHOLD\n",
    "\n",
    "    from mlflow import MlflowClient\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # tags sur la version\n",
    "    client.set_model_version_tag(\"solar-flares-classifier\", reg.version, \"test_f1_macro\", str(metrics[\"test_f1_macro\"]))\n",
    "    client.set_model_version_tag(\"solar-flares-classifier\", reg.version, \"promoted_to_production\", str(promoted))\n",
    "\n",
    "    # alias Staging toujours mis Ã  jour\n",
    "    client.set_registered_model_alias(\"solar-flares-classifier\", \"Staging\", reg.version)\n",
    "\n",
    "    if promoted:\n",
    "        client.set_registered_model_alias(\"solar-flares-classifier\", \"Production\", reg.version)\n",
    "        print(f\"ðŸš€ Promu en Production (v{reg.version}) â€” test_f1_macro={metrics['test_f1_macro']:.4f} â‰¥ {PROD_THRESHOLD}\")\n",
    "    else:\n",
    "        print(f\"â¸ï¸ Non promu (reste en Staging) â€” test_f1_macro={metrics['test_f1_macro']:.4f} < {PROD_THRESHOLD}\")\n",
    "\n",
    "print(\"âœ… modÃ¨le sauvegardÃ© & ðŸ“¡ MLflow loggÃ© (Evidently + CM + report) + Registry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd5567-bec1-4a4a-a303-fd5213b4cb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8505a8-d2ab-4d01-b1bc-029cf1eb7501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (solarflares)",
   "language": "python",
   "name": "solarflares"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
